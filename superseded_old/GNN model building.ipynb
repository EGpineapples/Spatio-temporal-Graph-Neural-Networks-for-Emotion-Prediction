{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from enum import Enum\n",
    "\n",
    "# Constants definitions\n",
    "MAX_SIMU_TOKENS = 16  \n",
    "N_TRACKS = 4  # Number of \"instrument\" tracks\n",
    "N_BARS = 2  # Assuming 2 bars for simplicity, adjust as needed\n",
    "N_TIMESTEPS = 120  # Number of timesteps per bar, adjust as needed\n",
    "RESOLUTION = 8  # Assuming 8 timesteps per beat, adjust as needed\n",
    "\n",
    "# This enum contains edge type indices for each edge type\n",
    "class EdgeTypes(Enum):\n",
    "    TRACK = 0 # This has to be interpreted as the starting index\n",
    "    ONSET = N_TRACKS\n",
    "    NEXT = N_TRACKS + 1\n",
    "\n",
    "# N_TRACKS track types + 1 onset edge type + 1 next edge type\n",
    "N_EDGE_TYPES = N_TRACKS + 2\n",
    "\n",
    "# Assuming these are defined elsewhere or simplifying for this example\n",
    "N_DISCRETE_VALUES = 4\n",
    "N_SAMPLES = 10\n",
    "\n",
    "def generate_sample_data(num_samples, n_timesteps):\n",
    "    np.random.seed(42)\n",
    "    emotions = np.random.randint(0, N_DISCRETE_VALUES, (num_samples, n_timesteps))\n",
    "    locations = np.random.randint(0, N_DISCRETE_VALUES, (num_samples, n_timesteps))\n",
    "    activities = np.random.randint(0, N_DISCRETE_VALUES, (num_samples, n_timesteps))\n",
    "    modes = np.random.randint(0, N_DISCRETE_VALUES, (num_samples, n_timesteps))\n",
    "    return emotions, locations, activities, modes\n",
    "\n",
    "def preprocess_sample_data(emotions, locations, activities, modes, dest_dir):\n",
    "    num_samples = emotions.shape[0]\n",
    "    n_timesteps = emotions.shape[1]\n",
    "    window_size = N_BARS * 4 * RESOLUTION  # Calculate window size\n",
    "\n",
    "    for sample_idx in range(num_samples):\n",
    "        # Initialize tensors for this sample with the full length first\n",
    "        full_c_tensor = np.zeros((N_TRACKS, n_timesteps, MAX_SIMU_TOKENS, 2), dtype=np.int16)\n",
    "        full_s_tensor = np.zeros((N_TRACKS, n_timesteps), dtype=bool)\n",
    "\n",
    "        # Populate the full tensors\n",
    "        for t in range(n_timesteps):\n",
    "            for track_idx, data in enumerate([emotions, locations, activities, modes]):\n",
    "                value = data[sample_idx, t]\n",
    "                full_c_tensor[track_idx, t, 0, 0] = value  # Pitch as emotion value\n",
    "                full_c_tensor[track_idx, t, 0, 1] = 1  # Duration as 1 for simplicity\n",
    "                full_s_tensor[track_idx, t] = True  # Note played at this timestep\n",
    "        \n",
    "        stride = window_size // 2\n",
    "\n",
    "        # Windowing over time\n",
    "        for start_idx in range(0, n_timesteps - window_size + 1, stride):\n",
    "            c_tensor_segment = full_c_tensor[:, start_idx:start_idx + window_size, :, :]\n",
    "            s_tensor_segment = full_s_tensor[:, start_idx:start_idx + window_size]\n",
    "\n",
    "            # Save the tensors for this segment to an .npz file\n",
    "            sample_filepath = os.path.join(dest_dir, f\"sample_{sample_idx}_segment_{start_idx//stride}.npz\")\n",
    "            try:\n",
    "                np.savez(sample_filepath, c_tensor=c_tensor_segment, s_tensor=s_tensor_segment)\n",
    "                print(f\"File saved: {sample_filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to save {sample_filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_0_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_0_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_1_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_1_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_2_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_2_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_3_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_3_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_4_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_4_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_5_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_5_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_6_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_6_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_7_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_7_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_8_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_8_segment_1.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_9_segment_0.npz\n",
      "File saved: C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_9_segment_1.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Fixed directory\n",
    "dest_dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed'\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.makedirs(dest_dir)\n",
    "\n",
    "# Generate sample data\n",
    "emotions, locations, activities, modes = generate_sample_data(N_SAMPLES, N_TIMESTEPS)\n",
    "\n",
    "# Preprocess and save the sample data\n",
    "preprocess_sample_data(emotions, locations, activities, modes, dest_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of c_tensor: (4, 64, 16, 2)\n",
      "Shape of s_tensor: (4, 64)\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_0_segment_0.npz'\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load(file_path)\n",
    "\n",
    "# Access the tensors\n",
    "c_tensor = data['c_tensor']\n",
    "s_tensor = data['s_tensor']\n",
    "\n",
    "# Print their shapes\n",
    "print(f'Shape of c_tensor: {c_tensor.shape}')\n",
    "print(f'Shape of s_tensor: {s_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.collate import collate\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "\n",
    "def get_node_labels(s_tensor, ones_idxs):\n",
    "    # Build a tensor which has node labels in place of each activation in the\n",
    "    # stucture tensor\n",
    "    labels = torch.zeros_like(s_tensor, dtype=torch.long, \n",
    "                              device=s_tensor.device)\n",
    "    n_nodes = len(ones_idxs[0])\n",
    "    labels[ones_idxs] = torch.arange(n_nodes, device=s_tensor.device)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_track_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "\n",
    "    track_edges = []\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        # Indices where the binary structure tensor is active\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    # For each track, add direct and inverse edges between consecutive nodes\n",
    "    for track in range(s_tensor.size(0)):\n",
    "        # List of active timesteps in the current track\n",
    "        tss = list(ones_idxs[1][ones_idxs[0] == track])\n",
    "        edge_type = EdgeTypes.TRACK.value + track\n",
    "        edges = [\n",
    "            # Edge tuple: (u, v, type, ts_distance). Zip is used to obtain\n",
    "            # consecutive active timesteps. Edges in different tracks have\n",
    "            # different types.\n",
    "            (node_labels[track, t1],\n",
    "             node_labels[track, t2], edge_type, t2 - t1)\n",
    "            for t1, t2 in zip(tss[:-1], tss[1:])\n",
    "        ]\n",
    "        inverse_edges = [(u, v, t, d) for (v, u, t, d) in edges]\n",
    "        track_edges.extend(edges + inverse_edges)\n",
    "\n",
    "    return torch.tensor(track_edges, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_onset_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "\n",
    "    onset_edges = []\n",
    "    edge_type = EdgeTypes.ONSET.value\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        # Indices where the binary structure tensor is active\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    # Add direct and inverse edges between nodes played in the same timestep\n",
    "    for ts in range(s_tensor.size(1)):\n",
    "        # List of active tracks in the current timestep\n",
    "        tracks = list(ones_idxs[0][ones_idxs[1] == ts])\n",
    "        # Obtain all possible pairwise combinations of active tracks\n",
    "        combinations = list(itertools.combinations(tracks, 2))\n",
    "        edges = [\n",
    "            # Edge tuple: (u, v, type, ts_distance(=0)).\n",
    "            (node_labels[track1, ts], node_labels[track2, ts], edge_type, 0)\n",
    "            for track1, track2 in combinations\n",
    "        ]\n",
    "        inverse_edges = [(u, v, t, d) for (v, u, t, d) in edges]\n",
    "        onset_edges.extend(edges + inverse_edges)\n",
    "\n",
    "    return torch.tensor(onset_edges, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_next_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "\n",
    "    next_edges = []\n",
    "    edge_type = EdgeTypes.NEXT.value\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        # Indices where the binary structure tensor is active\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    # List of active timesteps\n",
    "    tss = torch.nonzero(torch.any(s_tensor.bool(), dim=0)).squeeze()\n",
    "    if tss.dim() == 0:\n",
    "        return torch.tensor([], dtype=torch.long)\n",
    "\n",
    "    for i in range(tss.size(0)-1):\n",
    "        # Get consecutive active timesteps\n",
    "        t1, t2 = tss[i], tss[i+1]\n",
    "        # Get all the active tracks in the two timesteps\n",
    "        t1_tracks = ones_idxs[0][ones_idxs[1] == t1]\n",
    "        t2_tracks = ones_idxs[0][ones_idxs[1] == t2]\n",
    "\n",
    "        # Combine the source and destination tracks, removing combinations with\n",
    "        # the same source and destination track (since these represent track\n",
    "        # edges).\n",
    "        tracks_product = list(itertools.product(t1_tracks, t2_tracks))\n",
    "        tracks_product = [(track1, track2)\n",
    "                          for (track1, track2) in tracks_product\n",
    "                          if track1 != track2]\n",
    "        # Edge tuple: (u, v, type, ts_distance).\n",
    "        edges = [(node_labels[track1, t1], node_labels[track2, t2],\n",
    "                  edge_type, t2 - t1)\n",
    "                 for track1, track2 in tracks_product]\n",
    "\n",
    "        next_edges.extend(edges)\n",
    "\n",
    "    return torch.tensor(next_edges, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_track_features(s_tensor):\n",
    "\n",
    "    # Indices where the binary structure tensor is active\n",
    "    ones_idxs = torch.nonzero(s_tensor)\n",
    "\n",
    "    n_nodes = len(ones_idxs)\n",
    "    tracks = ones_idxs[:, 0]\n",
    "    n_tracks = s_tensor.size(0)\n",
    "\n",
    "    # The feature n_nodes x n_tracks tensor contains one-hot tracks\n",
    "    # representations for each node\n",
    "    features = torch.zeros((n_nodes, n_tracks))\n",
    "    features[torch.arange(n_nodes), tracks] = 1\n",
    "\n",
    "    return features\n",
    "\n",
    "def custom_collate(data_list):\n",
    "    batch = Batch.from_data_list(data_list)\n",
    "    if hasattr(batch, 'batch'):\n",
    "        batch.bars = batch.batch.clone()  # Optionally clone to ensure no accidental modification\n",
    "    return batch\n",
    "\n",
    "\n",
    "def graph_from_tensor(s_tensor):\n",
    "\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over bars and construct a graph for each bar\n",
    "    for i in range(s_tensor.size(0)):\n",
    "\n",
    "        bar = s_tensor[i]\n",
    "\n",
    "        # If the bar contains no activations, add a fake one to avoid having \n",
    "        # to deal with empty graphs\n",
    "        if not torch.any(bar):\n",
    "            bar[0, 0] = 1\n",
    "\n",
    "        # Get edges from boolean activations\n",
    "        track_edges = get_track_edges(bar)\n",
    "        onset_edges = get_onset_edges(bar)\n",
    "        next_edges = get_next_edges(bar)\n",
    "        edges = [track_edges, onset_edges, next_edges]\n",
    "\n",
    "        # Concatenate edge tensors (N x 4) (if any)\n",
    "        is_edgeless = (len(track_edges) == 0 and\n",
    "                       len(onset_edges) == 0 and\n",
    "                       len(next_edges) == 0)\n",
    "        if not is_edgeless:\n",
    "            edge_list = torch.cat([x for x in edges\n",
    "                                   if torch.numel(x) > 0])\n",
    "\n",
    "        # Adapt tensor to torch_geometric's Data\n",
    "        # If no edges, add fake self-edge\n",
    "        # edge_list[:, :2] contains source and destination node labels\n",
    "        # edge_list[:, 2:] contains edge types and timestep distances\n",
    "        edge_index = (edge_list[:, :2].t().contiguous() if not is_edgeless else\n",
    "                      torch.LongTensor([[0], [0]]))\n",
    "        attrs = (edge_list[:, 2:] if not is_edgeless else\n",
    "                 torch.Tensor([[0, 0]]))\n",
    "\n",
    "        # Add one hot timestep distance to edge attributes\n",
    "        edge_attr = torch.zeros(attrs.size(0), s_tensor.shape[-1] + 1)\n",
    "        edge_attr[:, 0] = attrs[:, 0]\n",
    "        edge_attr[torch.arange(edge_attr.size(0)),\n",
    "                   attrs.long()[:, 1] + 1] = 1\n",
    "        # print(type(edge_attr))\n",
    "\n",
    "        node_features = get_track_features(bar)\n",
    "        is_drum = node_features[:, 0].bool()\n",
    "        num_nodes = torch.sum(bar, dtype=torch.long)\n",
    "        bars.append(Data(edge_index=edge_index, edge_attr=edge_attr,\n",
    "                         num_nodes=num_nodes, node_features=node_features,\n",
    "                         is_drum=is_drum).to(s_tensor.device))\n",
    "\n",
    "    # Use custom collate function to merge all Data objects into a single Batch\n",
    "    #graph = custom_collate(bars)\n",
    "\n",
    "    # Manage the batch attribute as bars, if it exists\n",
    "    #if hasattr(graph, 'batch'):\n",
    "    #    graph.bars = graph.batch.clone()  # Cloning to ensure that original batch numbers are preserved\n",
    "    #    # print(\"Bars attribute added to graph\")\n",
    "\n",
    "    #return graph\n",
    "\n",
    "    # Merge the graphs corresponding to different bars into a single big graph\n",
    "    graph, _, _ = collate(\n",
    "        Data,\n",
    "        data_list=bars,\n",
    "        increment=True,\n",
    "        add_batch=True\n",
    "    )\n",
    "\n",
    "    # Change bars assignment vector name (otherwise, Dataloader's collate\n",
    "    # would overwrite graphs.batch)\n",
    "    graph.bars = graph.batch\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "N_PITCH_TOKENS = 131\n",
    "N_DUR_TOKENS = 99\n",
    "D_TOKEN_PAIR = N_PITCH_TOKENS + N_DUR_TOKENS\n",
    "\n",
    "\n",
    "class PolyphemusDataset(Dataset):\n",
    "    def __init__(self, dir, n_bars=2):\n",
    "        self.dir = dir\n",
    "        self.files = [entry.path for entry in os.scandir(self.dir) if entry.is_file()]\n",
    "        self.len = len(self.files)\n",
    "        self.n_bars = n_bars\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load tensors\n",
    "        sample_path = self.files[idx]  # Directly use the path string\n",
    "        data = np.load(sample_path, allow_pickle = True)\n",
    "        c_tensor = torch.tensor(data[\"c_tensor\"], dtype=torch.long)\n",
    "        s_tensor = torch.tensor(data[\"s_tensor\"], dtype=torch.bool)\n",
    "\n",
    "        # From (n_tracks x n_timesteps x ...)\n",
    "        # to (n_bars x n_tracks x n_timesteps x ...)\n",
    "        c_tensor = c_tensor.reshape(c_tensor.shape[0], self.n_bars, -1,\n",
    "                                    c_tensor.shape[2], c_tensor.shape[3])\n",
    "        c_tensor = c_tensor.permute(1, 0, 2, 3, 4)\n",
    "        s_tensor = s_tensor.reshape(s_tensor.shape[0], self.n_bars, -1)\n",
    "        s_tensor = s_tensor.permute(1, 0, 2)\n",
    "\n",
    "        # From decimals to onehot (pitches)\n",
    "        pitches = c_tensor[..., 0]\n",
    "        onehot_p = torch.zeros(\n",
    "            (pitches.shape[0]*pitches.shape[1]*pitches.shape[2]*pitches.shape[3],\n",
    "             N_PITCH_TOKENS),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        onehot_p[torch.arange(0, onehot_p.shape[0]), pitches.reshape(-1)] = 1.\n",
    "        onehot_p = onehot_p.reshape(pitches.shape[0], pitches.shape[1],\n",
    "                                    pitches.shape[2], pitches.shape[3],\n",
    "                                    N_PITCH_TOKENS)\n",
    "\n",
    "        # From decimals to onehot (durations)\n",
    "        durs = c_tensor[..., 1]\n",
    "        onehot_d = torch.zeros(\n",
    "            (durs.shape[0]*durs.shape[1]*durs.shape[2]*durs.shape[3],\n",
    "             N_DUR_TOKENS),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        onehot_d[torch.arange(0, onehot_d.shape[0]), durs.reshape(-1)] = 1.\n",
    "        onehot_d = onehot_d.reshape(durs.shape[0], durs.shape[1],\n",
    "                                    durs.shape[2], durs.shape[3],\n",
    "                                    N_DUR_TOKENS)\n",
    "\n",
    "        # Concatenate pitches and durations\n",
    "        c_tensor = torch.cat((onehot_p, onehot_d), dim=-1)\n",
    "\n",
    "        # Build graph structure from structure tensor\n",
    "        graph = graph_from_tensor(s_tensor)\n",
    "        #print(type(graph.edge_attr))  # This should print <class 'torch.Tensor'>\n",
    "\n",
    "        # Filter silences in order to get a sparse representation\n",
    "        c_tensor = c_tensor.reshape(-1, c_tensor.shape[-2], c_tensor.shape[-1])\n",
    "        c_tensor = c_tensor[s_tensor.reshape(-1).bool()]\n",
    "\n",
    "        graph.c_tensor = c_tensor\n",
    "        graph.s_tensor = s_tensor.float()\n",
    "\n",
    "        return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "# Assuming constants are defined somewhere in your codebase\n",
    "N_PITCH_TOKENS = 131\n",
    "N_DUR_TOKENS = 99\n",
    "\n",
    "# Import the PolyphemusDataset class definition here\n",
    "\n",
    "# Define the directory where your dataset is located\n",
    "data_dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed'\n",
    "\n",
    "# Create an instance of the PolyphemusDataset\n",
    "dataset = PolyphemusDataset(dir=data_dir, n_bars=2)\n",
    "\n",
    "# Access the first item in the dataset to check edge_attr\n",
    "graph = dataset[0]  # This will call the __getitem__ method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph: Data(edge_index=[2, 2008], edge_attr=[2008, 33], num_nodes=256, node_features=[256, 4], is_drum=[256], batch=[256], ptr=[3], bars=[256], c_tensor=[256, 16, 230], s_tensor=[2, 4, 32])\n",
      "Graph.c_tensor shape: torch.Size([256, 16, 230])\n",
      "Graph.s_tensor shape: torch.Size([2, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "# Constants for one-hot encoding\n",
    "N_PITCH_TOKENS = 131\n",
    "N_DUR_TOKENS = 99\n",
    "D_TOKEN_PAIR = N_PITCH_TOKENS + N_DUR_TOKENS\n",
    "\n",
    "# PolyphemusDataset class definition here (as provided in your question)\n",
    "\n",
    "# Create an instance of the PolyphemusDataset\n",
    "dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed'\n",
    "dataset = PolyphemusDataset(dir, n_bars=2)\n",
    "\n",
    "# Load a sample from the dataset\n",
    "sample_index = 0  # For example, load the first sample\n",
    "graph = dataset[sample_index]\n",
    "\n",
    "# Inspect the graph and its tensors\n",
    "print(\"Graph:\", graph)\n",
    "print(\"Graph.c_tensor shape:\", graph.c_tensor.shape)\n",
    "print(\"Graph.s_tensor shape:\", graph.s_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch_sparse import SparseTensor, masked_select_nnz\n",
    "from torch_geometric.typing import OptTensor, Adj\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn.conv import RGCNConv\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (Tensor, Tensor) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (SparseTensor, Tensor) -> SparseTensor\n",
    "    pass\n",
    "\n",
    "\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    if isinstance(edge_index, Tensor):\n",
    "        return edge_index[:, edge_mask]\n",
    "    else:\n",
    "        return masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
    "\n",
    "\n",
    "def masked_edge_attr(edge_attr, edge_mask):\n",
    "    return edge_attr[edge_mask, :]\n",
    "\n",
    "\n",
    "class GCL(RGCNConv):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_relations, nn,\n",
    "                 dropout=0.1, **kwargs):\n",
    "        super().__init__(in_channels=in_channels, out_channels=out_channels,\n",
    "                         num_relations=num_relations, **kwargs)\n",
    "        self.nn = nn\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.reset_edge_nn()\n",
    "\n",
    "    def reset_edge_nn(self):\n",
    "        reset(self.nn)\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None,\n",
    "                edge_attr: OptTensor = None):\n",
    "        # print(f\"Before processing: x shape: {x.shape}, edge_index shape: {edge_index.shape}, edge_type shape: {edge_type.shape}, edge_attr shape: {edge_attr.shape}\")\n",
    "        # Convert input features to a pair of node features or node indices.\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor):\n",
    "            edge_type = edge_index.storage.value()\n",
    "        assert edge_type is not None\n",
    "\n",
    "        # propagate_type: (x: Tensor)\n",
    "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
    "        weight = self.weight\n",
    "\n",
    "        # Basis-decomposition\n",
    "        if self.num_bases is not None:\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        # Block-diagonal-decomposition\n",
    "        if self.num_blocks is not None:\n",
    "\n",
    "            if x_l.dtype == torch.long and self.num_blocks is not None:\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                h = self.propagate(tmp, x=x_l, size=size)\n",
    "                h = h.view(-1, weight.size(1), weight.size(2))\n",
    "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
    "                out += h.contiguous().view(-1, self.out_channels)\n",
    "\n",
    "        else:\n",
    "            # No regularization/Basis-decomposition\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                attr = masked_edge_attr(edge_attr, edge_type == i)\n",
    "\n",
    "                if x_l.dtype == torch.long:\n",
    "                    out += self.propagate(tmp, x=weight[i, x_l], size=size)\n",
    "                else:\n",
    "                    h = self.propagate(tmp, x=x_l, size=size,\n",
    "                                       edge_attr=attr)\n",
    "                    out = out + (h @ weight[i])\n",
    "\n",
    "        root = self.root\n",
    "        if root is not None:\n",
    "            out += root[x_r] if x_r.dtype == torch.long else x_r @ root\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        # print(f\"After processing: Output shape: {out.shape}\")\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "\n",
    "        # Use edge nn to compute weight tensor from edge attributes\n",
    "        # (=onehot timestep distances between nodes)\n",
    "        # print(f\"Message: x_j shape: {x_j.shape}, edge_attr shape: {edge_attr.shape}\")\n",
    "        weights = self.nn(edge_attr)\n",
    "        weights = weights[..., :self.in_channels_l]\n",
    "        weights = weights.view(-1, self.in_channels_l)\n",
    "\n",
    "        out = x_j * weights\n",
    "        # print(f\"Message output shape: {out.shape}\")\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=256, hidden_dim=256, output_dim=256,\n",
    "                 num_layers=2, activation=True, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        if num_layers == 1:\n",
    "            self.layers.append(nn.Linear(input_dim, output_dim))\n",
    "        else:\n",
    "            # Input layer (1) + Intermediate layers (n-2) + Output layer (1)\n",
    "            self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            for _ in range(num_layers - 2):\n",
    "                self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.activation = activation\n",
    "        self.p = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.dropout(x, p=self.p, training=self.training)\n",
    "            x = layer(x)\n",
    "            if self.activation:\n",
    "                x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=256, hidden_dim=256, n_layers=3,\n",
    "                 num_relations=3, num_dists=32, batch_norm=False, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norm_layers = nn.ModuleList()\n",
    "        edge_nn = nn.Linear(num_dists, input_dim)\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        self.layers.append(GCL(input_dim, hidden_dim, num_relations, edge_nn))\n",
    "        if self.batch_norm:\n",
    "            self.norm_layers.append(BatchNorm(hidden_dim))\n",
    "\n",
    "        for i in range(n_layers-1):\n",
    "            self.layers.append(GCL(hidden_dim, hidden_dim,\n",
    "                                   num_relations, edge_nn))\n",
    "            if self.batch_norm:\n",
    "                self.norm_layers.append(BatchNorm(hidden_dim))\n",
    "\n",
    "        self.p = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        # print(type(edge_attr))\n",
    "        edge_type = edge_attr[:, 0]\n",
    "        edge_attr = edge_attr[:, 1:]\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            # print(f\"Layer {i}: Input shape: {x.shape}\")\n",
    "            residual = x\n",
    "            x = F.dropout(x, p=self.p, training=self.training)\n",
    "            x = self.layers[i](x, edge_index, edge_type, edge_attr)\n",
    "\n",
    "            if self.batch_norm:\n",
    "                x = self.norm_layers[i](x)\n",
    "\n",
    "            x = F.relu(x)\n",
    "            x = residual + x\n",
    "            # print(f\"Layer {i}: Output shape: {x.shape}\")\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim=64, dense_dim=64, batch_norm=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        if batch_norm:\n",
    "            self.conv = nn.Sequential(\n",
    "                # From (4 x 32) to (8 x 4 x 32)\n",
    "                nn.Conv2d(1, 8, 3, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                # From (8 x 4 x 32) to (8 x 4 x 8)\n",
    "                nn.MaxPool2d((1, 4), stride=(1, 4)),\n",
    "                # From (8 x 4 x 8) to (16 x 4 x 8)\n",
    "                nn.Conv2d(8, 16, 3, padding=1),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(1, 8, 3, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d((1, 4), stride=(1, 4)),\n",
    "                nn.Conv2d(8, 16, 3, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        # Linear layers\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(16 * 4 * 8, dense_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=64, dense_dim=64, batch_norm=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear decompressors\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_dim, dense_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_dim, 16 * 4 * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(16, 4, 8))\n",
    "\n",
    "        # Upsample and convolutional layers\n",
    "        if batch_norm:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1, 4), mode='nearest'),\n",
    "                nn.Conv2d(16, 8, 3, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 1, 3, padding=1)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1, 4), mode='nearest'),\n",
    "                nn.Conv2d(16, 8, 3, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 1, 3, padding=1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.conv(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ContentEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        #self.device = device  # Store the device as an instance variable\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        # Pitch and duration embedding layers (separate layers for drums\n",
    "        # and non drums)\n",
    "        self.non_drums_pitch_emb = nn.Linear(N_PITCH_TOKENS, \n",
    "                                             self.d//2)\n",
    "        self.drums_pitch_emb = nn.Linear(N_PITCH_TOKENS, self.d//2)\n",
    "        self.dur_emb = nn.Linear(N_DUR_TOKENS, self.d//2)\n",
    "\n",
    "        # Batch norm layers\n",
    "        self.bn_non_drums = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        self.bn_drums = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        self.bn_dur = nn.BatchNorm1d(num_features=self.d//2)\n",
    "\n",
    "        self.chord_encoder = nn.Linear(\n",
    "            self.d * (MAX_SIMU_TOKENS-1), self.d)\n",
    "\n",
    "        self.graph_encoder = GCN(\n",
    "            dropout=self.dropout,\n",
    "            input_dim=self.d,\n",
    "            hidden_dim=self.d,\n",
    "            n_layers=self.gnn_n_layers,\n",
    "            num_relations=N_EDGE_TYPES,\n",
    "            batch_norm=self.batch_norm\n",
    "        )\n",
    "\n",
    "        # Soft attention node-aggregation layer\n",
    "        gate_nn = nn.Sequential(\n",
    "            MLP(input_dim=self.d, output_dim=1, num_layers=1,\n",
    "                activation=False, dropout=self.dropout),\n",
    "            nn.BatchNorm1d(1)\n",
    "        )\n",
    "        self.graph_attention = GlobalAttention(gate_nn)\n",
    "\n",
    "        self.bars_encoder = nn.Linear(self.n_bars * self.d, self.d)\n",
    "    \n",
    "    def forward(self, graph):\n",
    "        c_tensor = graph.c_tensor\n",
    "\n",
    "        # Discard SOS token\n",
    "        c_tensor = c_tensor[:, 1:, :]\n",
    "\n",
    "        # Get drums and non drums tensors\n",
    "        drums = c_tensor[graph.is_drum]\n",
    "        non_drums = c_tensor[torch.logical_not(graph.is_drum)]\n",
    "\n",
    "        # Compute drums embeddings\n",
    "        sz = drums.size()\n",
    "        drums_pitch = self.drums_pitch_emb(\n",
    "            drums[..., :N_PITCH_TOKENS])\n",
    "        drums_pitch = self.bn_drums(drums_pitch.view(-1, self.d//2))\n",
    "        drums_pitch = drums_pitch.view(sz[0], sz[1], self.d//2)\n",
    "        drums_dur = self.dur_emb(drums[..., N_PITCH_TOKENS:])\n",
    "        drums_dur = self.bn_dur(drums_dur.view(-1, self.d//2))\n",
    "        drums_dur = drums_dur.view(sz[0], sz[1], self.d//2)\n",
    "        drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        # n_nodes x MAX_SIMU_TOKENS x d\n",
    "\n",
    "        # Compute non drums embeddings\n",
    "        sz = non_drums.size()\n",
    "        non_drums_pitch = self.non_drums_pitch_emb(\n",
    "            non_drums[..., :N_PITCH_TOKENS]\n",
    "        )\n",
    "        non_drums_pitch = self.bn_non_drums(non_drums_pitch.view(-1, self.d//2))\n",
    "        non_drums_pitch = non_drums_pitch.view(sz[0], sz[1], self.d//2)\n",
    "        non_drums_dur = self.dur_emb(non_drums[..., N_PITCH_TOKENS:])\n",
    "        non_drums_dur = self.bn_dur(non_drums_dur.view(-1, self.d//2))\n",
    "        non_drums_dur = non_drums_dur.view(sz[0], sz[1], self.d//2)\n",
    "        non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        # n_nodes x MAX_SIMU_TOKENS x d\n",
    "\n",
    "        # Compute chord embeddings (drums and non drums)\n",
    "        drums = self.chord_encoder(\n",
    "            drums.view(-1, self.d * (MAX_SIMU_TOKENS-1))\n",
    "        )\n",
    "        non_drums = self.chord_encoder(\n",
    "            non_drums.view(-1, self.d * (MAX_SIMU_TOKENS-1))\n",
    "        )\n",
    "        drums = F.relu(drums)\n",
    "        non_drums = F.relu(non_drums)\n",
    "        drums = self.dropout_layer(drums)\n",
    "        non_drums = self.dropout_layer(non_drums)\n",
    "        # n_nodes x d\n",
    "\n",
    "        # Merge drums and non drums\n",
    "        out = torch.zeros((c_tensor.size(0), self.d), device=self.device,\n",
    "                          dtype=drums.dtype)\n",
    "        out[graph.is_drum] = drums\n",
    "        out[torch.logical_not(graph.is_drum)] = non_drums\n",
    "        # n_nodes x d\n",
    "\n",
    "        # Set initial graph node states to intermediate chord representations \n",
    "        # and pass through GCN\n",
    "        graph.x = out\n",
    "        graph.distinct_bars = graph.bars + self.n_bars*graph.batch\n",
    "        out = self.graph_encoder(graph)\n",
    "        # n_nodes x d\n",
    "\n",
    "        # Aggregate final node states into bar encodings with soft attention\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            out = self.graph_attention(out, batch=graph.distinct_bars)\n",
    "        # bs x n_bars x d\n",
    "\n",
    "        out = out.view(-1, self.n_bars * self.d)\n",
    "        # bs x (n_bars*d)\n",
    "        z_c = self.bars_encoder(out)\n",
    "        # bs x d\n",
    "        \n",
    "        return z_c\n",
    "\n",
    "\n",
    "class StructureEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.cnn_encoder = CNNEncoder(\n",
    "            dense_dim=self.d,\n",
    "            output_dim=self.d,\n",
    "            dropout=self.dropout,\n",
    "            batch_norm=self.batch_norm\n",
    "        )\n",
    "        self.bars_encoder = nn.Linear(self.n_bars * self.d, self.d)\n",
    "        # self.bars_encoder = nn.Linear(self.d, self.d)\n",
    "    \n",
    "    def forward(self, graph):\n",
    "        s_tensor = graph.s_tensor\n",
    "        # print(f\"Initial s_tensor shape: {s_tensor.shape}\")  # Initial shape: [bs, N_TRACKS, feature_dim]\n",
    "\n",
    "        # Adjust the reshaping for CNN input\n",
    "        # We assume feature_dim is the total dimension for each track, needing to be reshaped\n",
    "        # to fit CNN expectations. If your CNN expects [batch_size, channels, height, width],\n",
    "        # and here you interpret N_TRACKS as channels, your reshaping needs to reflect this.\n",
    "        s_tensor_reshaped = s_tensor.view(-1, N_TRACKS , self.resolution* 4 )  # Reshape to include a channel dimension\n",
    "\n",
    "        # Feed into CNN, the expected shape might need to adjust based on CNN's expected input dimensions\n",
    "        out = self.cnn_encoder(s_tensor_reshaped)\n",
    "        # print(f\"After CNN encoder, out shape: {out.shape}\")  # Check CNN output shape\n",
    "\n",
    "        # Correct the reshaping to re-establish batch dimension\n",
    "        out = out.view(-1, self.n_bars * self.d)  # Reshape to [bs, n_bars * d]\n",
    "        # print(f\"After view, out shape: {out.shape}\")\n",
    "        # print(f\"Shape before linear layer: {out.shape}\")\n",
    "        z_s = self.bars_encoder(out)\n",
    "        # print(f\"Final z_s shape: {z_s.shape}\")  # Expect [bs, d]\n",
    "\n",
    "        return z_s\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.s_encoder = StructureEncoder(**kwargs)\n",
    "        self.c_encoder = ContentEncoder(**kwargs)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        # Linear layer that merges content and structure representations\n",
    "        self.linear_merge = nn.Linear(2*self.d, self.d)\n",
    "        self.bn_linear_merge = nn.BatchNorm1d(num_features=self.d)\n",
    "\n",
    "        self.linear_mu = nn.Linear(self.d, self.d)\n",
    "        self.linear_log_var = nn.Linear(self.d, self.d)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \n",
    "        z_s = self.s_encoder(graph)\n",
    "        z_c = self.c_encoder(graph)\n",
    "        \n",
    "        # Merge content and structure representations\n",
    "        # print(f\"z_c shape: {z_c.shape}\")\n",
    "        # print(f\"z_s shape: {z_s.shape}\")\n",
    "        z_g = torch.cat((z_c, z_s), dim=1)\n",
    "        z_g = self.dropout_layer(z_g)\n",
    "        z_g = self.linear_merge(z_g)\n",
    "        z_g = self.bn_linear_merge(z_g)\n",
    "        z_g = F.relu(z_g)\n",
    "\n",
    "        # Compute mu and log(std^2)\n",
    "        z_g = self.dropout_layer(z_g)\n",
    "        mu = self.linear_mu(z_g)\n",
    "        log_var = self.linear_log_var(z_g)\n",
    "\n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class StructureDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.bars_decoder = nn.Linear(self.d, self.d * self.n_bars)\n",
    "        #self.bars_decoder = nn.Linear(self.d, self.d)\n",
    "        self.cnn_decoder = CNNDecoder(\n",
    "            input_dim=self.d,\n",
    "            dense_dim=self.d,\n",
    "            dropout=self.dropout,\n",
    "            batch_norm=self.batch_norm\n",
    "        )\n",
    "\n",
    "    def forward(self, z_s):\n",
    "        # z_s: bs x d\n",
    "        out = self.bars_decoder(z_s)  # bs x (n_bars*d)\n",
    "        # out = self.cnn_decoder(out)\n",
    "        out = self.cnn_decoder(out.reshape(-1, self.d))\n",
    "        out = out.view(z_s.size(0), self.n_bars, N_TRACKS, -1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ContentDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.bars_decoder = nn.Linear(self.d, self.d * self.n_bars)\n",
    "\n",
    "        self.graph_decoder = GCN(\n",
    "            dropout=self.dropout,\n",
    "            input_dim=self.d,\n",
    "            hidden_dim=self.d,\n",
    "            n_layers=self.gnn_n_layers,\n",
    "            num_relations=N_EDGE_TYPES,\n",
    "            batch_norm=self.batch_norm\n",
    "        )\n",
    "\n",
    "        self.chord_decoder = nn.Linear(\n",
    "            self.d, self.d*(MAX_SIMU_TOKENS-1))\n",
    "\n",
    "        # Pitch and duration (un)embedding linear layers\n",
    "        self.drums_pitch_emb = nn.Linear(self.d//2, N_PITCH_TOKENS)\n",
    "        self.non_drums_pitch_emb = nn.Linear(\n",
    "            self.d//2, N_PITCH_TOKENS)\n",
    "        self.dur_emb = nn.Linear(self.d//2, N_DUR_TOKENS)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "    def forward(self, z_c, s):\n",
    "\n",
    "        out = self.bars_decoder(z_c)  # bs x (n_bars*d)\n",
    "\n",
    "        # Initialize node features with corresponding z_bar\n",
    "        # and propagate with GNN\n",
    "        s.distinct_bars = s.bars + self.n_bars*s.batch\n",
    "        _, counts = torch.unique(s.distinct_bars, return_counts=True)\n",
    "        out = out.view(-1, self.d)\n",
    "        out = torch.repeat_interleave(out, counts, axis=0)  # n_nodes x d\n",
    "        s.x = out\n",
    "        out = self.graph_decoder(s)  # n_nodes x d\n",
    "\n",
    "        out = self.chord_decoder(out)  # n_nodes x (MAX_SIMU_TOKENS*d)\n",
    "        out = out.view(-1, MAX_SIMU_TOKENS-1, self.d)\n",
    "\n",
    "        drums = out[s.is_drum]  # n_nodes_drums x MAX_SIMU_TOKENS x d\n",
    "        non_drums = out[torch.logical_not(s.is_drum)]\n",
    "        # n_nodes_non_drums x MAX_SIMU_TOKENS x d\n",
    "\n",
    "        # Obtain final pitch and dur logits (softmax will be applied\n",
    "        # outside forward)\n",
    "        non_drums = self.dropout_layer(non_drums)\n",
    "        drums = self.dropout_layer(drums)\n",
    "\n",
    "        drums_pitch = self.drums_pitch_emb(drums[..., :self.d//2])\n",
    "        drums_dur = self.dur_emb(drums[..., self.d//2:])\n",
    "        drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        # n_nodes_drums x MAX_SIMU_TOKENS x d_token\n",
    "\n",
    "        non_drums_pitch = self.non_drums_pitch_emb(non_drums[..., :self.d//2])\n",
    "        non_drums_dur = self.dur_emb(non_drums[..., self.d//2:])\n",
    "        non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        # n_nodes_non_drums x MAX_SIMU_TOKENS x d_token\n",
    "\n",
    "        # Merge drums and non-drums in the final output tensor\n",
    "        d_token = D_TOKEN_PAIR\n",
    "        out = torch.zeros((s.num_nodes, MAX_SIMU_TOKENS-1, d_token),\n",
    "                          device=self.device, dtype=drums.dtype)\n",
    "        out[s.is_drum] = drums\n",
    "        out[torch.logical_not(s.is_drum)] = non_drums\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.lin_decoder = nn.Linear(self.d, 2 * self.d)\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=2*self.d)\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        self.s_decoder = StructureDecoder(**kwargs)\n",
    "        self.c_decoder = ContentDecoder(**kwargs)\n",
    "\n",
    "        self.sigmoid_thresh = 0.5\n",
    "\n",
    "    def _structure_from_binary(self, s_tensor):\n",
    "\n",
    "        # Create graph structures for each batch\n",
    "        s = []\n",
    "        for i in range(s_tensor.size(0)):\n",
    "            s.append(graph_from_tensor(s_tensor[i]))\n",
    "\n",
    "        # Create batch of graphs from single graphs\n",
    "        s = Batch.from_data_list(s, exclude_keys=['batch'])\n",
    "        s = s.to(next(self.parameters()).device)\n",
    "\n",
    "        return s\n",
    "\n",
    "    def _binary_from_logits(self, s_logits):\n",
    "\n",
    "        # Hard threshold instead of sampling gives more pleasant results\n",
    "        s_tensor = torch.sigmoid(s_logits)\n",
    "        s_tensor[s_tensor >= self.sigmoid_thresh] = 1\n",
    "        s_tensor[s_tensor < self.sigmoid_thresh] = 0\n",
    "        s_tensor = s_tensor.bool()\n",
    "        \n",
    "        # Avoid empty bars by creating a fake activation for each empty\n",
    "        # (n_tracks x n_timesteps) bar matrix in position [0, 0]\n",
    "        empty_mask = ~s_tensor.any(dim=-1).any(dim=-1)\n",
    "        idxs = torch.nonzero(empty_mask, as_tuple=True)\n",
    "        s_tensor[idxs + (0, 0)] = True\n",
    "\n",
    "        return s_tensor\n",
    "\n",
    "    def _structure_from_logits(self, s_logits):\n",
    "\n",
    "        # Compute binary structure tensor from logits and build torch geometric\n",
    "        # structure from binary tensor\n",
    "        s_tensor = self._binary_from_logits(s_logits)\n",
    "        s = self._structure_from_binary(s_tensor)\n",
    "\n",
    "        return s\n",
    "\n",
    "    def forward(self, z, s=None):\n",
    "\n",
    "        # Obtain z_s and z_c from z\n",
    "        z = self.lin_decoder(z)\n",
    "        z = self.batch_norm(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.dropout(z)  # bs x (2*d)\n",
    "        z_s, z_c = z[:, :self.d], z[:, self.d:]\n",
    "\n",
    "        # Obtain the tensor containing structure logits\n",
    "        s_logits = self.s_decoder(z_s)\n",
    "\n",
    "        if s is None:\n",
    "            # Build torch geometric graph structure from structure logits.\n",
    "            # This step involves non differentiable operations.\n",
    "            # No gradients pass through here.\n",
    "            s = self._structure_from_logits(s_logits.detach())\n",
    "\n",
    "        # Obtain the tensor containing content logits\n",
    "        c_logits = self.c_decoder(z_c, s)\n",
    "\n",
    "        return s_logits, c_logits\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(**kwargs)\n",
    "        self.decoder = Decoder(**kwargs)\n",
    "\n",
    "    def forward(self, graph):\n",
    "\n",
    "        # Encoder pass\n",
    "        mu, log_var = self.encoder(graph)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        z = torch.exp(0.5 * log_var)\n",
    "        z = z * torch.randn_like(z)\n",
    "        z = z + mu\n",
    "\n",
    "        # Decoder pass\n",
    "        out = self.decoder(z, graph)\n",
    "\n",
    "        return out, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchToken(Enum):\n",
    "    SOS = 128\n",
    "    EOS = 129\n",
    "    PAD = 130\n",
    "\n",
    "\n",
    "N_PITCH_TOKENS = 131\n",
    "MAX_PITCH_TOKEN = 127\n",
    "\n",
    "\n",
    "# Duration tokens have values in the range [0, 98]. Tokens from 0 to 95 have to\n",
    "# be interpreted as durations from 1 to 96 timesteps.\n",
    "class DurationToken(Enum):\n",
    "    SOS = 96\n",
    "    EOS = 97\n",
    "    PAD = 98\n",
    "    \n",
    "def append_dict(dest_d, source_d):\n",
    "\n",
    "    for k, v in source_d.items():\n",
    "        dest_d[k].append(v)\n",
    "\n",
    "def print_divider():\n",
    "    print('' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from statistics import mean\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "import pprint\n",
    "import math\n",
    "\n",
    "#import constants\n",
    "#from constants import PitchToken, DurationToken\n",
    "#from utils import append_dict, print_divider\n",
    "\n",
    "\n",
    "class StepBetaScheduler():\n",
    "    def __init__(self, anneal_start, beta_max, step_size, anneal_end):\n",
    "        self.anneal_start = anneal_start\n",
    "        self.beta_max = beta_max\n",
    "        self.step_size = step_size\n",
    "        self.anneal_end = anneal_end\n",
    "\n",
    "        self.update_steps = 0\n",
    "        self.beta = 0\n",
    "        n_steps = self.beta_max // self.step_size\n",
    "        self.inc_every = (self.anneal_end-self.anneal_start) // n_steps\n",
    "\n",
    "    def step(self):\n",
    "        self.update_steps += 1\n",
    "\n",
    "        if (self.update_steps >= self.anneal_start or\n",
    "                self.update_steps < self.anneal_end):\n",
    "            # If we are annealing, update beta according to current step\n",
    "            curr_step = (self.update_steps-self.anneal_start) // self.inc_every\n",
    "            self.beta = self.step_size * (curr_step+1)\n",
    "            \n",
    "        return self.beta\n",
    "\n",
    "\n",
    "class ExpDecayLRScheduler():\n",
    "    def __init__(self, optimizer, peak_lr, warmup_steps, final_lr_scale,\n",
    "                 decay_steps):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.peak_lr = peak_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_steps = decay_steps\n",
    "\n",
    "        # Find the decay factor needed to reach the specified\n",
    "        # learning rate scale after decay_steps steps\n",
    "        self.decay_factor = -math.log(final_lr_scale) / self.decay_steps\n",
    "\n",
    "        self.update_steps = 0\n",
    "\n",
    "    def set_lr(self, optimizer, lr):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def step(self):\n",
    "        self.update_steps += 1\n",
    "\n",
    "        if self.update_steps <= self.warmup_steps:\n",
    "            self.lr = self.peak_lr\n",
    "        else:\n",
    "            # Decay lr exponentially\n",
    "            steps_after_warmup = self.update_steps - self. warmup_steps\n",
    "            self.lr = \\\n",
    "                self.peak_lr * math.exp(-self.decay_factor*steps_after_warmup)\n",
    "\n",
    "        self.set_lr(self.optimizer, self.lr)\n",
    "\n",
    "        return self.lr\n",
    "\n",
    "\n",
    "class PolyphemusTrainer():\n",
    "\n",
    "    def __init__(self, model_dir, model, optimizer, init_lr=1e-4,\n",
    "                 lr_scheduler=None, beta_scheduler=None, device=None, \n",
    "                 print_every=1, save_every=1, eval_every=100, \n",
    "                 iters_to_accumulate=1, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.model_dir = model_dir\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.beta_scheduler = beta_scheduler\n",
    "        self.device = device if device is not None else torch.device(\"cpu\")\n",
    "        self.cuda = True if self.device.type == 'cuda' else False\n",
    "        self.print_every = print_every\n",
    "        self.save_every = save_every\n",
    "        self.eval_every = eval_every\n",
    "        self.iters_to_accumulate = iters_to_accumulate\n",
    "\n",
    "        # Losses (ignoring PAD tokens)\n",
    "        self.bce_unreduced = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.ce_p = nn.CrossEntropyLoss(ignore_index=PitchToken.PAD.value)\n",
    "        self.ce_d = nn.CrossEntropyLoss(ignore_index=DurationToken.PAD.value)\n",
    "\n",
    "        # Training stats\n",
    "        self.tr_losses = defaultdict(list)\n",
    "        self.tr_accuracies = defaultdict(list)\n",
    "        self.val_losses = defaultdict(list)\n",
    "        self.val_accuracies = defaultdict(list)\n",
    "        self.lrs = []\n",
    "        self.betas = []\n",
    "        self.times = []\n",
    "\n",
    "    def train(self, trainloader, validloader=None, epochs=100, early_exit=None):\n",
    "\n",
    "        self.tot_batches = 0\n",
    "        self.beta = 0\n",
    "        self.min_val_loss = np.inf\n",
    "\n",
    "        start = time.time()\n",
    "        self.times.append(start)\n",
    "\n",
    "        self.model.train()\n",
    "        scaler = torch.cuda.amp.GradScaler() if self.cuda else None\n",
    "        self.optimizer.zero_grad()\n",
    "        progress_bar = tqdm(range(len(trainloader)))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.cur_epoch = epoch\n",
    "            for batch_idx, graph in enumerate(trainloader):\n",
    "                self.cur_batch_idx = batch_idx\n",
    "\n",
    "                # Move batch of graphs to device. Note: a single graph here\n",
    "                # represents a bar in the original sequence.\n",
    "                graph = graph.to(self.device)\n",
    "                s_tensor, c_tensor = graph.s_tensor, graph.c_tensor\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=self.cuda):\n",
    "                    # Forward pass to obtain mu, log(sigma^2), computed by the\n",
    "                    # encoder, and structure and content logits, computed by the\n",
    "                    # decoder\n",
    "                    (s_logits, c_logits), mu, log_var = self.model(graph)\n",
    "\n",
    "                    # Compute losses\n",
    "                    tot_loss, losses = self._losses(\n",
    "                        s_tensor, s_logits,\n",
    "                        c_tensor, c_logits,\n",
    "                        mu, log_var\n",
    "                    )\n",
    "                    tot_loss = tot_loss / self.iters_to_accumulate\n",
    "\n",
    "                # Backpropagation\n",
    "                if self.cuda:\n",
    "                    scaler.scale(tot_loss).backward()\n",
    "                else:\n",
    "                    tot_loss.backward()\n",
    "\n",
    "                # Update weights with accumulated gradients\n",
    "                if (self.tot_batches + 1) % self.iters_to_accumulate == 0:\n",
    "\n",
    "                    if self.cuda:\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        self.optimizer.step()\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    # Update lr and beta\n",
    "                    if self.lr_scheduler is not None:\n",
    "                        self.lr_scheduler.step()\n",
    "                    if self.beta_scheduler is not None:\n",
    "                        self.beta_scheduler.step()\n",
    "\n",
    "                # Compute accuracies\n",
    "                accs = self._accuracies(\n",
    "                    s_tensor, s_logits,\n",
    "                    c_tensor, c_logits,\n",
    "                    graph.is_drum\n",
    "                )\n",
    "\n",
    "                # Update the stats\n",
    "                append_dict(self.tr_losses, losses)\n",
    "                append_dict(self.tr_accuracies, accs)\n",
    "                last_lr = (self.lr_scheduler.lr\n",
    "                           if self.lr_scheduler is not None else self.init_lr)\n",
    "                self.lrs.append(last_lr)\n",
    "                self.betas.append(self.beta)\n",
    "                now = time.time()\n",
    "                self.times.append(now)\n",
    "\n",
    "                # Print stats\n",
    "                if (self.tot_batches + 1) % self.print_every == 0:\n",
    "                    print(\"Training on batch {}/{} of epoch {}/{} complete.\"\n",
    "                          .format(batch_idx+1,\n",
    "                                  len(trainloader),\n",
    "                                  epoch+1,\n",
    "                                  epochs))\n",
    "                    self._print_stats()\n",
    "                    print_divider()\n",
    "\n",
    "                # Eval on VL every `eval_every` gradient updates\n",
    "                if (validloader is not None and\n",
    "                        (self.tot_batches + 1) % self.eval_every == 0):\n",
    "\n",
    "                    # Evaluate on VL\n",
    "                    print(\"\\nEvaluating on validation set...\\n\")\n",
    "                    val_losses, val_accuracies = self.evaluate(validloader)\n",
    "\n",
    "                    # Update stats\n",
    "                    append_dict(self.val_losses, val_losses)\n",
    "                    append_dict(self.val_accuracies, val_accuracies)\n",
    "\n",
    "                    print(\"Val losses:\")\n",
    "                    print(val_losses)\n",
    "                    print(\"Val accuracies:\")\n",
    "                    print(val_accuracies)\n",
    "\n",
    "                    # Save model if VL loss (tot) reached a new minimum\n",
    "                    # Example check before accessing 'tot'\n",
    "                    if 'tot' in val_losses:\n",
    "                        tot_loss = val_losses['tot']\n",
    "                    else:\n",
    "                        # Handle the missing key, e.g., set a default value or raise a more informative error\n",
    "                        tot_loss = 0  # or some default value\n",
    "                        print(\"Key 'tot' not found in val_losses. Setting tot_loss to 0.\")\n",
    "\n",
    "                    if tot_loss < self.min_val_loss:\n",
    "                        print(\"\\nValidation loss improved.\")\n",
    "                        print(\"Saving new best model to disk...\\n\")\n",
    "                        self._save_model('best_model')\n",
    "                        self.min_val_loss = tot_loss\n",
    "\n",
    "                    self.model.train()\n",
    "\n",
    "                progress_bar.update(1)\n",
    "\n",
    "                # Save model and stats on disk\n",
    "                if (self.save_every > 0 and\n",
    "                        (self.tot_batches + 1) % self.save_every == 0):\n",
    "                    self._save_model('checkpoint')\n",
    "\n",
    "                # Stop prematurely if early_exit is set and reached\n",
    "                if (early_exit is not None and\n",
    "                        (self.tot_batches + 1) > early_exit):\n",
    "                    break\n",
    "\n",
    "                self.tot_batches += 1\n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Training completed in (h:m:s): {:0>2}:{:0>2}:{:05.2f}\"\n",
    "              .format(int(hours), int(minutes), seconds))\n",
    "\n",
    "        self._save_model('checkpoint')\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        print(f\"Starting evaluation with {len(loader)} batches...\")\n",
    "        losses = defaultdict(list)\n",
    "        accs = defaultdict(list)\n",
    "\n",
    "        self.model.eval()\n",
    "        progress_bar = tqdm(range(len(loader)))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _, graph in enumerate(loader):\n",
    "\n",
    "                # Get the inputs and move them to device\n",
    "                graph = graph.to(self.device)\n",
    "                s_tensor, c_tensor = graph.s_tensor, graph.c_tensor\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # Forward pass, get the reconstructions\n",
    "                    (s_logits, c_logits), mu, log_var = self.model(graph)\n",
    "\n",
    "                    _, losses_b = self._losses(\n",
    "                        s_tensor, s_logits,\n",
    "                        c_tensor, c_logits,\n",
    "                        mu, log_var\n",
    "                    )\n",
    "\n",
    "                accs_b = self._accuracies(\n",
    "                    s_tensor, s_logits,\n",
    "                    c_tensor, c_logits,\n",
    "                    graph.is_drum\n",
    "                )\n",
    "\n",
    "                # Save losses and accuracies\n",
    "                append_dict(losses, losses_b)\n",
    "                append_dict(accs, accs_b)\n",
    "\n",
    "                progress_bar.update(1)\n",
    "\n",
    "        # Compute avg losses and accuracies\n",
    "        avg_losses = {}\n",
    "        for k, l in losses.items():\n",
    "            avg_losses[k] = mean(l)\n",
    "\n",
    "        avg_accs = {}\n",
    "        for k, l in accs.items():\n",
    "            avg_accs[k] = mean(l)\n",
    "\n",
    "        return avg_losses, avg_accs\n",
    "\n",
    "    def _losses(self, s_tensor, s_logits, c_tensor, c_logits, mu, log_var):\n",
    "\n",
    "        # Do not consider SOS token\n",
    "        c_tensor = c_tensor[..., 1:, :]\n",
    "        c_logits = c_logits.reshape(-1, c_logits.size(-1))\n",
    "        c_tensor = c_tensor.reshape(-1, c_tensor.size(-1))\n",
    "\n",
    "        # Reshape logits to match s_tensor dimensions:\n",
    "        # n_graphs (in batch) x n_tracks x n_timesteps\n",
    "        s_logits = s_tensor.reshape(-1, *s_logits.shape[2:])\n",
    "\n",
    "        # Binary structure tensor loss (binary cross entropy)\n",
    "        s_loss = self.bce_unreduced(\n",
    "            s_logits.view(-1), s_tensor.view(-1).float())\n",
    "        s_loss = torch.mean(s_loss)\n",
    "\n",
    "        # Content tensor loss (pitches)\n",
    "        # argmax is used to obtain token ids from onehot rep\n",
    "        pitch_logits = c_logits[:, :N_PITCH_TOKENS]\n",
    "        pitch_true = c_tensor[:, :N_PITCH_TOKENS].argmax(dim=1)\n",
    "        pitch_loss = self.ce_p(pitch_logits, pitch_true)\n",
    "\n",
    "        # Content tensor loss (durations)\n",
    "        dur_logits = c_logits[:, N_PITCH_TOKENS:]\n",
    "        dur_true = c_tensor[:, N_PITCH_TOKENS:].argmax(dim=1)\n",
    "        dur_loss = self.ce_d(dur_logits, dur_true)\n",
    "\n",
    "        # Kullback-Leibler divergence loss\n",
    "        # Derivation in Kingma, Diederik P., and Max Welling. \"Auto-encoding\n",
    "        # variational bayes.\" (2013), Appendix B.\n",
    "        # (https://arxiv.org/pdf/1312.6114.pdf)\n",
    "        kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(),\n",
    "                                    dim=1)\n",
    "        kld_loss = torch.mean(kld_loss)\n",
    "\n",
    "        # Reconstruction loss and total loss\n",
    "        rec_loss = pitch_loss + dur_loss + s_loss\n",
    "        tot_loss = rec_loss + self.beta*kld_loss\n",
    "\n",
    "        losses = {\n",
    "            'tot': tot_loss.item(),\n",
    "            'pitch': pitch_loss.item(),\n",
    "            'dur': dur_loss.item(),\n",
    "            'structure': s_loss.item(),\n",
    "            'reconstruction': rec_loss.item(),\n",
    "            'kld': kld_loss.item(),\n",
    "            'beta*kld': self.beta*kld_loss.item()\n",
    "        }\n",
    "\n",
    "        return tot_loss, losses\n",
    "\n",
    "    def _accuracies(self, s_tensor, s_logits, c_tensor, c_logits, is_drum):\n",
    "\n",
    "        # Do not consider SOS token\n",
    "        c_tensor = c_tensor[..., 1:, :]\n",
    "\n",
    "        # Reshape logits to match s_tensor dimensions:\n",
    "        # n_graphs (in batch) x n_tracks x n_timesteps\n",
    "        s_logits = s_tensor.reshape(-1, *s_logits.shape[2:])\n",
    "\n",
    "        # Note accuracy considers both pitches and durations\n",
    "        note_acc = self._note_accuracy(c_logits, c_tensor)\n",
    "\n",
    "        pitch_acc = self._pitch_accuracy(c_logits, c_tensor)\n",
    "\n",
    "        # Compute pitch accuracies for drums and non drums separately\n",
    "        pitch_acc_drums = self._pitch_accuracy(\n",
    "            c_logits, c_tensor, drums=True, is_drum=is_drum\n",
    "        )\n",
    "        pitch_acc_non_drums = self._pitch_accuracy(\n",
    "            c_logits, c_tensor, drums=False, is_drum=is_drum\n",
    "        )\n",
    "\n",
    "        dur_acc = self._duration_accuracy(c_logits, c_tensor)\n",
    "\n",
    "        s_acc = self._structure_accuracy(s_logits, s_tensor)\n",
    "        s_precision = self._structure_precision(s_logits, s_tensor)\n",
    "        s_recall = self._structure_recall(s_logits, s_tensor)\n",
    "        s_f1 = (2*s_recall*s_precision / (s_recall+s_precision))\n",
    "\n",
    "        accs = {\n",
    "            'note': note_acc.item(),\n",
    "            'pitch': pitch_acc.item(),\n",
    "            'pitch_drums': pitch_acc_drums.item(),\n",
    "            'pitch_non_drums': pitch_acc_non_drums.item(),\n",
    "            'dur': dur_acc.item(),\n",
    "            's_acc': s_acc.item(),\n",
    "            's_precision': s_precision.item(),\n",
    "            's_recall': s_recall.item(),\n",
    "            's_f1': s_f1.item()\n",
    "        }\n",
    "\n",
    "        return accs\n",
    "\n",
    "    def _pitch_accuracy(self, c_logits, c_tensor, drums=None, is_drum=None):\n",
    "\n",
    "        # When drums is None, just compute the global pitch accuracy without\n",
    "        # distinguishing between drum and non drum pitches\n",
    "        if drums is not None:\n",
    "            if drums:\n",
    "                c_logits = c_logits[is_drum]\n",
    "                c_tensor = c_tensor[is_drum]\n",
    "            else:\n",
    "                c_logits = c_logits[torch.logical_not(is_drum)]\n",
    "                c_tensor = c_tensor[torch.logical_not(is_drum)]\n",
    "\n",
    "        # Apply softmax to obtain pitch reconstructions\n",
    "        pitch_rec = c_logits[..., :N_PITCH_TOKENS]\n",
    "        pitch_rec = F.softmax(pitch_rec, dim=-1)\n",
    "        pitch_rec = torch.argmax(pitch_rec, dim=-1)\n",
    "\n",
    "        pitch_true = c_tensor[..., :N_PITCH_TOKENS]\n",
    "        pitch_true = torch.argmax(pitch_true, dim=-1)\n",
    "\n",
    "        # Do not consider PAD tokens when computing accuracies\n",
    "        not_pad = (pitch_true != PitchToken.PAD.value)\n",
    "\n",
    "        correct = (pitch_rec == pitch_true)\n",
    "        correct = torch.logical_and(correct, not_pad)\n",
    "\n",
    "        return torch.sum(correct) / torch.sum(not_pad)\n",
    "\n",
    "    def _duration_accuracy(self, c_logits, c_tensor):\n",
    "\n",
    "        # Apply softmax to obtain reconstructed durations\n",
    "        dur_rec = c_logits[..., N_PITCH_TOKENS:]\n",
    "        dur_rec = F.softmax(dur_rec, dim=-1)\n",
    "        dur_rec = torch.argmax(dur_rec, dim=-1)\n",
    "\n",
    "        dur_true = c_tensor[..., N_PITCH_TOKENS:]\n",
    "        dur_true = torch.argmax(dur_true, dim=-1)\n",
    "\n",
    "        # Do not consider PAD tokens when computing accuracies\n",
    "        not_pad = (dur_true != DurationToken.PAD.value)\n",
    "\n",
    "        correct = (dur_rec == dur_true)\n",
    "        correct = torch.logical_and(correct, not_pad)\n",
    "\n",
    "        return torch.sum(correct) / torch.sum(not_pad)\n",
    "\n",
    "    def _note_accuracy(self, c_logits, c_tensor):\n",
    "\n",
    "        # Apply softmax to obtain pitch reconstructions\n",
    "        pitch_rec = c_logits[..., :N_PITCH_TOKENS]\n",
    "        pitch_rec = F.softmax(pitch_rec, dim=-1)\n",
    "        pitch_rec = torch.argmax(pitch_rec, dim=-1)\n",
    "\n",
    "        pitch_true = c_tensor[..., :N_PITCH_TOKENS]\n",
    "        pitch_true = torch.argmax(pitch_true, dim=-1)\n",
    "\n",
    "        not_pad_p = (pitch_true != PitchToken.PAD.value)\n",
    "\n",
    "        correct_p = (pitch_rec == pitch_true)\n",
    "        correct_p = torch.logical_and(correct_p, not_pad_p)\n",
    "\n",
    "        dur_rec = c_logits[..., N_PITCH_TOKENS:]\n",
    "        dur_rec = F.softmax(dur_rec, dim=-1)\n",
    "        dur_rec = torch.argmax(dur_rec, dim=-1)\n",
    "\n",
    "        dur_true = c_tensor[..., N_PITCH_TOKENS:]\n",
    "        dur_true = torch.argmax(dur_true, dim=-1)\n",
    "\n",
    "        not_pad_d = (dur_true != DurationToken.PAD.value)\n",
    "\n",
    "        correct_d = (dur_rec == dur_true)\n",
    "        correct_d = torch.logical_and(correct_d, not_pad_d)\n",
    "\n",
    "        note_accuracy = torch.sum(\n",
    "            torch.logical_and(correct_p, correct_d)) / torch.sum(not_pad_p)\n",
    "\n",
    "        return note_accuracy\n",
    "\n",
    "    def _structure_accuracy(self, s_logits, s_tensor):\n",
    "\n",
    "        s_logits = torch.sigmoid(s_logits)\n",
    "        s_logits[s_logits < 0.5] = 0\n",
    "        s_logits[s_logits >= 0.5] = 1\n",
    "\n",
    "        return torch.sum(s_logits == s_tensor) / s_tensor.numel()\n",
    "\n",
    "    def _structure_precision(self, s_logits, s_tensor):\n",
    "\n",
    "        s_logits = torch.sigmoid(s_logits)\n",
    "        s_logits[s_logits < 0.5] = 0\n",
    "        s_logits[s_logits >= 0.5] = 1\n",
    "\n",
    "        tp = torch.sum(s_tensor[s_logits == 1])\n",
    "\n",
    "        return tp / torch.sum(s_logits)\n",
    "\n",
    "    def _structure_recall(self, s_logits, s_tensor):\n",
    "\n",
    "        s_logits = torch.sigmoid(s_logits)\n",
    "        s_logits[s_logits < 0.5] = 0\n",
    "        s_logits[s_logits >= 0.5] = 1\n",
    "\n",
    "        tp = torch.sum(s_tensor[s_logits == 1])\n",
    "\n",
    "        return tp / torch.sum(s_tensor)\n",
    "\n",
    "    def _save_model(self, filename):\n",
    "\n",
    "        path = os.path.join(self.model_dir, filename)\n",
    "        print(\"Saving model to disk...\")\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': self.cur_epoch,\n",
    "            'batch': self.cur_batch_idx,\n",
    "            'tot_batches': self.tot_batches,\n",
    "            'betas': self.betas,\n",
    "            'min_val_loss': self.min_val_loss,\n",
    "            'print_every': self.print_every,\n",
    "            'save_every': self.save_every,\n",
    "            'eval_every': self.eval_every,\n",
    "            'lrs': self.lrs,\n",
    "            'tr_losses': self.tr_losses,\n",
    "            'tr_accuracies': self.tr_accuracies,\n",
    "            'val_losses': self.val_losses,\n",
    "            'val_accuracies': self.val_accuracies,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict()\n",
    "        }, path)\n",
    "\n",
    "        print(\"The model has been successfully saved.\")\n",
    "\n",
    "    def _print_stats(self):\n",
    "\n",
    "        hours, rem = divmod(self.times[-1]-self.times[0], 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Elapsed time from start (h:m:s): {:0>2}:{:0>2}:{:05.2f}\"\n",
    "              .format(int(hours), int(minutes), seconds))\n",
    "\n",
    "        # Take mean of the last non-printed batches for each loss and accuracy\n",
    "        avg_losses = {}\n",
    "        for k, l in self.tr_losses.items():\n",
    "            v = mean(l[-self.print_every:])\n",
    "            avg_losses[k] = round(v, 2)\n",
    "\n",
    "        avg_accs = {}\n",
    "        for k, l in self.tr_accuracies.items():\n",
    "            v = mean(l[-self.print_every:])\n",
    "            avg_accs[k] = round(v, 2)\n",
    "\n",
    "        print(\"Losses:\")\n",
    "        pprint.pprint(avg_losses, indent=2)\n",
    "\n",
    "        print(\"Accuracies:\")\n",
    "        pprint.pprint(avg_accs, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "\n",
    "def print_params(model):\n",
    "\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "\n",
    "    for name, parameter in model.named_parameters():\n",
    "\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Parameters: {total_params}\")\n",
    "\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the configuration file C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\training.json...\n",
      "Preparing datasets and dataloaders...\n",
      "Creating the model and moving it to cpu device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s222445\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+------------+\n",
      "|                           Modules                           | Parameters |\n",
      "+-------------------------------------------------------------+------------+\n",
      "|         encoder.s_encoder.cnn_encoder.conv.0.weight         |     72     |\n",
      "|          encoder.s_encoder.cnn_encoder.conv.0.bias          |     8      |\n",
      "|         encoder.s_encoder.cnn_encoder.conv.1.weight         |     8      |\n",
      "|          encoder.s_encoder.cnn_encoder.conv.1.bias          |     8      |\n",
      "|         encoder.s_encoder.cnn_encoder.conv.4.weight         |    1152    |\n",
      "|          encoder.s_encoder.cnn_encoder.conv.4.bias          |     16     |\n",
      "|         encoder.s_encoder.cnn_encoder.conv.5.weight         |     16     |\n",
      "|          encoder.s_encoder.cnn_encoder.conv.5.bias          |     16     |\n",
      "|          encoder.s_encoder.cnn_encoder.lin.1.weight         |   262144   |\n",
      "|           encoder.s_encoder.cnn_encoder.lin.1.bias          |    512     |\n",
      "|          encoder.s_encoder.cnn_encoder.lin.4.weight         |   262144   |\n",
      "|           encoder.s_encoder.cnn_encoder.lin.4.bias          |    512     |\n",
      "|            encoder.s_encoder.bars_encoder.weight            |   524288   |\n",
      "|             encoder.s_encoder.bars_encoder.bias             |    512     |\n",
      "|         encoder.c_encoder.non_drums_pitch_emb.weight        |   33536    |\n",
      "|          encoder.c_encoder.non_drums_pitch_emb.bias         |    256     |\n",
      "|           encoder.c_encoder.drums_pitch_emb.weight          |   33536    |\n",
      "|            encoder.c_encoder.drums_pitch_emb.bias           |    256     |\n",
      "|               encoder.c_encoder.dur_emb.weight              |   25344    |\n",
      "|                encoder.c_encoder.dur_emb.bias               |    256     |\n",
      "|            encoder.c_encoder.bn_non_drums.weight            |    256     |\n",
      "|             encoder.c_encoder.bn_non_drums.bias             |    256     |\n",
      "|              encoder.c_encoder.bn_drums.weight              |    256     |\n",
      "|               encoder.c_encoder.bn_drums.bias               |    256     |\n",
      "|               encoder.c_encoder.bn_dur.weight               |    256     |\n",
      "|                encoder.c_encoder.bn_dur.bias                |    256     |\n",
      "|            encoder.c_encoder.chord_encoder.weight           |  3932160   |\n",
      "|             encoder.c_encoder.chord_encoder.bias            |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.0.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.0.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.0.bias        |    512     |\n",
      "|      encoder.c_encoder.graph_encoder.layers.0.nn.weight     |   16384    |\n",
      "|       encoder.c_encoder.graph_encoder.layers.0.nn.bias      |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.1.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.1.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.1.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.2.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.2.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.2.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.3.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.3.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.3.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.4.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.4.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.4.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.5.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.5.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.5.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.6.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.6.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.6.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.7.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.7.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.7.bias        |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.0.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.0.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.1.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.1.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.2.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.2.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.3.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.3.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.4.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.4.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.5.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.5.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.6.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.6.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.7.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.7.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_attention.gate_nn.0.layers.0.weight |    512     |\n",
      "|  encoder.c_encoder.graph_attention.gate_nn.0.layers.0.bias  |     1      |\n",
      "|      encoder.c_encoder.graph_attention.gate_nn.1.weight     |     1      |\n",
      "|       encoder.c_encoder.graph_attention.gate_nn.1.bias      |     1      |\n",
      "|            encoder.c_encoder.bars_encoder.weight            |   524288   |\n",
      "|             encoder.c_encoder.bars_encoder.bias             |    512     |\n",
      "|                 encoder.linear_merge.weight                 |   524288   |\n",
      "|                  encoder.linear_merge.bias                  |    512     |\n",
      "|                encoder.bn_linear_merge.weight               |    512     |\n",
      "|                 encoder.bn_linear_merge.bias                |    512     |\n",
      "|                   encoder.linear_mu.weight                  |   262144   |\n",
      "|                    encoder.linear_mu.bias                   |    512     |\n",
      "|                encoder.linear_log_var.weight                |   262144   |\n",
      "|                 encoder.linear_log_var.bias                 |    512     |\n",
      "|                  decoder.lin_decoder.weight                 |   524288   |\n",
      "|                   decoder.lin_decoder.bias                  |    1024    |\n",
      "|                  decoder.batch_norm.weight                  |    1024    |\n",
      "|                   decoder.batch_norm.bias                   |    1024    |\n",
      "|            decoder.s_decoder.bars_decoder.weight            |   524288   |\n",
      "|             decoder.s_decoder.bars_decoder.bias             |    1024    |\n",
      "|          decoder.s_decoder.cnn_decoder.lin.1.weight         |   262144   |\n",
      "|           decoder.s_decoder.cnn_decoder.lin.1.bias          |    512     |\n",
      "|          decoder.s_decoder.cnn_decoder.lin.4.weight         |   262144   |\n",
      "|           decoder.s_decoder.cnn_decoder.lin.4.bias          |    512     |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.1.weight         |    1152    |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.1.bias          |     8      |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.2.weight         |     8      |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.2.bias          |     8      |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.4.weight         |     72     |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.4.bias          |     1      |\n",
      "|            decoder.c_decoder.bars_decoder.weight            |   524288   |\n",
      "|             decoder.c_decoder.bars_decoder.bias             |    1024    |\n",
      "|       decoder.c_decoder.graph_decoder.layers.0.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.0.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.0.bias        |    512     |\n",
      "|      decoder.c_decoder.graph_decoder.layers.0.nn.weight     |   16384    |\n",
      "|       decoder.c_decoder.graph_decoder.layers.0.nn.bias      |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.1.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.1.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.1.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.2.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.2.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.2.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.3.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.3.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.3.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.4.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.4.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.4.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.5.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.5.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.5.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.6.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.6.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.6.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.7.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.7.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.7.bias        |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.0.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.0.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.1.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.1.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.2.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.2.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.3.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.3.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.4.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.4.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.5.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.5.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.6.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.6.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.7.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.7.module.bias  |    512     |\n",
      "|            decoder.c_decoder.chord_decoder.weight           |  3932160   |\n",
      "|             decoder.c_decoder.chord_decoder.bias            |    7680    |\n",
      "|           decoder.c_decoder.drums_pitch_emb.weight          |   33536    |\n",
      "|            decoder.c_decoder.drums_pitch_emb.bias           |    131     |\n",
      "|         decoder.c_decoder.non_drums_pitch_emb.weight        |   33536    |\n",
      "|          decoder.c_decoder.non_drums_pitch_emb.bias         |    131     |\n",
      "|               decoder.c_decoder.dur_emb.weight              |   25344    |\n",
      "|                decoder.c_decoder.dur_emb.bias               |     99     |\n",
      "+-------------------------------------------------------------+------------+\n",
      "Total Trainable Parameters: 42210909\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [04:21, 29.01s/it]00:00<?, ?it/s]\n",
      " 14%|        | 1/7 [00:02<00:13,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/7 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:02.30\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 5.66,\n",
      "  'kld': 53.79,\n",
      "  'pitch': 5.19,\n",
      "  'reconstruction': 11.17,\n",
      "  'structure': 0.31,\n",
      "  'tot': 11.17}\n",
      "Accuracies:\n",
      "{ 'dur': 0.0,\n",
      "  'note': 0.0,\n",
      "  'pitch': 0.03,\n",
      "  'pitch_drums': 0.04,\n",
      "  'pitch_non_drums': 0.03,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 2/7 [00:04<00:10,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 2/7 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:04.42\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 5.6,\n",
      "  'kld': 56.81,\n",
      "  'pitch': 5.16,\n",
      "  'reconstruction': 11.07,\n",
      "  'structure': 0.31,\n",
      "  'tot': 11.07}\n",
      "Accuracies:\n",
      "{ 'dur': 0.0,\n",
      "  'note': 0.0,\n",
      "  'pitch': 0.03,\n",
      "  'pitch_drums': 0.02,\n",
      "  'pitch_non_drums': 0.03,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 3/7 [00:06<00:08,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 3/7 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:06.67\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 4.25,\n",
      "  'kld': 53.9,\n",
      "  'pitch': 4.02,\n",
      "  'reconstruction': 8.58,\n",
      "  'structure': 0.31,\n",
      "  'tot': 8.58}\n",
      "Accuracies:\n",
      "{ 'dur': 0.05,\n",
      "  'note': 0.01,\n",
      "  'pitch': 0.17,\n",
      "  'pitch_drums': 0.05,\n",
      "  'pitch_non_drums': 0.21,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 4/7 [00:08<00:06,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 4/7 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:08.83\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 2.98,\n",
      "  'kld': 53.92,\n",
      "  'pitch': 2.95,\n",
      "  'reconstruction': 6.24,\n",
      "  'structure': 0.31,\n",
      "  'tot': 6.24}\n",
      "Accuracies:\n",
      "{ 'dur': 0.38,\n",
      "  'note': 0.15,\n",
      "  'pitch': 0.44,\n",
      "  'pitch_drums': 0.05,\n",
      "  'pitch_non_drums': 0.57,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 5/7 [00:10<00:04,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 5/7 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:10.95\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 1.82,\n",
      "  'kld': 54.03,\n",
      "  'pitch': 2.07,\n",
      "  'reconstruction': 4.2,\n",
      "  'structure': 0.31,\n",
      "  'tot': 4.2}\n",
      "Accuracies:\n",
      "{ 'dur': 0.75,\n",
      "  'note': 0.52,\n",
      "  'pitch': 0.69,\n",
      "  'pitch_drums': 0.09,\n",
      "  'pitch_non_drums': 0.89,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 6/7 [00:13<00:02,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 6/7 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:13.02\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.93,\n",
      "  'kld': 54.53,\n",
      "  'pitch': 1.42,\n",
      "  'reconstruction': 2.66,\n",
      "  'structure': 0.31,\n",
      "  'tot': 2.66}\n",
      "Accuracies:\n",
      "{ 'dur': 0.98,\n",
      "  'note': 0.75,\n",
      "  'pitch': 0.77,\n",
      "  'pitch_drums': 0.1,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 7/7 [00:15<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 7/7 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:15.74\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.39,\n",
      "  'kld': 54.9,\n",
      "  'pitch': 1.01,\n",
      "  'reconstruction': 1.71,\n",
      "  'structure': 0.31,\n",
      "  'tot': 1.71}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.81,\n",
      "  'pitch': 0.81,\n",
      "  'pitch_drums': 0.23,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:18,  2.40s/it]                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/7 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:18.29\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.14,\n",
      "  'kld': 55.22,\n",
      "  'pitch': 0.76,\n",
      "  'reconstruction': 1.21,\n",
      "  'structure': 0.31,\n",
      "  'tot': 1.21}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.86,\n",
      "  'pitch': 0.86,\n",
      "  'pitch_drums': 0.45,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:20,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 2/7 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:20.80\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.05,\n",
      "  'kld': 51.58,\n",
      "  'pitch': 0.56,\n",
      "  'reconstruction': 0.93,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.93}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.91,\n",
      "  'pitch': 0.91,\n",
      "  'pitch_drums': 0.64,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "Training on batch 3/7 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:23.26\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.02,\n",
      "  'kld': 55.89,\n",
      "  'pitch': 0.4,\n",
      "  'reconstruction': 0.73,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.73}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.96,\n",
      "  'pitch': 0.96,\n",
      "  'pitch_drums': 0.84,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "\n",
      "Evaluating on validation set...\n",
      "\n",
      "Starting evaluation with 1 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s222445\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "100%|| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val losses:\n",
      "{'tot': 1.2931205034255981, 'pitch': 0.7541825175285339, 'dur': 0.22567637264728546, 'structure': 0.31326165795326233, 'reconstruction': 1.2931205034255981, 'kld': 8.15030574798584, 'beta*kld': 0.0}\n",
      "Val accuracies:\n",
      "{'note': 0.9791666865348816, 'pitch': 0.9791666865348816, 'pitch_drums': 0.9166666865348816, 'pitch_non_drums': 1.0, 'dur': 1.0, 's_acc': 1.0, 's_precision': 1.0, 's_recall': 1.0, 's_f1': 1.0}\n",
      "\n",
      "Validation loss improved.\n",
      "Saving new best model to disk...\n",
      "\n",
      "Saving model to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:24,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been successfully saved.\n",
      "Saving model to disk...\n",
      "The model has been successfully saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:29,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 4/7 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:29.44\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.01,\n",
      "  'kld': 51.61,\n",
      "  'pitch': 0.26,\n",
      "  'reconstruction': 0.58,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.58}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.99,\n",
      "  'pitch': 0.99,\n",
      "  'pitch_drums': 0.95,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:32,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 5/7 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:32.38\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.58,\n",
      "  'pitch': 0.16,\n",
      "  'reconstruction': 0.48,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.48}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 0.98,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:35,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 6/7 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:35.24\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.57,\n",
      "  'pitch': 0.09,\n",
      "  'reconstruction': 0.4,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.4}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:38,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 7/7 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:38.51\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.25,\n",
      "  'pitch': 0.04,\n",
      "  'reconstruction': 0.36,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.36}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:41,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/7 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:41.41\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.94,\n",
      "  'pitch': 0.02,\n",
      "  'reconstruction': 0.34,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.34}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:44,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 2/7 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:44.13\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 53.49,\n",
      "  'pitch': 0.01,\n",
      "  'reconstruction': 0.33,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.33}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:47,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 3/7 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:47.23\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 55.68,\n",
      "  'pitch': 0.01,\n",
      "  'reconstruction': 0.32,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.32}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:49,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 4/7 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:49.84\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 56.63,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.32,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.32}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:52,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 5/7 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:52.46\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 53.07,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "Training on batch 6/7 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:55.15\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.89,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "\n",
      "Evaluating on validation set...\n",
      "\n",
      "Starting evaluation with 1 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val losses:\n",
      "{'tot': 0.32058408856391907, 'pitch': 0.006891996134072542, 'dur': 0.0004304362228140235, 'structure': 0.31326165795326233, 'reconstruction': 0.32058408856391907, 'kld': 40.243751525878906, 'beta*kld': 0.0}\n",
      "Val accuracies:\n",
      "{'note': 1.0, 'pitch': 1.0, 'pitch_drums': 1.0, 'pitch_non_drums': 1.0, 'dur': 1.0, 's_acc': 1.0, 's_precision': 1.0, 's_recall': 1.0, 's_f1': 1.0}\n",
      "\n",
      "Validation loss improved.\n",
      "Saving new best model to disk...\n",
      "\n",
      "Saving model to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:56,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been successfully saved.\n",
      "Saving model to disk...\n",
      "The model has been successfully saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [01:00,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 7/7 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:00.25\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.25,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [01:02,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/7 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:02.95\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 52.81,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [01:06,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 2/7 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:06.06\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 55.11,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [01:09,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 3/7 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:09.87\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 52.85,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [01:12,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 4/7 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:12.69\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.24,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [01:15,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 5/7 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:15.98\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 55.79,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [01:18,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 6/7 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:18.87\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 56.91,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [01:21,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 7/7 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:21.47\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.18,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [01:24,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/7 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:24.07\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 55.23,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "Training on batch 2/7 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:26.99\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 55.0,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "\n",
      "Evaluating on validation set...\n",
      "\n",
      "Starting evaluation with 1 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val losses:\n",
      "{'tot': 0.3132694959640503, 'pitch': 7.604952770634554e-06, 'dur': 2.2328450199893268e-07, 'structure': 0.31326165795326233, 'reconstruction': 0.3132694959640503, 'kld': 141.52072143554688, 'beta*kld': 0.0}\n",
      "Val accuracies:\n",
      "{'note': 1.0, 'pitch': 1.0, 'pitch_drums': 1.0, 'pitch_non_drums': 1.0, 'dur': 1.0, 's_acc': 1.0, 's_precision': 1.0, 's_recall': 1.0, 's_f1': 1.0}\n",
      "\n",
      "Validation loss improved.\n",
      "Saving new best model to disk...\n",
      "\n",
      "Saving model to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [01:28,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been successfully saved.\n",
      "Saving model to disk...\n",
      "The model has been successfully saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [01:32,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 3/7 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:32.07\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 51.77,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:34,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 4/7 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:34.89\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 56.18,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [01:37,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 5/7 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:37.78\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 54.21,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [01:41,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 6/7 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:41.24\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 55.43,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [01:43,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 7/7 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:43.83\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 53.31,\n",
      "  'pitch': 0.0,\n",
      "  'reconstruction': 0.31,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.31}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "\n",
      "Training completed in (h:m:s): 00:01:43.83\n",
      "Saving model to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [01:44,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been successfully saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "# Ensure you have imported PolyphemusDataset, VAE, set_seed, print_params, print_divider, PolyphemusTrainer, ExpDecayLRScheduler, StepBetaScheduler correctly\n",
    "\n",
    "# Configuration and setup\n",
    "dataset_dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed'\n",
    "output_dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\output'\n",
    "config_file = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\training.json'\n",
    "model_name = 'testing1'  # or None to use a UUID\n",
    "save_every = 10\n",
    "print_every = 1\n",
    "eval_flag = True  # Set to False if you don't want to perform evaluation\n",
    "eval_every = 10  \n",
    "use_gpu = False\n",
    "gpu_id = 0\n",
    "num_workers = 0\n",
    "tr_split = 0.7\n",
    "vl_split = 0.1\n",
    "max_epochs = 5\n",
    "seed = 42  # or None\n",
    "\n",
    "# Set seed for reproducibility\n",
    "if seed is not None:\n",
    "    set_seed(seed)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "#if use_gpu:\n",
    "#    torch.cuda.set_device(gpu_id)\n",
    "\n",
    "# Load training configuration from JSON file\n",
    "print(f\"Loading the configuration file {config_file}...\")\n",
    "with open(config_file, 'r') as f:\n",
    "    training_config = json.load(f)\n",
    "\n",
    "n_bars = training_config['model']['n_bars']\n",
    "batch_size = training_config['batch_size']\n",
    "\n",
    "# Prepare datasets and dataloaders\n",
    "print(\"Preparing datasets and dataloaders...\")\n",
    "dataset = PolyphemusDataset(dataset_dir, n_bars)\n",
    "\n",
    "tr_len = int(tr_split * len(dataset))\n",
    "vl_len = int(vl_split * len(dataset)) if eval_flag else 0\n",
    "ts_len = len(dataset) - tr_len - vl_len\n",
    "lengths = (tr_len, vl_len, ts_len) if eval_flag else (tr_len, len(dataset) - tr_len)\n",
    "\n",
    "split = random_split(dataset, lengths)\n",
    "tr_set, vl_set = split[0], (split[1] if eval_flag else None)\n",
    "\n",
    "trainloader = DataLoader(tr_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validloader = DataLoader(vl_set, batch_size=batch_size, shuffle=False, num_workers=num_workers) if eval_flag else None\n",
    "\n",
    "# Model setup\n",
    "model_dir = os.path.join(output_dir, model_name or str(uuid.uuid1()))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=False)\n",
    "\n",
    "print(f\"Creating the model and moving it to {device} device...\")\n",
    "vae = VAE(**training_config['model'], device=device).to(device)\n",
    "print_params(vae)\n",
    "\n",
    "# Optimizer and schedulers setup\n",
    "optimizer = optim.Adam(vae.parameters(), **training_config['optimizer'])\n",
    "lr_scheduler = ExpDecayLRScheduler(optimizer=optimizer, **training_config['lr_scheduler'])\n",
    "beta_scheduler = StepBetaScheduler(**training_config['beta_scheduler'])\n",
    "\n",
    "# Save configuration\n",
    "config_path = os.path.join(model_dir, 'configuration.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(training_config, f)\n",
    "\n",
    "# Training\n",
    "print(\"Starting training...\")\n",
    "trainer = PolyphemusTrainer(\n",
    "    model_dir=model_dir,\n",
    "    model=vae,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    beta_scheduler=beta_scheduler,\n",
    "    save_every=save_every,\n",
    "    print_every=print_every,\n",
    "    eval_every=eval_every,\n",
    "    device=device\n",
    ")\n",
    "trainer.train(trainloader, validloader=validloader, epochs=max_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
