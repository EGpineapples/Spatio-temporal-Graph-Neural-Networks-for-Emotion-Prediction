{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data from 1 Person "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 81,
=======
   "execution_count": 28,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone  # Import timezone here\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Constants\n",
    "PAD_VALUE = 0\n",
    "SOS = 1\n",
    "EOS = 2\n",
    "TOKEN_OFFSET = 3  # Offset for unique activity and mode indices to include special tokens\n",
    "LAT_LON_PAD = 0\n",
    "\n",
    "def preprocess_data(csv_file, hr_file, start_time, end_time, dest_dir):\n",
    "    # Convert start and end times to datetime objects, explicitly defining them as UTC\n",
    "    start_dt = datetime.strptime(start_time, '%A, %B %d, %Y %I:%M:%S %p').replace(tzinfo=timezone.utc)\n",
    "    end_dt = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S UTC').replace(tzinfo=timezone.utc)\n",
    "\n",
    "    # Load CSV files\n",
    "    df_activities = pd.read_csv(csv_file)\n",
    "    df_hr = pd.read_csv(hr_file, skiprows=2, header=None, names=['HR'])\n",
    "\n",
    "    # Convert 'Start Time' and 'End Time' to timezone-aware datetime objects\n",
    "    df_activities['Start Time'] = pd.to_datetime(df_activities['Start Time'])\n",
    "    df_activities['End Time'] = pd.to_datetime(df_activities['End Time'])\n",
    "\n",
    "    # Localize or convert to UTC\n",
    "    df_activities['Start Time'] = df_activities['Start Time'].dt.tz_localize('UTC') if df_activities['Start Time'].dt.tz is None else df_activities['Start Time'].dt.tz_convert('UTC')\n",
    "    df_activities['End Time'] = df_activities['End Time'].dt.tz_localize('UTC') if df_activities['End Time'].dt.tz is None else df_activities['End Time'].dt.tz_convert('UTC')\n",
    "\n",
    "    # Filter activities data for the specified day\n",
    "    filtered_activities = df_activities[(df_activities['Start Time'] >= start_dt) & (df_activities['End Time'] <= end_dt)]\n",
    "    # print(filtered_activities)\n",
    "    # Create time series for activities, modes, and emotions at 1 Hz\n",
    "    total_seconds = min(int((end_dt - start_dt).total_seconds()), len(df_hr) - 1)\n",
<<<<<<< HEAD
    "    timesteps = pd.date_range(start=start_dt, periods=total_seconds + 1, freq='s')\n",
=======
    "    timesteps = pd.date_range(start=start_dt, periods=total_seconds + 1, freq='S')\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "\n",
    "    # Initialize data arrays\n",
    "    activities = np.full((1, total_seconds + 1), PAD_VALUE)\n",
    "    modes = np.full((1, total_seconds + 1), PAD_VALUE)\n",
    "    emotions = np.full((1, total_seconds + 1), df_hr['HR'].values, dtype=float)\n",
    "\n",
    "    # Unique tokens for activities and modes, ensuring they do not overlap\n",
    "    activity_tokens = {activity: i + TOKEN_OFFSET for i, activity in enumerate(filtered_activities['mainActivity'].unique())}\n",
    "    mode_tokens = {mode: i + TOKEN_OFFSET + len(activity_tokens) for i, mode in enumerate(filtered_activities['howTravelled'].unique())}  # Offset by number of activities\n",
    "\n",
    "    # Fill activity and mode arrays\n",
    "    for _, row in filtered_activities.iterrows():\n",
    "        start_sec = int((row['Start Time'] - start_dt).total_seconds())\n",
    "        end_sec = int((row['End Time'] - start_dt).total_seconds())\n",
    "        activities[0, start_sec:end_sec + 1] = activity_tokens.get(row['mainActivity'], PAD_VALUE)\n",
    "        modes[0, start_sec:end_sec + 1] = mode_tokens.get(row['howTravelled'], PAD_VALUE)\n",
    "\n",
<<<<<<< HEAD
    "    # Initialize data arrays\n",
    "    latitudes = np.full(total_seconds + 1, LAT_LON_PAD, dtype=float)\n",
    "    longitudes = np.full(total_seconds + 1, LAT_LON_PAD, dtype=float)\n",
    "    durations = np.zeros(total_seconds + 1, dtype=int)\n",
    "\n",
    "    # Find non-NaN lat/lon indices and calculate durations\n",
    "    valid_indices = filtered_activities.dropna(subset=['lat', 'lon']).index.tolist()\n",
    "    last_valid_index = 0\n",
    "    for i in range(len(valid_indices)):\n",
    "        if i > 0:\n",
    "            start_idx = valid_indices[i - 1]\n",
    "            end_idx = valid_indices[i]\n",
    "            duration = (filtered_activities.at[end_idx, 'Start Time'] - filtered_activities.at[start_idx, 'Start Time']).seconds\n",
    "            durations[start_idx] = duration\n",
    "        # Set current valid point values\n",
    "        idx = valid_indices[i]\n",
    "        latitudes[idx] = filtered_activities.at[idx, 'lat']\n",
    "        longitudes[idx] = filtered_activities.at[idx, 'lon']\n",
=======
    "    # Handling latitude and longitude with interpolation\n",
    "    latitudes = np.interp(\n",
    "        [t.timestamp() for t in timesteps],\n",
    "        [t.timestamp() for t in filtered_activities['Start Time']],\n",
    "        filtered_activities['lat'].fillna(LAT_LON_PAD)\n",
    "    )\n",
    "    longitudes = np.interp(\n",
    "        [t.timestamp() for t in timesteps],\n",
    "        [t.timestamp() for t in filtered_activities['Start Time']],\n",
    "        filtered_activities['lon'].fillna(LAT_LON_PAD)\n",
    "    )\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "\n",
    "    return {\n",
    "        'emotions': emotions,\n",
    "        'latitudes': np.array([latitudes]),  # Shape as (1, n)\n",
    "        'longitudes': np.array([longitudes]),\n",
<<<<<<< HEAD
    "        'durations': np.array([durations]),  # Added durations array\n",
=======
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "        'activities': activities,\n",
    "        'modes': modes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 82,
=======
   "execution_count": 29,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "DataFrame shape: (34610, 6)\n",
      "DataFrame head:    Emotions  Latitudes  Longitudes  Durations  Activities  Modes\n",
      "0     71.00        0.0         0.0          0           0      0\n",
      "1     71.00        0.0         0.0          0           0      0\n",
      "2     70.33        0.0         0.0          0           0      0\n",
      "3     71.00        0.0         0.0          0           0      0\n",
      "4     72.40        0.0         0.0          0           0      0\n",
      "Data saved to SampledData.csv\n"
=======
      "Emotions shape: (1, 34610)\n",
      "Emotions data: [[71.   71.   70.33 ... 85.97 85.98 86.02]]\n",
      "Emotions does not contain any NaN values.\n",
      "Latitudes shape: (1, 34610)\n",
      "Latitudes data: [[ 0.          0.          0.         ... 55.73402467 55.73402467\n",
      "  55.73402467]]\n",
      "Latitudes does not contain any NaN values.\n",
      "Longitudes shape: (1, 34610)\n",
      "Longitudes data: [[ 0.         0.         0.        ... 12.5760144 12.5760144 12.5760144]]\n",
      "Longitudes does not contain any NaN values.\n",
      "Activities shape: (1, 34610)\n",
      "Activities data: [[0 0 0 ... 4 4 4]]\n",
      "Activities does not contain any NaN values.\n",
      "Modes shape: (1, 34610)\n",
      "Modes data: [[0 0 0 ... 7 7 7]]\n",
      "Modes does not contain any NaN values.\n"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "csv_file = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\diary.csv\"\n",
    "hr_file = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\participant\\0701\\HR.csv\"\n",
    "dest_dir = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\processed\"\n",
    "start_time = 'Friday, January 7, 2022 12:36:56 PM'\n",
    "end_time = '2022-01-08 14:53:03 UTC'\n",
    "emotions, latitudes, longitudes, durations, activities, modes = preprocess_data(csv_file, hr_file, start_time, end_time, dest_dir).values()\n",
=======
    "\n",
    "csv_file = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\sample data\\diary.csv'\n",
    "hr_file = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\sample data\\participant\\0701\\HR.csv'\n",
    "dest_dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\sample data\\processed'\n",
    "start_time = 'Friday, January 7, 2022 12:36:56 PM'\n",
    "end_time = '2022-01-08 14:53:03 UTC'\n",
    "emotions, latitudes, longitudes, activities, modes = preprocess_data(csv_file, hr_file, start_time, end_time, dest_dir).values()\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "\n",
    "# Function to check for NaN values in the data arrays\n",
    "def check_for_nans(array, name):\n",
    "    if np.isnan(array).any():\n",
    "        print(f\"{name} contains NaN values.\")\n",
    "    else:\n",
    "        print(f\"{name} does not contain any NaN values.\")\n",
    "\n",
<<<<<<< HEAD
    "# Sampling every 10th timepoint\n",
    "emotions_sampled = emotions[:, ::10]\n",
    "latitudes_sampled = latitudes[:,::10]\n",
    "longitudes_sampled = longitudes[:,::10]\n",
    "durations_sampled = durations[:,::10]\n",
    "activities_sampled = activities[:,::10]\n",
    "modes_sampled = modes[:, ::10]\n",
    "\n",
    "# Create a DataFrame directly from arrays\n",
    "sampled_data = pd.DataFrame({\n",
    "    \"Emotions\": emotions.flatten(),\n",
    "    \"Latitudes\": latitudes.flatten(),\n",
    "    \"Longitudes\": longitudes.flatten(),\n",
    "    \"Durations\": durations.flatten(),\n",
    "    \"Activities\": activities.flatten(),\n",
    "    \"Modes\": modes.flatten()\n",
    "})\n",
    "\n",
    "# Print the shape and head of the dataframe to verify its contents before saving\n",
    "print(\"DataFrame shape:\", sampled_data.shape)\n",
    "print(\"DataFrame head:\", sampled_data.head())\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "file_path = 'SampledData.csv'\n",
    "sampled_data.to_csv(file_path, index=False)\n",
    "print(f\"Data saved to {file_path}\")"
=======
    "# Print the data and their shapes, and check for NaN values\n",
    "print(\"Emotions shape:\", emotions.shape)\n",
    "print(\"Emotions data:\", emotions[:1])  # Show only the first row for brevity\n",
    "check_for_nans(emotions, \"Emotions\")\n",
    "\n",
    "print(\"Latitudes shape:\", latitudes.shape)\n",
    "print(\"Latitudes data:\", latitudes[:1])  # Show only the first row for brevity\n",
    "check_for_nans(latitudes, \"Latitudes\")\n",
    "\n",
    "print(\"Longitudes shape:\", longitudes.shape)\n",
    "print(\"Longitudes data:\", longitudes[:1])  # Show only the first row for brevity\n",
    "check_for_nans(longitudes, \"Longitudes\")\n",
    "\n",
    "print(\"Activities shape:\", activities.shape)\n",
    "print(\"Activities data:\", activities[:1])  # Show only the first row for brevity\n",
    "check_for_nans(activities, \"Activities\")\n",
    "\n",
    "print(\"Modes shape:\", modes.shape)\n",
    "print(\"Modes data:\", modes[:1])  # Show only the first row for brevity\n",
    "check_for_nans(modes, \"Modes\")\n",
    "\n",
    "# Sampling every 10th timepoint\n",
    "emotions_sampled = emotions[:, ::10]\n",
    "latitudes_sampled = latitudes[::10]\n",
    "longitudes_sampled = longitudes[::10]\n",
    "activities_sampled = activities[:, ::10]\n",
    "modes_sampled = modes[:, ::10]"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 non-zero values in Latitudes: [55.73402467 55.73633084 55.73402467]\n",
      "There are 3 non-zero values in Longitudes: [12.5760144  12.57472828 12.5760144 ]\n",
      "There are 2 non-zero values in Durations: [7714  320]\n"
     ]
    }
   ],
   "source": [
    "def check_and_print_non_zeros(arr, name):\n",
    "    \"\"\" Checks and prints non-zero values in the array \"\"\"\n",
    "    non_zero_values = arr[arr != 0]  # Filter out non-zero values\n",
    "    non_zeros_count = non_zero_values.size  # Count non-zero values\n",
    "    if non_zeros_count == 0:\n",
    "        print(f\"No non-zero values found in {name}.\")\n",
    "    else:\n",
    "        print(f\"There are {non_zeros_count} non-zero values in {name}: {non_zero_values}\")\n",
    "\n",
    "# Check each array for non-zero values and print them\n",
    "check_and_print_non_zeros(latitudes, \"Latitudes\")\n",
    "check_and_print_non_zeros(longitudes, \"Longitudes\")\n",
    "check_and_print_non_zeros(durations, \"Durations\")"
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ..., 55.73402467,\n",
       "        55.73402467, 55.73402467]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitudes_sampled"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 84,
=======
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.       ,  0.       ,  0.       , ..., 12.5760144, 12.5760144,\n",
       "        12.5760144]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longitudes_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 4, 4, 4]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved: preprocessed\\sample_0_segment_0.npz\n",
      "File saved: preprocessed\\sample_0_segment_1.npz\n",
      "File saved: preprocessed\\sample_0_segment_2.npz\n",
      "File saved: preprocessed\\sample_0_segment_3.npz\n",
      "File saved: preprocessed\\sample_0_segment_4.npz\n",
      "File saved: preprocessed\\sample_0_segment_5.npz\n",
      "File saved: preprocessed\\sample_0_segment_6.npz\n",
      "File saved: preprocessed\\sample_0_segment_7.npz\n",
<<<<<<< HEAD
      "File saved: preprocessed\\sample_0_segment_8.npz\n",
      "File saved: preprocessed\\sample_0_segment_9.npz\n",
      "File saved: preprocessed\\sample_0_segment_10.npz\n",
      "File saved: preprocessed\\sample_0_segment_11.npz\n",
      "File saved: preprocessed\\sample_0_segment_12.npz\n",
      "File saved: preprocessed\\sample_0_segment_13.npz\n",
      "File saved: preprocessed\\sample_0_segment_14.npz\n",
      "File saved: preprocessed\\sample_0_segment_15.npz\n",
      "File saved: preprocessed\\sample_0_segment_16.npz\n",
      "File saved: preprocessed\\sample_0_segment_17.npz\n",
      "File saved: preprocessed\\sample_0_segment_18.npz\n",
      "File saved: preprocessed\\sample_0_segment_19.npz\n",
      "File saved: preprocessed\\sample_0_segment_20.npz\n",
      "File saved: preprocessed\\sample_0_segment_21.npz\n",
      "File saved: preprocessed\\sample_0_segment_22.npz\n",
      "File saved: preprocessed\\sample_0_segment_23.npz\n",
      "File saved: preprocessed\\sample_0_segment_24.npz\n",
      "File saved: preprocessed\\sample_0_segment_25.npz\n",
      "File saved: preprocessed\\sample_0_segment_26.npz\n",
      "File saved: preprocessed\\sample_0_segment_27.npz\n",
      "File saved: preprocessed\\sample_0_segment_28.npz\n",
      "File saved: preprocessed\\sample_0_segment_29.npz\n",
      "File saved: preprocessed\\sample_0_segment_30.npz\n",
      "File saved: preprocessed\\sample_0_segment_31.npz\n",
      "File saved: preprocessed\\sample_0_segment_32.npz\n",
      "File saved: preprocessed\\sample_0_segment_33.npz\n",
      "File saved: preprocessed\\sample_0_segment_34.npz\n",
      "File saved: preprocessed\\sample_0_segment_35.npz\n",
      "File saved: preprocessed\\sample_0_segment_36.npz\n",
      "File saved: preprocessed\\sample_0_segment_37.npz\n",
      "File saved: preprocessed\\sample_0_segment_38.npz\n",
      "File saved: preprocessed\\sample_0_segment_39.npz\n",
      "File saved: preprocessed\\sample_0_segment_40.npz\n",
      "File saved: preprocessed\\sample_0_segment_41.npz\n",
      "File saved: preprocessed\\sample_0_segment_42.npz\n",
      "File saved: preprocessed\\sample_0_segment_43.npz\n",
      "File saved: preprocessed\\sample_0_segment_44.npz\n",
      "File saved: preprocessed\\sample_0_segment_45.npz\n",
      "File saved: preprocessed\\sample_0_segment_46.npz\n",
      "File saved: preprocessed\\sample_0_segment_47.npz\n",
      "File saved: preprocessed\\sample_0_segment_48.npz\n",
      "File saved: preprocessed\\sample_0_segment_49.npz\n",
      "File saved: preprocessed\\sample_0_segment_50.npz\n",
      "File saved: preprocessed\\sample_0_segment_51.npz\n",
      "File saved: preprocessed\\sample_0_segment_52.npz\n",
      "File saved: preprocessed\\sample_0_segment_53.npz\n"
=======
      "File saved: preprocessed\\sample_0_segment_8.npz\n"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "\n",
    "# Constants\n",
    "N_DISCRETE_VALUES = 4  \n",
    "N_SAMPLES = 1\n",
<<<<<<< HEAD
    "N_TIMESTEPS = 34610  # For the initial data generation\n",
=======
    "N_TIMESTEPS = 3461  # For the initial data generation\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "PAD_VALUE = 0  # Define a padding value for activities and modes\n",
    "MAX_SIMU_TOKENS = 4 \n",
    "N_TRACKS = 4  # Number of \"instrument\" tracks\n",
    "N_BARS = 2  # Assuming 2 bars for simplicity, bars = days\n",
<<<<<<< HEAD
    "RESOLUTION = 8 # Assuming 8 timesteps per beat, adjust as needed, hours ?\n",
=======
    "RESOLUTION = 8  # Assuming 8 timesteps per beat, adjust as needed, hours ?\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "\n",
    "# Assuming the location track is the second track (index 1)\n",
    "LOCATION_TRACK_IDX = 1  # Adjust this index based on which track you want to use for location data\n",
    "\n",
    "class EdgeTypes(Enum):\n",
    "    TRACK = 0\n",
    "    ONSET = N_TRACKS\n",
    "    NEXT = N_TRACKS + 1\n",
    "\n",
    "# N_TRACKS track types + 1 onset edge type + 1 next edge type\n",
    "N_EDGE_TYPES = N_TRACKS + 2\n",
    "\n",
    "# Calculate window size and stride for sliding windows\n",
    "window_size = N_BARS * 4 * RESOLUTION\n",
<<<<<<< HEAD
    "stride = window_size * 10\n",
=======
    "stride = window_size // 2\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "\n",
    "def preprocess_sample_data(dest_dir):\n",
    "\n",
    "    # Sampling every 10th timestep\n",
<<<<<<< HEAD
    "    #emotions = emotions_sampled\n",
    "    #latitudes = latitudes_sampled\n",
    "    #longitudes = longitudes_sampled\n",
    "    #activities = activities_sampled\n",
    "    #modes = modes_sampled\n",
    "\n",
    "    for sample_idx in range(N_SAMPLES):\n",
    "        full_c_tensor = np.zeros((N_TRACKS, N_TIMESTEPS, MAX_SIMU_TOKENS, 2), dtype=np.float32)\n",
    "        for t in range(N_TIMESTEPS):\n",
    "            for track_idx, data in enumerate([emotions, latitudes, activities, modes]):\n",
    "                value = data[sample_idx, t]\n",
    "                if track_idx == LOCATION_TRACK_IDX:\n",
    "                    full_c_tensor[track_idx, t, 0, :] = [latitudes[sample_idx, t], durations[sample_idx, t]]   # Latitude\n",
    "                    full_c_tensor[track_idx, t, 1, :] = [longitudes[sample_idx, t], durations[sample_idx, t]] # Longitude\n",
    "                else:\n",
    "                    # Location track with durations\n",
=======
    "    emotions = emotions_sampled\n",
    "    latitudes = latitudes_sampled\n",
    "    longitudes = longitudes_sampled\n",
    "    activities = activities_sampled\n",
    "    modes = modes_sampled\n",
    "\n",
    "    for sample_idx in range(N_SAMPLES):\n",
    "        full_c_tensor = np.zeros((N_TRACKS, N_TIMESTEPS // 10, MAX_SIMU_TOKENS, 2), dtype=np.float32)\n",
    "        for t in range(N_TIMESTEPS // 10):\n",
    "            for track_idx, data in enumerate([emotions, latitudes, activities, modes]):\n",
    "                value = data[sample_idx, t]\n",
    "                if track_idx == LOCATION_TRACK_IDX:\n",
    "                    full_c_tensor[track_idx, t, 0, :] = [latitudes[sample_idx, t], 1]  # Latitude\n",
    "                    full_c_tensor[track_idx, t, 1, :] = [longitudes[sample_idx, t], 1]  # Longitude\n",
    "                else:\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "                    full_c_tensor[track_idx, t, 0, :] = [value, 1]\n",
    "\n",
    "        full_s_tensor = np.any(full_c_tensor != 0, axis=(2, 3)).astype(int)\n",
    "\n",
<<<<<<< HEAD
    "        for start_idx in range(0, N_TIMESTEPS - window_size + 1, stride):\n",
=======
    "        for start_idx in range(0, N_TIMESTEPS // 10 - window_size + 1, stride):\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "            c_tensor_segment = full_c_tensor[:, start_idx:start_idx + window_size, :, :]\n",
    "            s_tensor_segment = full_s_tensor[:, start_idx:start_idx + window_size]\n",
    "            sample_filepath = os.path.join(dest_dir, f\"sample_{sample_idx}_segment_{start_idx//stride}.npz\")\n",
    "            try:\n",
    "                np.savez(sample_filepath, c_tensor=c_tensor_segment, s_tensor=s_tensor_segment)\n",
    "                print(f\"File saved: {sample_filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to save {sample_filepath}: {e}\")\n",
    "\n",
    "csv_file = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\sample data\\diary.csv'\n",
    "dest_dir = 'preprocessed'\n",
    "preprocess_sample_data(dest_dir)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 85,
=======
   "execution_count": 31,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of c_tensor: (4, 64, 4, 2)\n",
      "Shape of s_tensor: (4, 64)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "file_path = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\preprocessed\\sample_0_segment_0.npz\"\n",
=======
    "file_path = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_0_segment_0.npz'\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "\n",
    "# Load the .npz file\n",
    "data = np.load(file_path)\n",
    "\n",
    "# Access the tensors\n",
    "c_tensor = data['c_tensor']\n",
    "s_tensor = data['s_tensor']\n",
    "\n",
    "# Print their shapes\n",
    "print(f'Shape of c_tensor: {c_tensor.shape}')\n",
    "print(f'Shape of s_tensor: {s_tensor.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
=======
    "# Continuous Values Testing Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_geographical_data(samples=1, n_timesteps=100):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Latitude and Longitude ranges for New York City\n",
    "    lat_range = (40.7128, 40.7480)\n",
    "    lon_range = (-74.0060, -73.9352)\n",
    "\n",
    "    # Generate random lat-lon coordinates\n",
    "    latitudes = np.random.uniform(low=lat_range[0], high=lat_range[1], size=(samples, n_timesteps))\n",
    "    longitudes = np.random.uniform(low=lon_range[0], high=lon_range[1], size=(samples, n_timesteps))\n",
    "\n",
    "    # Simulate % greenage (0 to 100%)\n",
    "    greenage = np.random.uniform(low=0, high=100, size=(samples, n_timesteps))\n",
    "\n",
    "    # Normalize the features\n",
    "    latitudes_normalized = (latitudes - lat_range[0]) / (lat_range[1] - lat_range[0])\n",
    "    longitudes_normalized = (longitudes - lon_range[0]) / (lon_range[1] - lon_range[0])\n",
    "    greenage_normalized = greenage / 100  # Since greenage is already within 0 to 100%\n",
    "\n",
    "    return latitudes_normalized, longitudes_normalized, greenage_normalized\n",
    "\n",
    "# Example usage\n",
    "latitudes, longitudes, greenage = generate_geographical_data(samples=1, n_timesteps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "csv_file = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\sample data\\diary.csv' \n",
    "df = pd.read_csv(csv_file)  \n",
    "\n",
    "# Assuming df is your original DataFrame\n",
    "lat_lon_df = df[['lat', 'lon']].copy()\n",
    "lat_lon_df.dropna(subset=['lat', 'lon'], inplace=True)\n",
    "\n",
    "# Rename 'lat' and 'lon' columns\n",
    "lat_lon_df.rename(columns={'lat': 'Latitude', 'lon': 'Longitude'}, inplace=True)\n",
    "\n",
    "# Save the modified DataFrame to a CSV file\n",
    "lat_lon_df.to_csv('lat_lon.csv', index=False)\n",
    "\n",
    "# Select only the first 3 rows\n",
    "first_three_rows = lat_lon_df.head(100)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "first_three_rows.to_csv('lat_lon_first_100_rows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 3 0 3 0 4 0 3 0 3 0 1 0 0 0 1 0 5 0 5 0 3 0 6 0 3 0 3 0 4 0 6 0 4 0\n",
      "  3 0 5 0 7 0 1 0 6 0 0 1 0 0 1 0 3 0 6 0 3 0 1 0 1 0 3 0 3 0 8 0 0 0 0 0\n",
      "  0 3 0 3 0 3 0 1 0 5 0 4 0 4 0 3 0 5 0 0 0 0 0 1 0 4 0 4]]\n",
      "File saved: preprocessed\\sample_0_segment_0.npz\n",
      "File saved: preprocessed\\sample_0_segment_1.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "from enum import Enum\n",
    "\n",
    "# Constants\n",
    "N_DISCRETE_VALUES = 4  \n",
    "N_SAMPLES = 1\n",
    "N_TIMESTEPS = 100  # For the initial data generation\n",
    "PAD_VALUE = 0  # Define a padding value for activities and modes\n",
    "MAX_SIMU_TOKENS = 4 \n",
    "N_TRACKS = 4  # Number of \"instrument\" tracks\n",
    "N_BARS = 2  # Assuming 2 bars for simplicity, bars = days\n",
    "RESOLUTION = 8  # Assuming 8 timesteps per beat, adjust as needed, hours ?\n",
    "\n",
    "# Assuming the location track is the second track (index 1)\n",
    "LOCATION_TRACK_IDX = 1  # Adjust this index based on which track you want to use for location data\n",
    "\n",
    "class EdgeTypes(Enum):\n",
    "    TRACK = 0 # This has to be interpreted as the starting index\n",
    "    ONSET = N_TRACKS\n",
    "    NEXT = N_TRACKS + 1\n",
    "\n",
    "# N_TRACKS track types + 1 onset edge type + 1 next edge type\n",
    "N_EDGE_TYPES = N_TRACKS + 2\n",
    "\n",
    "def generate_sample_data():\n",
    "    # Generate emotions and locations with random values\n",
    "    emotions = np.random.randint(0, N_DISCRETE_VALUES, (N_SAMPLES, N_TIMESTEPS))\n",
    "    locations = np.random.randint(0, N_DISCRETE_VALUES, (N_SAMPLES, N_TIMESTEPS))\n",
    "    return emotions, locations\n",
    "\n",
    "# Generate or load real data for emotions, locations, activities, and modes\n",
    "# This is a placeholder. Replace it with actual data loading or generation\n",
    "emotions, locations = generate_sample_data()  # You need to define this function\n",
    "latitudes, longitudes, greenage = generate_geographical_data()  \n",
    "\n",
    "# Calculate window size and stride for sliding windows\n",
    "window_size = N_BARS * 4 * RESOLUTION\n",
    "stride = window_size // 2\n",
    "\n",
    "def preprocess_sample_data(csv_file, dest_dir):\n",
    "    # Load CSV and preprocess activities and modes\n",
    "    df = pd.read_csv(csv_file)\n",
    "    activities_map = {activity: i for i, activity in enumerate(df['mainActivity'].unique(), start=1)}\n",
    "    modes_map = {mode: i for i, mode in enumerate(df['howTravelled'].unique(), start=1)}\n",
    "    df['activity_int'] = df['mainActivity'].fillna('PAD').map(lambda x: activities_map.get(x, PAD_VALUE))\n",
    "    df['mode_int'] = df['howTravelled'].fillna('PAD').map(lambda x: modes_map.get(x, PAD_VALUE))\n",
    "        \n",
    "    activities = np.full((N_SAMPLES, N_TIMESTEPS), PAD_VALUE, dtype=int)\n",
    "    modes = np.full((N_SAMPLES, N_TIMESTEPS), PAD_VALUE, dtype=int)\n",
    "    activities[:min(N_SAMPLES, len(df)), :] = df['activity_int'].head(N_TIMESTEPS)\n",
    "    modes[:min(N_SAMPLES, len(df)), :] = df['mode_int'].head(N_TIMESTEPS)\n",
    "    print(activities)\n",
    "        \n",
    "    for sample_idx in range(N_SAMPLES):\n",
    "        # Initialize tensors for this sample with the full length first\n",
    "        full_c_tensor = np.zeros((N_TRACKS, N_TIMESTEPS, MAX_SIMU_TOKENS, 2), dtype=np.float32)\n",
    "\n",
    "        # Populate the full tensors\n",
    "        for t in range(N_TIMESTEPS):\n",
    "            for track_idx, data in enumerate([emotions, locations, activities, modes]):\n",
    "                value = data[sample_idx, t]\n",
    "                if track_idx == LOCATION_TRACK_IDX:\n",
    "                    # Populate latitude, longitude, and greenage in the location track\n",
    "                    full_c_tensor[track_idx, t, 0, :] = [value, 1]  # Emotion/Location value and duration\n",
    "                    full_c_tensor[track_idx, t, 1, :] = [latitudes[sample_idx, t], 1]  # Latitude\n",
    "                    # print(full_c_tensor[track_idx, t, 1, :])\n",
    "                    full_c_tensor[track_idx, t, 2, :] = [longitudes[sample_idx, t], 1]  # Longitude\n",
    "                    full_c_tensor[track_idx, t, 3, :] = [greenage[sample_idx, t], 1]  # Greenage\n",
    "                else:\n",
    "                    # Populate other tracks with their respective data\n",
    "                    full_c_tensor[track_idx, t, 0, :] = [value, 1]  # Example of populating non-location data\n",
    "\n",
    "        # Calculate full_s_tensor based on non-zero values in full_c_tensor for the current sample\n",
    "        full_s_tensor = np.any(full_c_tensor != 0, axis=(2, 3)).astype(int)\n",
    "\n",
    "        # Windowing over time\n",
    "        for start_idx in range(0, N_TIMESTEPS - window_size + 1, stride):\n",
    "            c_tensor_segment = full_c_tensor[:, start_idx:start_idx + window_size, :, :]\n",
    "            s_tensor_segment = full_s_tensor[:, start_idx:start_idx + window_size]\n",
    "\n",
    "            # Save the tensors for this segment to an .npz file\n",
    "            sample_filepath = os.path.join(dest_dir, f\"sample_{sample_idx}_segment_{start_idx//stride}.npz\")\n",
    "            try:\n",
    "                np.savez(sample_filepath, c_tensor=c_tensor_segment, s_tensor=s_tensor_segment)\n",
    "                print(f\"File saved: {sample_filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to save {sample_filepath}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "csv_file = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\sample data\\diary.csv'   # Update this path to your CSV file\n",
    "dest_dir = 'preprocessed'  # Destination directory for preprocessed data\n",
    "preprocess_sample_data(csv_file, dest_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of c_tensor: (4, 64, 4, 2)\n",
      "Shape of s_tensor: (4, 64)\n"
     ]
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed\\sample_1_segment_0.npz'\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load(file_path)\n",
    "\n",
    "# Access the tensors\n",
    "c_tensor = data['c_tensor']\n",
    "s_tensor = data['s_tensor']\n",
    "\n",
    "# Print their shapes\n",
    "print(f'Shape of c_tensor: {c_tensor.shape}')\n",
    "print(f'Shape of s_tensor: {s_tensor.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        ],\n",
       "       [0.5085707 , 1.        ],\n",
       "       [0.92775226, 1.        ],\n",
       "       [0.6958991 , 1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_tensor[1, 3, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "# Graph Construction"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 86,
=======
   "execution_count": 32,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.collate import collate\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "\n",
    "def get_node_labels(s_tensor, ones_idxs):\n",
    "    # Build a tensor which has node labels in place of each activation in the\n",
    "    # stucture tensor\n",
    "    labels = torch.zeros_like(s_tensor, dtype=torch.long, \n",
    "                              device=s_tensor.device)\n",
    "    n_nodes = len(ones_idxs[0])\n",
    "    labels[ones_idxs] = torch.arange(n_nodes, device=s_tensor.device)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_track_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "\n",
    "    track_edges = []\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        # Indices where the binary structure tensor is active\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    # For each track, add direct and inverse edges between consecutive nodes\n",
    "    for track in range(s_tensor.size(0)):\n",
    "        # List of active timesteps in the current track\n",
    "        tss = list(ones_idxs[1][ones_idxs[0] == track])\n",
    "        edge_type = EdgeTypes.TRACK.value + track\n",
    "        edges = [\n",
    "            # Edge tuple: (u, v, type, ts_distance). Zip is used to obtain\n",
    "            # consecutive active timesteps. Edges in different tracks have\n",
    "            # different types.\n",
    "            (node_labels[track, t1],\n",
    "             node_labels[track, t2], edge_type, t2 - t1)\n",
    "            for t1, t2 in zip(tss[:-1], tss[1:])\n",
    "        ]\n",
    "        inverse_edges = [(u, v, t, d) for (v, u, t, d) in edges]\n",
    "        track_edges.extend(edges + inverse_edges)\n",
    "\n",
    "    return torch.tensor(track_edges, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_onset_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "\n",
    "    onset_edges = []\n",
    "    edge_type = EdgeTypes.ONSET.value\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        # Indices where the binary structure tensor is active\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    # Add direct and inverse edges between nodes played in the same timestep\n",
    "    for ts in range(s_tensor.size(1)):\n",
    "        # List of active tracks in the current timestep\n",
    "        tracks = list(ones_idxs[0][ones_idxs[1] == ts])\n",
    "        # Obtain all possible pairwise combinations of active tracks\n",
    "        combinations = list(itertools.combinations(tracks, 2))\n",
    "        edges = [\n",
    "            # Edge tuple: (u, v, type, ts_distance(=0)).\n",
    "            (node_labels[track1, ts], node_labels[track2, ts], edge_type, 0)\n",
    "            for track1, track2 in combinations\n",
    "        ]\n",
    "        inverse_edges = [(u, v, t, d) for (v, u, t, d) in edges]\n",
    "        onset_edges.extend(edges + inverse_edges)\n",
    "\n",
    "    return torch.tensor(onset_edges, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_next_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "\n",
    "    next_edges = []\n",
    "    edge_type = EdgeTypes.NEXT.value\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        # Indices where the binary structure tensor is active\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    # List of active timesteps\n",
    "    tss = torch.nonzero(torch.any(s_tensor.bool(), dim=0)).squeeze()\n",
    "    if tss.dim() == 0:\n",
    "        return torch.tensor([], dtype=torch.long)\n",
    "\n",
    "    for i in range(tss.size(0)-1):\n",
    "        # Get consecutive active timesteps\n",
    "        t1, t2 = tss[i], tss[i+1]\n",
    "        # Get all the active tracks in the two timesteps\n",
    "        t1_tracks = ones_idxs[0][ones_idxs[1] == t1]\n",
    "        t2_tracks = ones_idxs[0][ones_idxs[1] == t2]\n",
    "\n",
    "        # Combine the source and destination tracks, removing combinations with\n",
    "        # the same source and destination track (since these represent track\n",
    "        # edges).\n",
    "        tracks_product = list(itertools.product(t1_tracks, t2_tracks))\n",
    "        tracks_product = [(track1, track2)\n",
    "                          for (track1, track2) in tracks_product\n",
    "                          if track1 != track2]\n",
    "        # Edge tuple: (u, v, type, ts_distance).\n",
    "        edges = [(node_labels[track1, t1], node_labels[track2, t2],\n",
    "                  edge_type, t2 - t1)\n",
    "                 for track1, track2 in tracks_product]\n",
    "\n",
    "        next_edges.extend(edges)\n",
    "\n",
    "    return torch.tensor(next_edges, dtype=torch.long)\n",
    "\n",
    "\n",
    "def get_track_features(s_tensor):\n",
    "\n",
    "    # Indices where the binary structure tensor is active\n",
    "    ones_idxs = torch.nonzero(s_tensor)\n",
    "\n",
    "    n_nodes = len(ones_idxs)\n",
    "    tracks = ones_idxs[:, 0]\n",
    "    n_tracks = s_tensor.size(0)\n",
    "\n",
    "    # The feature n_nodes x n_tracks tensor contains one-hot tracks\n",
    "    # representations for each node\n",
    "    features = torch.zeros((n_nodes, n_tracks))\n",
    "    features[torch.arange(n_nodes), tracks] = 1\n",
    "\n",
    "    return features\n",
    "\n",
    "def custom_collate(data_list):\n",
    "    batch = Batch.from_data_list(data_list)\n",
    "    if hasattr(batch, 'batch'):\n",
    "        batch.bars = batch.batch.clone()  # Optionally clone to ensure no accidental modification\n",
    "    return batch\n",
    "\n",
    "\n",
    "def graph_from_tensor(s_tensor):\n",
    "\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over bars and construct a graph for each bar\n",
    "    for i in range(s_tensor.size(0)):\n",
    "\n",
    "        bar = s_tensor[i]\n",
    "\n",
    "        # If the bar contains no activations, add a fake one to avoid having \n",
    "        # to deal with empty graphs\n",
    "        if not torch.any(bar):\n",
    "            bar[0, 0] = 1\n",
    "\n",
    "        # Get edges from boolean activations\n",
    "        track_edges = get_track_edges(bar)\n",
    "        onset_edges = get_onset_edges(bar)\n",
    "        next_edges = get_next_edges(bar)\n",
    "        edges = [track_edges, onset_edges, next_edges]\n",
    "\n",
    "        # Concatenate edge tensors (N x 4) (if any)\n",
    "        is_edgeless = (len(track_edges) == 0 and\n",
    "                       len(onset_edges) == 0 and\n",
    "                       len(next_edges) == 0)\n",
    "        if not is_edgeless:\n",
    "            edge_list = torch.cat([x for x in edges\n",
    "                                   if torch.numel(x) > 0])\n",
    "\n",
    "        # Adapt tensor to torch_geometric's Data\n",
    "        # If no edges, add fake self-edge\n",
    "        # edge_list[:, :2] contains source and destination node labels\n",
    "        # edge_list[:, 2:] contains edge types and timestep distances\n",
    "        edge_index = (edge_list[:, :2].t().contiguous() if not is_edgeless else\n",
    "                      torch.LongTensor([[0], [0]]))\n",
    "        attrs = (edge_list[:, 2:] if not is_edgeless else\n",
    "                 torch.Tensor([[0, 0]]))\n",
    "\n",
    "        # Add one hot timestep distance to edge attributes\n",
    "        edge_attr = torch.zeros(attrs.size(0), s_tensor.shape[-1] + 1)\n",
    "        edge_attr[:, 0] = attrs[:, 0]\n",
    "        edge_attr[torch.arange(edge_attr.size(0)),\n",
    "                   attrs.long()[:, 1] + 1] = 1\n",
    "        # print(type(edge_attr))\n",
    "\n",
    "        node_features = get_track_features(bar)\n",
    "        is_drum = node_features[:, 0].bool()\n",
    "        num_nodes = torch.sum(bar, dtype=torch.long)\n",
    "        bars.append(Data(edge_index=edge_index, edge_attr=edge_attr,\n",
    "                         num_nodes=num_nodes, node_features=node_features,\n",
    "                         is_drum=is_drum).to(s_tensor.device))\n",
    "\n",
    "    # Use custom collate function to merge all Data objects into a single Batch\n",
    "    #graph = custom_collate(bars)\n",
    "\n",
    "    # Manage the batch attribute as bars, if it exists\n",
    "    #if hasattr(graph, 'batch'):\n",
    "    #    graph.bars = graph.batch.clone()  # Cloning to ensure that original batch numbers are preserved\n",
    "    #    # print(\"Bars attribute added to graph\")\n",
    "\n",
    "    #return graph\n",
    "\n",
    "    # Merge the graphs corresponding to different bars into a single big graph\n",
    "    graph, _, _ = collate(\n",
    "        Data,\n",
    "        data_list=bars,\n",
    "        increment=True,\n",
    "        add_batch=True\n",
    "    )\n",
    "\n",
    "    # Change bars assignment vector name (otherwise, Dataloader's collate\n",
    "    # would overwrite graphs.batch)\n",
    "    graph.bars = graph.batch\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 87,
=======
   "execution_count": 33,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "N_PITCH_TOKENS = 131\n",
    "N_DUR_TOKENS = 99\n",
    "D_TOKEN_PAIR = N_PITCH_TOKENS + N_DUR_TOKENS\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "N_PITCH_TOKENS = 131\n",
    "N_DUR_TOKENS = 99\n",
    "D_TOKEN_PAIR = N_PITCH_TOKENS + N_DUR_TOKENS\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "class PolyphemusDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dir, n_bars=2):\n",
    "        self.dir = dir\n",
    "        self.files = [entry.path for entry in os.scandir(self.dir) if entry.is_file()]\n",
    "        self.len = len(self.files)\n",
    "        self.n_bars = n_bars\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load tensors\n",
    "        sample_path = self.files[idx]\n",
    "        data = np.load(sample_path, allow_pickle=True)\n",
    "        c_tensor = torch.tensor(data[\"c_tensor\"], dtype=torch.float32)\n",
    "        print(c_tensor.shape)\n",
    "        s_tensor = torch.tensor(data[\"s_tensor\"], dtype=torch.bool)\n",
    "        print(s_tensor.shape)\n",
    "\n",
    "        # Split continuous and categorical data\n",
    "        continuous_data = c_tensor[0:2, :, :, :]\n",
    "        print(continuous_data.shape)\n",
    "        categorical_data = c_tensor[2:4, :, :, :]\n",
    "        print(categorical_data.shape)\n",
    "        # Reshape for `n_bars` alignment\n",
    "        # Ensure that `n_timesteps` is divisible evenly by `n_bars`\n",
    "        n_timesteps_per_bar = c_tensor.shape[1] // self.n_bars\n",
    "\n",
    "        continuous_data = continuous_data.reshape(-1, self.n_bars, n_timesteps_per_bar, continuous_data.shape[2], continuous_data.shape[3])\n",
    "        continuous_data = continuous_data.permute(1, 0, 2, 3, 4)  # Reorder to (n_bars, batch, timesteps, features, feature_dims)\n",
    "\n",
    "        categorical_data = categorical_data.reshape(-1, self.n_bars, n_timesteps_per_bar, categorical_data.shape[2], categorical_data.shape[3])\n",
    "        categorical_data = categorical_data.permute(1, 0, 2, 3, 4)  # Reorder similarly\n",
    "\n",
    "        s_tensor = s_tensor.reshape(-1, self.n_bars, n_timesteps_per_bar)\n",
    "        s_tensor = s_tensor.permute(1, 0, 2)  # Reorder for structure tensor\n",
    "\n",
    "        # Process pitches as one-hot encoding\n",
    "        pitches = categorical_data[..., 0]\n",
    "        onehot_p = torch.zeros((pitches.numel(), N_PITCH_TOKENS), dtype=torch.float32)\n",
    "        onehot_p[torch.arange(pitches.numel()), pitches.long().flatten()] = 1.\n",
    "        onehot_p = onehot_p.view(*pitches.shape, N_PITCH_TOKENS)\n",
    "\n",
    "        # Assuming durations follow pitches in the second channel of the original categorical data\n",
    "        durs = categorical_data[..., 1]\n",
    "        onehot_d = torch.zeros((durs.numel(), N_DUR_TOKENS), dtype=torch.float32)\n",
    "        onehot_d[torch.arange(durs.numel()), durs.long().flatten()] = 1.\n",
    "        onehot_d = onehot_d.view(*durs.shape, N_DUR_TOKENS)\n",
    "    \n",
    "        # Match dimensions for concatenation\n",
    "        max_features = D_TOKEN_PAIR\n",
    "        pad_size = D_TOKEN_PAIR - continuous_data.shape[-1]\n",
    "        continuous_data = pad(continuous_data, (0, pad_size), \"constant\", 0)\n",
    "\n",
    "\n",
    "        print(onehot_p.shape)\n",
    "        print(onehot_d.shape)\n",
    "        print(continuous_data.shape)\n",
    "        c_tensor = torch.cat((onehot_p, onehot_d), dim=-1)\n",
    "\n",
    "        # Concatenate tensors\n",
    "        c_tensor = torch.cat([c_tensor, continuous_data], dim=0)\n",
    "\n",
    "        print(c_tensor.shape)\n",
    "\n",
    "        # Build graph structure from structure tensor\n",
    "        graph = graph_from_tensor(s_tensor)\n",
    "        #print(type(graph.edge_attr))  # This should print <class 'torch.Tensor'>\n",
    "\n",
    "        # Filter silences in order to get a sparse representation\n",
    "        c_tensor = c_tensor.reshape(-1, c_tensor.shape[-2], c_tensor.shape[-1])\n",
    "        c_tensor = c_tensor[s_tensor.reshape(-1).bool()]\n",
    "\n",
    "        graph.c_tensor = c_tensor\n",
    "        graph.s_tensor = s_tensor.float()\n",
    "\n",
    "\n",
    "        return graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 88,
=======
   "execution_count": 34,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "# Assuming constants are defined somewhere in your codebase\n",
    "N_PITCH_TOKENS = 131\n",
    "N_DUR_TOKENS = 99\n",
    "\n",
    "# Import the PolyphemusDataset class definition here\n",
    "\n",
    "# Define the directory where your dataset is located\n",
<<<<<<< HEAD
    "data_dir = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\preprocessed\"\n",
=======
    "data_dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed'\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "\n",
    "# Create an instance of the PolyphemusDataset\n",
    "dataset = PolyphemusDataset(dir=data_dir, n_bars=2)\n",
    "\n",
    "# Access the first item in the dataset to check edge_attr\n",
    "graph = dataset[0]  # This will call the __getitem__ method\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 89,
=======
   "execution_count": 35,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
<<<<<<< HEAD
      "Graph: Data(edge_index=[2, 1128], edge_attr=[1128, 33], num_nodes=192, node_features=[192, 4], is_drum=[192], batch=[192], ptr=[3], bars=[192], c_tensor=[192, 4, 230], s_tensor=[2, 4, 32])\n",
      "Graph.c_tensor shape: torch.Size([192, 4, 230])\n",
=======
      "Graph: Data(edge_index=[2, 2008], edge_attr=[2008, 33], num_nodes=256, node_features=[256, 4], is_drum=[256], batch=[256], ptr=[3], bars=[256], c_tensor=[256, 4, 230], s_tensor=[2, 4, 32])\n",
      "Graph.c_tensor shape: torch.Size([256, 4, 230])\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "Graph.s_tensor shape: torch.Size([2, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "# Constants for one-hot encoding\n",
    "N_PITCH_TOKENS = 131\n",
    "N_DUR_TOKENS = 99\n",
    "D_TOKEN_PAIR = N_PITCH_TOKENS + N_DUR_TOKENS\n",
    "\n",
    "# PolyphemusDataset class definition here (as provided in your question)\n",
    "\n",
    "# Create an instance of the PolyphemusDataset\n",
<<<<<<< HEAD
    "dir = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\preprocessed\"\n",
=======
    "dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed'\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "dataset = PolyphemusDataset(dir, n_bars=2)\n",
    "\n",
    "# Load a sample from the dataset\n",
    "sample_index = 0  # For example, load the first sample\n",
    "graph = dataset[sample_index]\n",
    "\n",
    "# Inspect the graph and its tensors\n",
    "print(\"Graph:\", graph)\n",
    "print(\"Graph.c_tensor shape:\", graph.c_tensor.shape)\n",
    "print(\"Graph.s_tensor shape:\", graph.s_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 90,
=======
   "execution_count": 37,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch_sparse import SparseTensor, masked_select_nnz\n",
    "from torch_geometric.typing import OptTensor, Adj\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.nn.glob import GlobalAttention\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn.conv import RGCNConv\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (Tensor, Tensor) -> Tensor\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.jit._overload\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    # type: (SparseTensor, Tensor) -> SparseTensor\n",
    "    pass\n",
    "\n",
    "\n",
    "def masked_edge_index(edge_index, edge_mask):\n",
    "    if isinstance(edge_index, Tensor):\n",
    "        return edge_index[:, edge_mask]\n",
    "    else:\n",
    "        return masked_select_nnz(edge_index, edge_mask, layout='coo')\n",
    "\n",
    "\n",
    "def masked_edge_attr(edge_attr, edge_mask):\n",
    "    return edge_attr[edge_mask, :]\n",
    "\n",
    "\n",
    "class GCL(RGCNConv):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, num_relations, nn,\n",
    "                 dropout=0.1, **kwargs):\n",
    "        super().__init__(in_channels=in_channels, out_channels=out_channels,\n",
    "                         num_relations=num_relations, **kwargs)\n",
    "        self.nn = nn\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.reset_edge_nn()\n",
    "\n",
    "    def reset_edge_nn(self):\n",
    "        reset(self.nn)\n",
    "\n",
    "    def forward(self, x: Union[OptTensor, Tuple[OptTensor, Tensor]],\n",
    "                edge_index: Adj, edge_type: OptTensor = None,\n",
    "                edge_attr: OptTensor = None):\n",
    "        # print(f\"Before processing: x shape: {x.shape}, edge_index shape: {edge_index.shape}, edge_type shape: {edge_type.shape}, edge_attr shape: {edge_attr.shape}\")\n",
    "        # Convert input features to a pair of node features or node indices.\n",
    "        x_l: OptTensor = None\n",
    "        if isinstance(x, tuple):\n",
    "            x_l = x[0]\n",
    "        else:\n",
    "            x_l = x\n",
    "        if x_l is None:\n",
    "            x_l = torch.arange(self.in_channels_l, device=self.weight.device)\n",
    "\n",
    "        x_r: Tensor = x_l\n",
    "        if isinstance(x, tuple):\n",
    "            x_r = x[1]\n",
    "\n",
    "        size = (x_l.size(0), x_r.size(0))\n",
    "\n",
    "        if isinstance(edge_index, SparseTensor):\n",
    "            edge_type = edge_index.storage.value()\n",
    "        assert edge_type is not None\n",
    "\n",
    "        # propagate_type: (x: Tensor)\n",
    "        out = torch.zeros(x_r.size(0), self.out_channels, device=x_r.device)\n",
    "        weight = self.weight\n",
    "\n",
    "        # Basis-decomposition\n",
    "        if self.num_bases is not None:\n",
    "            weight = (self.comp @ weight.view(self.num_bases, -1)).view(\n",
    "                self.num_relations, self.in_channels_l, self.out_channels)\n",
    "\n",
    "        # Block-diagonal-decomposition\n",
    "        if self.num_blocks is not None:\n",
    "\n",
    "            if x_l.dtype == torch.long and self.num_blocks is not None:\n",
    "                raise ValueError('Block-diagonal decomposition not supported '\n",
    "                                 'for non-continuous input features.')\n",
    "\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                h = self.propagate(tmp, x=x_l, size=size)\n",
    "                h = h.view(-1, weight.size(1), weight.size(2))\n",
    "                h = torch.einsum('abc,bcd->abd', h, weight[i])\n",
    "                out += h.contiguous().view(-1, self.out_channels)\n",
    "\n",
    "        else:\n",
    "            # No regularization/Basis-decomposition\n",
    "            for i in range(self.num_relations):\n",
    "                tmp = masked_edge_index(edge_index, edge_type == i)\n",
    "                attr = masked_edge_attr(edge_attr, edge_type == i)\n",
    "\n",
    "                if x_l.dtype == torch.long:\n",
    "                    out += self.propagate(tmp, x=weight[i, x_l], size=size)\n",
    "                else:\n",
    "                    h = self.propagate(tmp, x=x_l, size=size,\n",
    "                                       edge_attr=attr)\n",
    "                    out = out + (h @ weight[i])\n",
    "\n",
    "        root = self.root\n",
    "        if root is not None:\n",
    "            out += root[x_r] if x_r.dtype == torch.long else x_r @ root\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        # print(f\"After processing: Output shape: {out.shape}\")\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_attr: Tensor) -> Tensor:\n",
    "\n",
    "        # Use edge nn to compute weight tensor from edge attributes\n",
    "        # (=onehot timestep distances between nodes)\n",
    "        # print(f\"Message: x_j shape: {x_j.shape}, edge_attr shape: {edge_attr.shape}\")\n",
    "        weights = self.nn(edge_attr)\n",
    "        weights = weights[..., :self.in_channels_l]\n",
    "        weights = weights.view(-1, self.in_channels_l)\n",
    "\n",
    "        out = x_j * weights\n",
    "        # print(f\"Message output shape: {out.shape}\")\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=256, hidden_dim=256, output_dim=256,\n",
    "                 num_layers=2, activation=True, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        if num_layers == 1:\n",
    "            self.layers.append(nn.Linear(input_dim, output_dim))\n",
    "        else:\n",
    "            # Input layer (1) + Intermediate layers (n-2) + Output layer (1)\n",
    "            self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            for _ in range(num_layers - 2):\n",
    "                self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.activation = activation\n",
    "        self.p = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = F.dropout(x, p=self.p, training=self.training)\n",
    "            x = layer(x)\n",
    "            if self.activation:\n",
    "                x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=256, hidden_dim=256, n_layers=3,\n",
    "                 num_relations=3, num_dists=32, batch_norm=False, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norm_layers = nn.ModuleList()\n",
    "        edge_nn = nn.Linear(num_dists, input_dim)\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        self.layers.append(GCL(input_dim, hidden_dim, num_relations, edge_nn))\n",
    "        if self.batch_norm:\n",
    "            self.norm_layers.append(BatchNorm(hidden_dim))\n",
    "\n",
    "        for i in range(n_layers-1):\n",
    "            self.layers.append(GCL(hidden_dim, hidden_dim,\n",
    "                                   num_relations, edge_nn))\n",
    "            if self.batch_norm:\n",
    "                self.norm_layers.append(BatchNorm(hidden_dim))\n",
    "\n",
    "        self.p = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        # print(type(edge_attr))\n",
    "        edge_type = edge_attr[:, 0]\n",
    "        edge_attr = edge_attr[:, 1:]\n",
    "\n",
    "        for i in range(len(self.layers)):\n",
    "            # print(f\"Layer {i}: Input shape: {x.shape}\")\n",
    "            residual = x\n",
    "            x = F.dropout(x, p=self.p, training=self.training)\n",
    "            x = self.layers[i](x, edge_index, edge_type, edge_attr)\n",
    "\n",
    "            if self.batch_norm:\n",
    "                x = self.norm_layers[i](x)\n",
    "\n",
    "            x = F.relu(x)\n",
    "            x = residual + x\n",
    "            # print(f\"Layer {i}: Output shape: {x.shape}\")\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim=64, dense_dim=64, batch_norm=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        if batch_norm:\n",
    "            self.conv = nn.Sequential(\n",
    "                # From (4 x 32) to (8 x 4 x 32)\n",
    "                nn.Conv2d(1, 8, 3, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                # From (8 x 4 x 32) to (8 x 4 x 8)\n",
    "                nn.MaxPool2d((1, 4), stride=(1, 4)),\n",
    "                # From (8 x 4 x 8) to (16 x 4 x 8)\n",
    "                nn.Conv2d(8, 16, 3, padding=1),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(1, 8, 3, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d((1, 4), stride=(1, 4)),\n",
    "                nn.Conv2d(8, 16, 3, padding=1),\n",
    "                nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        # Linear layers\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(16 * 4 * 8, dense_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=64, dense_dim=64, batch_norm=False,\n",
    "                 dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Linear decompressors\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(input_dim, dense_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dense_dim, 16 * 4 * 8),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(16, 4, 8))\n",
    "\n",
    "        # Upsample and convolutional layers\n",
    "        if batch_norm:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1, 4), mode='nearest'),\n",
    "                nn.Conv2d(16, 8, 3, padding=1),\n",
    "                nn.BatchNorm2d(8),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 1, 3, padding=1)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=(1, 4), mode='nearest'),\n",
    "                nn.Conv2d(16, 8, 3, padding=1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(8, 1, 3, padding=1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.conv(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ContentEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        #self.device = device  # Store the device as an instance variable\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        # Pitch and duration embedding layers (separate layers for drums\n",
    "        # and non drums)\n",
    "        self.non_drums_pitch_emb = nn.Linear(N_PITCH_TOKENS, \n",
    "                                             self.d//2)\n",
    "        self.drums_pitch_emb = nn.Linear(N_PITCH_TOKENS, self.d//2)\n",
    "        self.dur_emb = nn.Linear(N_DUR_TOKENS, self.d//2)\n",
    "\n",
    "        # Batch norm layers\n",
    "        self.bn_non_drums = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        self.bn_drums = nn.BatchNorm1d(num_features=self.d//2)\n",
    "        self.bn_dur = nn.BatchNorm1d(num_features=self.d//2)\n",
    "\n",
    "        self.chord_encoder = nn.Linear(\n",
    "            self.d * (MAX_SIMU_TOKENS-1), self.d)\n",
    "\n",
    "        self.graph_encoder = GCN(\n",
    "            dropout=self.dropout,\n",
    "            input_dim=self.d,\n",
    "            hidden_dim=self.d,\n",
    "            n_layers=self.gnn_n_layers,\n",
    "            num_relations=N_EDGE_TYPES,\n",
    "            batch_norm=self.batch_norm\n",
    "        )\n",
    "\n",
    "        # Soft attention node-aggregation layer\n",
    "        gate_nn = nn.Sequential(\n",
    "            MLP(input_dim=self.d, output_dim=1, num_layers=1,\n",
    "                activation=False, dropout=self.dropout),\n",
    "            nn.BatchNorm1d(1)\n",
    "        )\n",
    "        self.graph_attention = GlobalAttention(gate_nn)\n",
    "\n",
    "        self.bars_encoder = nn.Linear(self.n_bars * self.d, self.d)\n",
    "    \n",
    "    def forward(self, graph):\n",
    "        c_tensor = graph.c_tensor\n",
    "        print(c_tensor.shape)\n",
    "        # Discard SOS token\n",
    "        c_tensor = c_tensor[:, 1:, :]\n",
    "\n",
    "        # Get drums and non drums tensors\n",
    "        drums = c_tensor[graph.is_drum]\n",
    "        non_drums = c_tensor[torch.logical_not(graph.is_drum)]\n",
    "\n",
    "        # Compute drums embeddings\n",
    "        sz = drums.size()\n",
    "        drums_pitch = self.drums_pitch_emb(\n",
    "            drums[..., :N_PITCH_TOKENS])\n",
    "        drums_pitch = self.bn_drums(drums_pitch.view(-1, self.d//2))\n",
    "        drums_pitch = drums_pitch.view(sz[0], sz[1], self.d//2)\n",
    "        drums_dur = self.dur_emb(drums[..., N_PITCH_TOKENS:])\n",
    "        drums_dur = self.bn_dur(drums_dur.view(-1, self.d//2))\n",
    "        drums_dur = drums_dur.view(sz[0], sz[1], self.d//2)\n",
    "        drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        # n_nodes x MAX_SIMU_TOKENS x d\n",
    "\n",
    "        # Compute non drums embeddings\n",
    "        sz = non_drums.size()\n",
    "        non_drums_pitch = self.non_drums_pitch_emb(\n",
    "            non_drums[..., :N_PITCH_TOKENS]\n",
    "        )\n",
    "        non_drums_pitch = self.bn_non_drums(non_drums_pitch.view(-1, self.d//2))\n",
    "        non_drums_pitch = non_drums_pitch.view(sz[0], sz[1], self.d//2)\n",
    "        non_drums_dur = self.dur_emb(non_drums[..., N_PITCH_TOKENS:])\n",
    "        non_drums_dur = self.bn_dur(non_drums_dur.view(-1, self.d//2))\n",
    "        non_drums_dur = non_drums_dur.view(sz[0], sz[1], self.d//2)\n",
    "        non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        # n_nodes x MAX_SIMU_TOKENS x d\n",
    "\n",
    "        # Compute chord embeddings (drums and non drums)\n",
    "        drums = self.chord_encoder(\n",
    "            drums.view(-1, self.d * (MAX_SIMU_TOKENS-1))\n",
    "        )\n",
    "        non_drums = self.chord_encoder(\n",
    "            non_drums.view(-1, self.d * (MAX_SIMU_TOKENS-1))\n",
    "        )\n",
    "        drums = F.relu(drums)\n",
    "        non_drums = F.relu(non_drums)\n",
    "        drums = self.dropout_layer(drums)\n",
    "        non_drums = self.dropout_layer(non_drums)\n",
    "        # n_nodes x d\n",
    "\n",
    "        # Merge drums and non drums\n",
    "        out = torch.zeros((c_tensor.size(0), self.d), device=self.device,\n",
    "                          dtype=drums.dtype)\n",
    "        out[graph.is_drum] = drums\n",
    "        out[torch.logical_not(graph.is_drum)] = non_drums\n",
    "        # n_nodes x d\n",
    "\n",
    "        # Set initial graph node states to intermediate chord representations \n",
    "        # and pass through GCN\n",
    "        graph.x = out\n",
    "        graph.distinct_bars = graph.bars + self.n_bars*graph.batch\n",
    "        out = self.graph_encoder(graph)\n",
    "        # n_nodes x d\n",
    "\n",
    "        # Aggregate final node states into bar encodings with soft attention\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            out = self.graph_attention(out, batch=graph.distinct_bars)\n",
    "        # bs x n_bars x d\n",
    "\n",
    "        out = out.view(-1, self.n_bars * self.d)\n",
    "        # bs x (n_bars*d)\n",
    "        z_c = self.bars_encoder(out)\n",
    "        # bs x d\n",
    "        \n",
    "        return z_c\n",
    "\n",
    "\n",
    "class StructureEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.cnn_encoder = CNNEncoder(\n",
    "            dense_dim=self.d,\n",
    "            output_dim=self.d,\n",
    "            dropout=self.dropout,\n",
    "            batch_norm=self.batch_norm\n",
    "        )\n",
    "        self.bars_encoder = nn.Linear(self.n_bars * self.d, self.d)\n",
    "        # self.bars_encoder = nn.Linear(self.d, self.d)\n",
    "    \n",
    "    def forward(self, graph):\n",
    "        s_tensor = graph.s_tensor\n",
    "        # print(f\"Initial s_tensor shape: {s_tensor.shape}\")  # Initial shape: [bs, N_TRACKS, feature_dim]\n",
    "\n",
    "        # Adjust the reshaping for CNN input\n",
    "        # We assume feature_dim is the total dimension for each track, needing to be reshaped\n",
    "        # to fit CNN expectations. If your CNN expects [batch_size, channels, height, width],\n",
    "        # and here you interpret N_TRACKS as channels, your reshaping needs to reflect this.\n",
    "        s_tensor_reshaped = s_tensor.view(-1, N_TRACKS , self.resolution* 4 )  # Reshape to include a channel dimension\n",
    "\n",
    "        # Feed into CNN, the expected shape might need to adjust based on CNN's expected input dimensions\n",
    "        out = self.cnn_encoder(s_tensor_reshaped)\n",
    "        # print(f\"After CNN encoder, out shape: {out.shape}\")  # Check CNN output shape\n",
    "\n",
    "        # Correct the reshaping to re-establish batch dimension\n",
    "        out = out.view(-1, self.n_bars * self.d)  # Reshape to [bs, n_bars * d]\n",
    "        # print(f\"After view, out shape: {out.shape}\")\n",
    "        # print(f\"Shape before linear layer: {out.shape}\")\n",
    "        z_s = self.bars_encoder(out)\n",
    "        # print(f\"Final z_s shape: {z_s.shape}\")  # Expect [bs, d]\n",
    "\n",
    "        return z_s\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.s_encoder = StructureEncoder(**kwargs)\n",
    "        self.c_encoder = ContentEncoder(**kwargs)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        # Linear layer that merges content and structure representations\n",
    "        self.linear_merge = nn.Linear(2*self.d, self.d)\n",
    "        self.bn_linear_merge = nn.BatchNorm1d(num_features=self.d)\n",
    "\n",
    "        self.linear_mu = nn.Linear(self.d, self.d)\n",
    "        self.linear_log_var = nn.Linear(self.d, self.d)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \n",
    "        z_s = self.s_encoder(graph)\n",
    "        z_c = self.c_encoder(graph)\n",
    "        \n",
    "        # Merge content and structure representations\n",
    "        # print(f\"z_c shape: {z_c.shape}\")\n",
    "        # print(f\"z_s shape: {z_s.shape}\")\n",
    "        z_g = torch.cat((z_c, z_s), dim=1)\n",
    "        z_g = self.dropout_layer(z_g)\n",
    "        z_g = self.linear_merge(z_g)\n",
    "        z_g = self.bn_linear_merge(z_g)\n",
    "        z_g = F.relu(z_g)\n",
    "\n",
    "        # Compute mu and log(std^2)\n",
    "        z_g = self.dropout_layer(z_g)\n",
    "        mu = self.linear_mu(z_g)\n",
    "        log_var = self.linear_log_var(z_g)\n",
    "\n",
    "        return mu, log_var\n",
    "\n",
    "\n",
    "class StructureDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.bars_decoder = nn.Linear(self.d, self.d * self.n_bars)\n",
    "        #self.bars_decoder = nn.Linear(self.d, self.d)\n",
    "        self.cnn_decoder = CNNDecoder(\n",
    "            input_dim=self.d,\n",
    "            dense_dim=self.d,\n",
    "            dropout=self.dropout,\n",
    "            batch_norm=self.batch_norm\n",
    "        )\n",
    "\n",
    "    def forward(self, z_s):\n",
    "        # z_s: bs x d\n",
    "        out = self.bars_decoder(z_s)  # bs x (n_bars*d)\n",
    "        # out = self.cnn_decoder(out)\n",
    "        out = self.cnn_decoder(out.reshape(-1, self.d))\n",
    "        out = out.view(z_s.size(0), self.n_bars, N_TRACKS, -1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ContentDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.bars_decoder = nn.Linear(self.d, self.d * self.n_bars)\n",
    "\n",
    "        self.graph_decoder = GCN(\n",
    "            dropout=self.dropout,\n",
    "            input_dim=self.d,\n",
    "            hidden_dim=self.d,\n",
    "            n_layers=self.gnn_n_layers,\n",
    "            num_relations=N_EDGE_TYPES,\n",
    "            batch_norm=self.batch_norm\n",
    "        )\n",
    "\n",
    "        self.chord_decoder = nn.Linear(\n",
    "            self.d, self.d*(MAX_SIMU_TOKENS-1))\n",
    "\n",
    "        # Pitch and duration (un)embedding linear layers\n",
    "        self.drums_pitch_emb = nn.Linear(self.d//2, N_PITCH_TOKENS)\n",
    "        self.non_drums_pitch_emb = nn.Linear(\n",
    "            self.d//2, N_PITCH_TOKENS)\n",
    "        self.dur_emb = nn.Linear(self.d//2, N_DUR_TOKENS)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=self.dropout)\n",
    "\n",
    "    def forward(self, z_c, s):\n",
    "\n",
    "        out = self.bars_decoder(z_c)  # bs x (n_bars*d)\n",
    "\n",
    "        # Initialize node features with corresponding z_bar\n",
    "        # and propagate with GNN\n",
    "        s.distinct_bars = s.bars + self.n_bars*s.batch\n",
    "        _, counts = torch.unique(s.distinct_bars, return_counts=True)\n",
    "        out = out.view(-1, self.d)\n",
    "        out = torch.repeat_interleave(out, counts, axis=0)  # n_nodes x d\n",
    "        s.x = out\n",
    "        out = self.graph_decoder(s)  # n_nodes x d\n",
    "\n",
    "        out = self.chord_decoder(out)  # n_nodes x (MAX_SIMU_TOKENS*d)\n",
    "        out = out.view(-1, MAX_SIMU_TOKENS-1, self.d)\n",
    "\n",
    "        drums = out[s.is_drum]  # n_nodes_drums x MAX_SIMU_TOKENS x d\n",
    "        non_drums = out[torch.logical_not(s.is_drum)]\n",
    "        # n_nodes_non_drums x MAX_SIMU_TOKENS x d\n",
    "\n",
    "        # Obtain final pitch and dur logits (softmax will be applied\n",
    "        # outside forward)\n",
    "        non_drums = self.dropout_layer(non_drums)\n",
    "        drums = self.dropout_layer(drums)\n",
    "\n",
    "        drums_pitch = self.drums_pitch_emb(drums[..., :self.d//2])\n",
    "        drums_dur = self.dur_emb(drums[..., self.d//2:])\n",
    "        drums = torch.cat((drums_pitch, drums_dur), dim=-1)\n",
    "        # n_nodes_drums x MAX_SIMU_TOKENS x d_token\n",
    "\n",
    "        non_drums_pitch = self.non_drums_pitch_emb(non_drums[..., :self.d//2])\n",
    "        non_drums_dur = self.dur_emb(non_drums[..., self.d//2:])\n",
    "        non_drums = torch.cat((non_drums_pitch, non_drums_dur), dim=-1)\n",
    "        # n_nodes_non_drums x MAX_SIMU_TOKENS x d_token\n",
    "\n",
    "        # Merge drums and non-drums in the final output tensor\n",
    "        d_token = D_TOKEN_PAIR\n",
    "        out = torch.zeros((s.num_nodes, MAX_SIMU_TOKENS-1, d_token),\n",
    "                          device=self.device, dtype=drums.dtype)\n",
    "        out[s.is_drum] = drums\n",
    "        out[torch.logical_not(s.is_drum)] = non_drums\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.lin_decoder = nn.Linear(self.d, 2 * self.d)\n",
    "        self.batch_norm = nn.BatchNorm1d(num_features=2*self.d)\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        self.s_decoder = StructureDecoder(**kwargs)\n",
    "        self.c_decoder = ContentDecoder(**kwargs)\n",
    "\n",
    "        self.sigmoid_thresh = 0.5\n",
    "\n",
    "    def _structure_from_binary(self, s_tensor):\n",
    "\n",
    "        # Create graph structures for each batch\n",
    "        s = []\n",
    "        for i in range(s_tensor.size(0)):\n",
    "            s.append(graph_from_tensor(s_tensor[i]))\n",
    "\n",
    "        # Create batch of graphs from single graphs\n",
    "        s = Batch.from_data_list(s, exclude_keys=['batch'])\n",
    "        s = s.to(next(self.parameters()).device)\n",
    "\n",
    "        return s\n",
    "\n",
    "    def _binary_from_logits(self, s_logits):\n",
    "\n",
    "        # Hard threshold instead of sampling gives more pleasant results\n",
    "        s_tensor = torch.sigmoid(s_logits)\n",
    "        s_tensor[s_tensor >= self.sigmoid_thresh] = 1\n",
    "        s_tensor[s_tensor < self.sigmoid_thresh] = 0\n",
    "        s_tensor = s_tensor.bool()\n",
    "        \n",
    "        # Avoid empty bars by creating a fake activation for each empty\n",
    "        # (n_tracks x n_timesteps) bar matrix in position [0, 0]\n",
    "        empty_mask = ~s_tensor.any(dim=-1).any(dim=-1)\n",
    "        idxs = torch.nonzero(empty_mask, as_tuple=True)\n",
    "        s_tensor[idxs + (0, 0)] = True\n",
    "\n",
    "        return s_tensor\n",
    "\n",
    "    def _structure_from_logits(self, s_logits):\n",
    "\n",
    "        # Compute binary structure tensor from logits and build torch geometric\n",
    "        # structure from binary tensor\n",
    "        s_tensor = self._binary_from_logits(s_logits)\n",
    "        s = self._structure_from_binary(s_tensor)\n",
    "\n",
    "        return s\n",
    "\n",
    "    def forward(self, z, s=None):\n",
    "\n",
    "        # Obtain z_s and z_c from z\n",
    "        z = self.lin_decoder(z)\n",
    "        z = self.batch_norm(z)\n",
    "        z = F.relu(z)\n",
    "        z = self.dropout(z)  # bs x (2*d)\n",
    "        z_s, z_c = z[:, :self.d], z[:, self.d:]\n",
    "\n",
    "        # Obtain the tensor containing structure logits\n",
    "        s_logits = self.s_decoder(z_s)\n",
    "\n",
    "        if s is None:\n",
    "            # Build torch geometric graph structure from structure logits.\n",
    "            # This step involves non differentiable operations.\n",
    "            # No gradients pass through here.\n",
    "            s = self._structure_from_logits(s_logits.detach())\n",
    "\n",
    "        # Obtain the tensor containing content logits\n",
    "        c_logits = self.c_decoder(z_c, s)\n",
    "\n",
    "        return s_logits, c_logits\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(**kwargs)\n",
    "        self.decoder = Decoder(**kwargs)\n",
    "\n",
    "    def forward(self, graph):\n",
    "\n",
    "        # Encoder pass\n",
    "        mu, log_var = self.encoder(graph)\n",
    "\n",
    "        # Reparameterization trick\n",
    "        z = torch.exp(0.5 * log_var)\n",
    "        z = z * torch.randn_like(z)\n",
    "        z = z + mu\n",
    "\n",
    "        # Decoder pass\n",
    "        out = self.decoder(z, graph)\n",
    "\n",
    "        return out, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 91,
=======
   "execution_count": 38,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchToken(Enum):\n",
    "    SOS = 128\n",
    "    EOS = 129\n",
    "    PAD = 130\n",
    "\n",
    "\n",
    "N_PITCH_TOKENS = 131\n",
    "MAX_PITCH_TOKEN = 127\n",
    "\n",
    "\n",
    "# Duration tokens have values in the range [0, 98]. Tokens from 0 to 95 have to\n",
    "# be interpreted as durations from 1 to 96 timesteps.\n",
    "class DurationToken(Enum):\n",
    "    SOS = 96\n",
    "    EOS = 97\n",
    "    PAD = 98\n",
    "    \n",
    "def append_dict(dest_d, source_d):\n",
    "\n",
    "    for k, v in source_d.items():\n",
    "        dest_d[k].append(v)\n",
    "\n",
    "def print_divider():\n",
    "    print('—' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 92,
=======
   "execution_count": 39,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from statistics import mean\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "import pprint\n",
    "import math\n",
    "\n",
    "#import constants\n",
    "#from constants import PitchToken, DurationToken\n",
    "#from utils import append_dict, print_divider\n",
    "\n",
    "\n",
    "class StepBetaScheduler():\n",
    "    def __init__(self, anneal_start, beta_max, step_size, anneal_end):\n",
    "        self.anneal_start = anneal_start\n",
    "        self.beta_max = beta_max\n",
    "        self.step_size = step_size\n",
    "        self.anneal_end = anneal_end\n",
    "\n",
    "        self.update_steps = 0\n",
    "        self.beta = 0\n",
    "        n_steps = self.beta_max // self.step_size\n",
    "        self.inc_every = (self.anneal_end-self.anneal_start) // n_steps\n",
    "\n",
    "    def step(self):\n",
    "        self.update_steps += 1\n",
    "\n",
    "        if (self.update_steps >= self.anneal_start or\n",
    "                self.update_steps < self.anneal_end):\n",
    "            # If we are annealing, update beta according to current step\n",
    "            curr_step = (self.update_steps-self.anneal_start) // self.inc_every\n",
    "            self.beta = self.step_size * (curr_step+1)\n",
    "            \n",
    "        return self.beta\n",
    "\n",
    "\n",
    "class ExpDecayLRScheduler():\n",
    "    def __init__(self, optimizer, peak_lr, warmup_steps, final_lr_scale,\n",
    "                 decay_steps):\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.peak_lr = peak_lr\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.decay_steps = decay_steps\n",
    "\n",
    "        # Find the decay factor needed to reach the specified\n",
    "        # learning rate scale after decay_steps steps\n",
    "        self.decay_factor = -math.log(final_lr_scale) / self.decay_steps\n",
    "\n",
    "        self.update_steps = 0\n",
    "\n",
    "    def set_lr(self, optimizer, lr):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    def step(self):\n",
    "        self.update_steps += 1\n",
    "\n",
    "        if self.update_steps <= self.warmup_steps:\n",
    "            self.lr = self.peak_lr\n",
    "        else:\n",
    "            # Decay lr exponentially\n",
    "            steps_after_warmup = self.update_steps - self. warmup_steps\n",
    "            self.lr = \\\n",
    "                self.peak_lr * math.exp(-self.decay_factor*steps_after_warmup)\n",
    "\n",
    "        self.set_lr(self.optimizer, self.lr)\n",
    "\n",
    "        return self.lr\n",
    "\n",
    "\n",
    "class PolyphemusTrainer():\n",
    "\n",
    "    def __init__(self, model_dir, model, optimizer, init_lr=1e-4,\n",
    "                 lr_scheduler=None, beta_scheduler=None, device=None, \n",
    "                 print_every=1, save_every=1, eval_every=100, \n",
    "                 iters_to_accumulate=1, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        self.model_dir = model_dir\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.init_lr = init_lr\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.beta_scheduler = beta_scheduler\n",
    "        self.device = device if device is not None else torch.device(\"cpu\")\n",
    "        self.cuda = True if self.device.type == 'cuda' else False\n",
    "        self.print_every = print_every\n",
    "        self.save_every = save_every\n",
    "        self.eval_every = eval_every\n",
    "        self.iters_to_accumulate = iters_to_accumulate\n",
    "\n",
    "        # Losses (ignoring PAD tokens)\n",
    "        self.bce_unreduced = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.ce_p = nn.CrossEntropyLoss(ignore_index=PitchToken.PAD.value)\n",
    "        self.ce_d = nn.CrossEntropyLoss(ignore_index=DurationToken.PAD.value)\n",
    "\n",
    "        # Training stats\n",
    "        self.tr_losses = defaultdict(list)\n",
    "        self.tr_accuracies = defaultdict(list)\n",
    "        self.val_losses = defaultdict(list)\n",
    "        self.val_accuracies = defaultdict(list)\n",
    "        self.lrs = []\n",
    "        self.betas = []\n",
    "        self.times = []\n",
    "\n",
    "    def train(self, trainloader, validloader=None, epochs=100, early_exit=None):\n",
    "\n",
    "        self.tot_batches = 0\n",
    "        self.beta = 0\n",
    "        self.min_val_loss = np.inf\n",
    "\n",
    "        start = time.time()\n",
    "        self.times.append(start)\n",
    "\n",
    "        self.model.train()\n",
    "        scaler = torch.cuda.amp.GradScaler() if self.cuda else None\n",
    "        self.optimizer.zero_grad()\n",
    "        progress_bar = tqdm(range(len(trainloader)))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.cur_epoch = epoch\n",
    "            for batch_idx, graph in enumerate(trainloader):\n",
    "                self.cur_batch_idx = batch_idx\n",
    "\n",
    "                # Move batch of graphs to device. Note: a single graph here\n",
    "                # represents a bar in the original sequence.\n",
    "                graph = graph.to(self.device)\n",
    "                s_tensor, c_tensor = graph.s_tensor, graph.c_tensor\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=self.cuda):\n",
    "                    # Forward pass to obtain mu, log(sigma^2), computed by the\n",
    "                    # encoder, and structure and content logits, computed by the\n",
    "                    # decoder\n",
    "                    (s_logits, c_logits), mu, log_var = self.model(graph)\n",
    "\n",
    "                    # Compute losses\n",
    "                    tot_loss, losses = self._losses(\n",
    "                        s_tensor, s_logits,\n",
    "                        c_tensor, c_logits,\n",
    "                        mu, log_var\n",
    "                    )\n",
    "                    tot_loss = tot_loss / self.iters_to_accumulate\n",
    "\n",
    "                # Backpropagation\n",
    "                if self.cuda:\n",
    "                    scaler.scale(tot_loss).backward()\n",
    "                else:\n",
    "                    tot_loss.backward()\n",
    "\n",
    "                # Update weights with accumulated gradients\n",
    "                if (self.tot_batches + 1) % self.iters_to_accumulate == 0:\n",
    "\n",
    "                    if self.cuda:\n",
    "                        scaler.step(self.optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        self.optimizer.step()\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    # Update lr and beta\n",
    "                    if self.lr_scheduler is not None:\n",
    "                        self.lr_scheduler.step()\n",
    "                    if self.beta_scheduler is not None:\n",
    "                        self.beta_scheduler.step()\n",
    "\n",
    "                # Compute accuracies\n",
    "                accs = self._accuracies(\n",
    "                    s_tensor, s_logits,\n",
    "                    c_tensor, c_logits,\n",
    "                    graph.is_drum\n",
    "                )\n",
    "\n",
    "                # Update the stats\n",
    "                append_dict(self.tr_losses, losses)\n",
    "                append_dict(self.tr_accuracies, accs)\n",
    "                last_lr = (self.lr_scheduler.lr\n",
    "                           if self.lr_scheduler is not None else self.init_lr)\n",
    "                self.lrs.append(last_lr)\n",
    "                self.betas.append(self.beta)\n",
    "                now = time.time()\n",
    "                self.times.append(now)\n",
    "\n",
    "                # Print stats\n",
    "                if (self.tot_batches + 1) % self.print_every == 0:\n",
    "                    print(\"Training on batch {}/{} of epoch {}/{} complete.\"\n",
    "                          .format(batch_idx+1,\n",
    "                                  len(trainloader),\n",
    "                                  epoch+1,\n",
    "                                  epochs))\n",
    "                    self._print_stats()\n",
    "                    print_divider()\n",
    "\n",
    "                # Eval on VL every `eval_every` gradient updates\n",
    "                if (validloader is not None and\n",
    "                        (self.tot_batches + 1) % self.eval_every == 0):\n",
    "\n",
    "                    # Evaluate on VL\n",
    "                    print(\"\\nEvaluating on validation set...\\n\")\n",
    "                    val_losses, val_accuracies = self.evaluate(validloader)\n",
    "\n",
    "                    # Update stats\n",
    "                    append_dict(self.val_losses, val_losses)\n",
    "                    append_dict(self.val_accuracies, val_accuracies)\n",
    "\n",
    "                    print(\"Val losses:\")\n",
    "                    print(val_losses)\n",
    "                    print(\"Val accuracies:\")\n",
    "                    print(val_accuracies)\n",
    "\n",
    "                    # Save model if VL loss (tot) reached a new minimum\n",
    "                    # Example check before accessing 'tot'\n",
    "                    if 'tot' in val_losses:\n",
    "                        tot_loss = val_losses['tot']\n",
    "                    else:\n",
    "                        # Handle the missing key, e.g., set a default value or raise a more informative error\n",
    "                        tot_loss = 0  # or some default value\n",
    "                        print(\"Key 'tot' not found in val_losses. Setting tot_loss to 0.\")\n",
    "\n",
    "                    if tot_loss < self.min_val_loss:\n",
    "                        print(\"\\nValidation loss improved.\")\n",
    "                        print(\"Saving new best model to disk...\\n\")\n",
    "                        self._save_model('best_model')\n",
    "                        self.min_val_loss = tot_loss\n",
    "\n",
    "                    self.model.train()\n",
    "\n",
    "                progress_bar.update(1)\n",
    "\n",
    "                # Save model and stats on disk\n",
    "                if (self.save_every > 0 and\n",
    "                        (self.tot_batches + 1) % self.save_every == 0):\n",
    "                    self._save_model('checkpoint')\n",
    "\n",
    "                # Stop prematurely if early_exit is set and reached\n",
    "                if (early_exit is not None and\n",
    "                        (self.tot_batches + 1) > early_exit):\n",
    "                    break\n",
    "\n",
    "                self.tot_batches += 1\n",
    "\n",
    "        end = time.time()\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Training completed in (h:m:s): {:0>2}:{:0>2}:{:05.2f}\"\n",
    "              .format(int(hours), int(minutes), seconds))\n",
    "\n",
    "        self._save_model('checkpoint')\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        print(f\"Starting evaluation with {len(loader)} batches...\")\n",
    "        losses = defaultdict(list)\n",
    "        accs = defaultdict(list)\n",
    "\n",
    "        self.model.eval()\n",
    "        progress_bar = tqdm(range(len(loader)))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _, graph in enumerate(loader):\n",
    "\n",
    "                # Get the inputs and move them to device\n",
    "                graph = graph.to(self.device)\n",
    "                s_tensor, c_tensor = graph.s_tensor, graph.c_tensor\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # Forward pass, get the reconstructions\n",
    "                    (s_logits, c_logits), mu, log_var = self.model(graph)\n",
    "\n",
    "                    _, losses_b = self._losses(\n",
    "                        s_tensor, s_logits,\n",
    "                        c_tensor, c_logits,\n",
    "                        mu, log_var\n",
    "                    )\n",
    "\n",
    "                accs_b = self._accuracies(\n",
    "                    s_tensor, s_logits,\n",
    "                    c_tensor, c_logits,\n",
    "                    graph.is_drum\n",
    "                )\n",
    "\n",
    "                # Save losses and accuracies\n",
    "                append_dict(losses, losses_b)\n",
    "                append_dict(accs, accs_b)\n",
    "\n",
    "                progress_bar.update(1)\n",
    "\n",
    "        # Compute avg losses and accuracies\n",
    "        avg_losses = {}\n",
    "        for k, l in losses.items():\n",
    "            avg_losses[k] = mean(l)\n",
    "\n",
    "        avg_accs = {}\n",
    "        for k, l in accs.items():\n",
    "            avg_accs[k] = mean(l)\n",
    "\n",
    "        return avg_losses, avg_accs\n",
    "\n",
    "    def _losses(self, s_tensor, s_logits, c_tensor, c_logits, mu, log_var):\n",
    "\n",
    "        # Do not consider SOS token\n",
    "        c_tensor = c_tensor[..., 1:, :]\n",
    "        c_logits = c_logits.reshape(-1, c_logits.size(-1))\n",
    "        c_tensor = c_tensor.reshape(-1, c_tensor.size(-1))\n",
    "\n",
    "        # Reshape logits to match s_tensor dimensions:\n",
    "        # n_graphs (in batch) x n_tracks x n_timesteps\n",
    "        s_logits = s_tensor.reshape(-1, *s_logits.shape[2:])\n",
    "\n",
    "        # Binary structure tensor loss (binary cross entropy)\n",
    "        s_loss = self.bce_unreduced(\n",
    "            s_logits.view(-1), s_tensor.view(-1).float())\n",
    "        s_loss = torch.mean(s_loss)\n",
    "\n",
    "        # Content tensor loss (pitches)\n",
    "        # argmax is used to obtain token ids from onehot rep\n",
    "        pitch_logits = c_logits[:, :N_PITCH_TOKENS]\n",
    "        pitch_true = c_tensor[:, :N_PITCH_TOKENS].argmax(dim=1)\n",
    "        pitch_loss = self.ce_p(pitch_logits, pitch_true)\n",
    "\n",
    "        # Content tensor loss (durations)\n",
    "        dur_logits = c_logits[:, N_PITCH_TOKENS:]\n",
    "        dur_true = c_tensor[:, N_PITCH_TOKENS:].argmax(dim=1)\n",
    "        dur_loss = self.ce_d(dur_logits, dur_true)\n",
    "\n",
    "        # Kullback-Leibler divergence loss\n",
    "        # Derivation in Kingma, Diederik P., and Max Welling. \"Auto-encoding\n",
    "        # variational bayes.\" (2013), Appendix B.\n",
    "        # (https://arxiv.org/pdf/1312.6114.pdf)\n",
    "        kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(),\n",
    "                                    dim=1)\n",
    "        kld_loss = torch.mean(kld_loss)\n",
    "\n",
    "        # Reconstruction loss and total loss\n",
    "        rec_loss = pitch_loss + dur_loss + s_loss\n",
    "        tot_loss = rec_loss + self.beta*kld_loss\n",
    "\n",
    "        losses = {\n",
    "            'tot': tot_loss.item(),\n",
    "            'pitch': pitch_loss.item(),\n",
    "            'dur': dur_loss.item(),\n",
    "            'structure': s_loss.item(),\n",
    "            'reconstruction': rec_loss.item(),\n",
    "            'kld': kld_loss.item(),\n",
    "            'beta*kld': self.beta*kld_loss.item()\n",
    "        }\n",
    "\n",
    "        return tot_loss, losses\n",
    "\n",
    "    def _accuracies(self, s_tensor, s_logits, c_tensor, c_logits, is_drum):\n",
    "\n",
    "        # Do not consider SOS token\n",
    "        c_tensor = c_tensor[..., 1:, :]\n",
    "\n",
    "        # Reshape logits to match s_tensor dimensions:\n",
    "        # n_graphs (in batch) x n_tracks x n_timesteps\n",
    "        s_logits = s_tensor.reshape(-1, *s_logits.shape[2:])\n",
    "\n",
    "        # Note accuracy considers both pitches and durations\n",
    "        note_acc = self._note_accuracy(c_logits, c_tensor)\n",
    "\n",
    "        pitch_acc = self._pitch_accuracy(c_logits, c_tensor)\n",
    "\n",
    "        # Compute pitch accuracies for drums and non drums separately\n",
    "        pitch_acc_drums = self._pitch_accuracy(\n",
    "            c_logits, c_tensor, drums=True, is_drum=is_drum\n",
    "        )\n",
    "        pitch_acc_non_drums = self._pitch_accuracy(\n",
    "            c_logits, c_tensor, drums=False, is_drum=is_drum\n",
    "        )\n",
    "\n",
    "        dur_acc = self._duration_accuracy(c_logits, c_tensor)\n",
    "\n",
    "        s_acc = self._structure_accuracy(s_logits, s_tensor)\n",
    "        s_precision = self._structure_precision(s_logits, s_tensor)\n",
    "        s_recall = self._structure_recall(s_logits, s_tensor)\n",
    "        s_f1 = (2*s_recall*s_precision / (s_recall+s_precision))\n",
    "\n",
    "        accs = {\n",
    "            'note': note_acc.item(),\n",
    "            'pitch': pitch_acc.item(),\n",
    "            'pitch_drums': pitch_acc_drums.item(),\n",
    "            'pitch_non_drums': pitch_acc_non_drums.item(),\n",
    "            'dur': dur_acc.item(),\n",
    "            's_acc': s_acc.item(),\n",
    "            's_precision': s_precision.item(),\n",
    "            's_recall': s_recall.item(),\n",
    "            's_f1': s_f1.item()\n",
    "        }\n",
    "\n",
    "        return accs\n",
    "\n",
    "    def _pitch_accuracy(self, c_logits, c_tensor, drums=None, is_drum=None):\n",
    "\n",
    "        # When drums is None, just compute the global pitch accuracy without\n",
    "        # distinguishing between drum and non drum pitches\n",
    "        if drums is not None:\n",
    "            if drums:\n",
    "                c_logits = c_logits[is_drum]\n",
    "                c_tensor = c_tensor[is_drum]\n",
    "            else:\n",
    "                c_logits = c_logits[torch.logical_not(is_drum)]\n",
    "                c_tensor = c_tensor[torch.logical_not(is_drum)]\n",
    "\n",
    "        # Apply softmax to obtain pitch reconstructions\n",
    "        pitch_rec = c_logits[..., :N_PITCH_TOKENS]\n",
    "        pitch_rec = F.softmax(pitch_rec, dim=-1)\n",
    "        pitch_rec = torch.argmax(pitch_rec, dim=-1)\n",
    "\n",
    "        pitch_true = c_tensor[..., :N_PITCH_TOKENS]\n",
    "        pitch_true = torch.argmax(pitch_true, dim=-1)\n",
    "\n",
    "        # Do not consider PAD tokens when computing accuracies\n",
    "        not_pad = (pitch_true != PitchToken.PAD.value)\n",
    "\n",
    "        correct = (pitch_rec == pitch_true)\n",
    "        correct = torch.logical_and(correct, not_pad)\n",
    "\n",
    "        return torch.sum(correct) / torch.sum(not_pad)\n",
    "\n",
    "    def _duration_accuracy(self, c_logits, c_tensor):\n",
    "\n",
    "        # Apply softmax to obtain reconstructed durations\n",
    "        dur_rec = c_logits[..., N_PITCH_TOKENS:]\n",
    "        dur_rec = F.softmax(dur_rec, dim=-1)\n",
    "        dur_rec = torch.argmax(dur_rec, dim=-1)\n",
    "\n",
    "        dur_true = c_tensor[..., N_PITCH_TOKENS:]\n",
    "        dur_true = torch.argmax(dur_true, dim=-1)\n",
    "\n",
    "        # Do not consider PAD tokens when computing accuracies\n",
    "        not_pad = (dur_true != DurationToken.PAD.value)\n",
    "\n",
    "        correct = (dur_rec == dur_true)\n",
    "        correct = torch.logical_and(correct, not_pad)\n",
    "\n",
    "        return torch.sum(correct) / torch.sum(not_pad)\n",
    "\n",
    "    def _note_accuracy(self, c_logits, c_tensor):\n",
    "\n",
    "        # Apply softmax to obtain pitch reconstructions\n",
    "        pitch_rec = c_logits[..., :N_PITCH_TOKENS]\n",
    "        pitch_rec = F.softmax(pitch_rec, dim=-1)\n",
    "        pitch_rec = torch.argmax(pitch_rec, dim=-1)\n",
    "\n",
    "        pitch_true = c_tensor[..., :N_PITCH_TOKENS]\n",
    "        pitch_true = torch.argmax(pitch_true, dim=-1)\n",
    "\n",
    "        not_pad_p = (pitch_true != PitchToken.PAD.value)\n",
    "\n",
    "        correct_p = (pitch_rec == pitch_true)\n",
    "        correct_p = torch.logical_and(correct_p, not_pad_p)\n",
    "\n",
    "        dur_rec = c_logits[..., N_PITCH_TOKENS:]\n",
    "        dur_rec = F.softmax(dur_rec, dim=-1)\n",
    "        dur_rec = torch.argmax(dur_rec, dim=-1)\n",
    "\n",
    "        dur_true = c_tensor[..., N_PITCH_TOKENS:]\n",
    "        dur_true = torch.argmax(dur_true, dim=-1)\n",
    "\n",
    "        not_pad_d = (dur_true != DurationToken.PAD.value)\n",
    "\n",
    "        correct_d = (dur_rec == dur_true)\n",
    "        correct_d = torch.logical_and(correct_d, not_pad_d)\n",
    "\n",
    "        note_accuracy = torch.sum(\n",
    "            torch.logical_and(correct_p, correct_d)) / torch.sum(not_pad_p)\n",
    "\n",
    "        return note_accuracy\n",
    "\n",
    "    def _structure_accuracy(self, s_logits, s_tensor):\n",
    "\n",
    "        s_logits = torch.sigmoid(s_logits)\n",
    "        s_logits[s_logits < 0.5] = 0\n",
    "        s_logits[s_logits >= 0.5] = 1\n",
    "\n",
    "        return torch.sum(s_logits == s_tensor) / s_tensor.numel()\n",
    "\n",
    "    def _structure_precision(self, s_logits, s_tensor):\n",
    "\n",
    "        s_logits = torch.sigmoid(s_logits)\n",
    "        s_logits[s_logits < 0.5] = 0\n",
    "        s_logits[s_logits >= 0.5] = 1\n",
    "\n",
    "        tp = torch.sum(s_tensor[s_logits == 1])\n",
    "\n",
    "        return tp / torch.sum(s_logits)\n",
    "\n",
    "    def _structure_recall(self, s_logits, s_tensor):\n",
    "\n",
    "        s_logits = torch.sigmoid(s_logits)\n",
    "        s_logits[s_logits < 0.5] = 0\n",
    "        s_logits[s_logits >= 0.5] = 1\n",
    "\n",
    "        tp = torch.sum(s_tensor[s_logits == 1])\n",
    "\n",
    "        return tp / torch.sum(s_tensor)\n",
    "\n",
    "    def _save_model(self, filename):\n",
    "\n",
    "        path = os.path.join(self.model_dir, filename)\n",
    "        print(\"Saving model to disk...\")\n",
    "\n",
    "        torch.save({\n",
    "            'epoch': self.cur_epoch,\n",
    "            'batch': self.cur_batch_idx,\n",
    "            'tot_batches': self.tot_batches,\n",
    "            'betas': self.betas,\n",
    "            'min_val_loss': self.min_val_loss,\n",
    "            'print_every': self.print_every,\n",
    "            'save_every': self.save_every,\n",
    "            'eval_every': self.eval_every,\n",
    "            'lrs': self.lrs,\n",
    "            'tr_losses': self.tr_losses,\n",
    "            'tr_accuracies': self.tr_accuracies,\n",
    "            'val_losses': self.val_losses,\n",
    "            'val_accuracies': self.val_accuracies,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict()\n",
    "        }, path)\n",
    "\n",
    "        print(\"The model has been successfully saved.\")\n",
    "\n",
    "    def _print_stats(self):\n",
    "\n",
    "        hours, rem = divmod(self.times[-1]-self.times[0], 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        print(\"Elapsed time from start (h:m:s): {:0>2}:{:0>2}:{:05.2f}\"\n",
    "              .format(int(hours), int(minutes), seconds))\n",
    "\n",
    "        # Take mean of the last non-printed batches for each loss and accuracy\n",
    "        avg_losses = {}\n",
    "        for k, l in self.tr_losses.items():\n",
    "            v = mean(l[-self.print_every:])\n",
    "            avg_losses[k] = round(v, 2)\n",
    "\n",
    "        avg_accs = {}\n",
    "        for k, l in self.tr_accuracies.items():\n",
    "            v = mean(l[-self.print_every:])\n",
    "            avg_accs[k] = round(v, 2)\n",
    "\n",
    "        print(\"Losses:\")\n",
    "        pprint.pprint(avg_losses, indent=2)\n",
    "\n",
    "        print(\"Accuracies:\")\n",
    "        pprint.pprint(avg_accs, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 93,
=======
   "execution_count": 40,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "\n",
    "def print_params(model):\n",
    "\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "\n",
    "    for name, parameter in model.named_parameters():\n",
    "\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Parameters: {total_params}\")\n",
    "\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 94,
=======
   "execution_count": 41,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Loading the configuration file D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\training.json...\n",
=======
      "Loading the configuration file C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\training.json...\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "Preparing datasets and dataloaders...\n",
      "Creating the model and moving it to cpu device...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "c:\\Users\\elysi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
=======
      "C:\\Users\\s222445\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+------------+\n",
      "|                           Modules                           | Parameters |\n",
      "+-------------------------------------------------------------+------------+\n",
      "|         encoder.s_encoder.cnn_encoder.conv.0.weight         |     72     |\n",
      "|          encoder.s_encoder.cnn_encoder.conv.0.bias          |     8      |\n",
      "|         encoder.s_encoder.cnn_encoder.conv.1.weight         |     8      |\n",
      "|          encoder.s_encoder.cnn_encoder.conv.1.bias          |     8      |\n",
      "|         encoder.s_encoder.cnn_encoder.conv.4.weight         |    1152    |\n",
      "|          encoder.s_encoder.cnn_encoder.conv.4.bias          |     16     |\n",
      "|         encoder.s_encoder.cnn_encoder.conv.5.weight         |     16     |\n",
      "|          encoder.s_encoder.cnn_encoder.conv.5.bias          |     16     |\n",
      "|          encoder.s_encoder.cnn_encoder.lin.1.weight         |   262144   |\n",
      "|           encoder.s_encoder.cnn_encoder.lin.1.bias          |    512     |\n",
      "|          encoder.s_encoder.cnn_encoder.lin.4.weight         |   262144   |\n",
      "|           encoder.s_encoder.cnn_encoder.lin.4.bias          |    512     |\n",
      "|            encoder.s_encoder.bars_encoder.weight            |   524288   |\n",
      "|             encoder.s_encoder.bars_encoder.bias             |    512     |\n",
      "|         encoder.c_encoder.non_drums_pitch_emb.weight        |   33536    |\n",
      "|          encoder.c_encoder.non_drums_pitch_emb.bias         |    256     |\n",
      "|           encoder.c_encoder.drums_pitch_emb.weight          |   33536    |\n",
      "|            encoder.c_encoder.drums_pitch_emb.bias           |    256     |\n",
      "|               encoder.c_encoder.dur_emb.weight              |   25344    |\n",
      "|                encoder.c_encoder.dur_emb.bias               |    256     |\n",
      "|            encoder.c_encoder.bn_non_drums.weight            |    256     |\n",
      "|             encoder.c_encoder.bn_non_drums.bias             |    256     |\n",
      "|              encoder.c_encoder.bn_drums.weight              |    256     |\n",
      "|               encoder.c_encoder.bn_drums.bias               |    256     |\n",
      "|               encoder.c_encoder.bn_dur.weight               |    256     |\n",
      "|                encoder.c_encoder.bn_dur.bias                |    256     |\n",
      "|            encoder.c_encoder.chord_encoder.weight           |   786432   |\n",
      "|             encoder.c_encoder.chord_encoder.bias            |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.0.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.0.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.0.bias        |    512     |\n",
      "|      encoder.c_encoder.graph_encoder.layers.0.nn.weight     |   16384    |\n",
      "|       encoder.c_encoder.graph_encoder.layers.0.nn.bias      |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.1.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.1.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.1.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.2.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.2.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.2.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.3.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.3.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.3.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.4.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.4.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.4.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.5.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.5.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.5.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.6.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.6.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.6.bias        |    512     |\n",
      "|       encoder.c_encoder.graph_encoder.layers.7.weight       |  1572864   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.7.root        |   262144   |\n",
      "|        encoder.c_encoder.graph_encoder.layers.7.bias        |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.0.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.0.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.1.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.1.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.2.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.2.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.3.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.3.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.4.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.4.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.5.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.5.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.6.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.6.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_encoder.norm_layers.7.module.weight |    512     |\n",
      "|  encoder.c_encoder.graph_encoder.norm_layers.7.module.bias  |    512     |\n",
      "| encoder.c_encoder.graph_attention.gate_nn.0.layers.0.weight |    512     |\n",
      "|  encoder.c_encoder.graph_attention.gate_nn.0.layers.0.bias  |     1      |\n",
      "|      encoder.c_encoder.graph_attention.gate_nn.1.weight     |     1      |\n",
      "|       encoder.c_encoder.graph_attention.gate_nn.1.bias      |     1      |\n",
      "|            encoder.c_encoder.bars_encoder.weight            |   524288   |\n",
      "|             encoder.c_encoder.bars_encoder.bias             |    512     |\n",
      "|                 encoder.linear_merge.weight                 |   524288   |\n",
      "|                  encoder.linear_merge.bias                  |    512     |\n",
      "|                encoder.bn_linear_merge.weight               |    512     |\n",
      "|                 encoder.bn_linear_merge.bias                |    512     |\n",
      "|                   encoder.linear_mu.weight                  |   262144   |\n",
      "|                    encoder.linear_mu.bias                   |    512     |\n",
      "|                encoder.linear_log_var.weight                |   262144   |\n",
      "|                 encoder.linear_log_var.bias                 |    512     |\n",
      "|                  decoder.lin_decoder.weight                 |   524288   |\n",
      "|                   decoder.lin_decoder.bias                  |    1024    |\n",
      "|                  decoder.batch_norm.weight                  |    1024    |\n",
      "|                   decoder.batch_norm.bias                   |    1024    |\n",
      "|            decoder.s_decoder.bars_decoder.weight            |   524288   |\n",
      "|             decoder.s_decoder.bars_decoder.bias             |    1024    |\n",
      "|          decoder.s_decoder.cnn_decoder.lin.1.weight         |   262144   |\n",
      "|           decoder.s_decoder.cnn_decoder.lin.1.bias          |    512     |\n",
      "|          decoder.s_decoder.cnn_decoder.lin.4.weight         |   262144   |\n",
      "|           decoder.s_decoder.cnn_decoder.lin.4.bias          |    512     |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.1.weight         |    1152    |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.1.bias          |     8      |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.2.weight         |     8      |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.2.bias          |     8      |\n",
      "|         decoder.s_decoder.cnn_decoder.conv.4.weight         |     72     |\n",
      "|          decoder.s_decoder.cnn_decoder.conv.4.bias          |     1      |\n",
      "|            decoder.c_decoder.bars_decoder.weight            |   524288   |\n",
      "|             decoder.c_decoder.bars_decoder.bias             |    1024    |\n",
      "|       decoder.c_decoder.graph_decoder.layers.0.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.0.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.0.bias        |    512     |\n",
      "|      decoder.c_decoder.graph_decoder.layers.0.nn.weight     |   16384    |\n",
      "|       decoder.c_decoder.graph_decoder.layers.0.nn.bias      |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.1.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.1.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.1.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.2.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.2.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.2.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.3.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.3.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.3.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.4.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.4.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.4.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.5.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.5.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.5.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.6.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.6.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.6.bias        |    512     |\n",
      "|       decoder.c_decoder.graph_decoder.layers.7.weight       |  1572864   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.7.root        |   262144   |\n",
      "|        decoder.c_decoder.graph_decoder.layers.7.bias        |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.0.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.0.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.1.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.1.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.2.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.2.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.3.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.3.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.4.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.4.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.5.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.5.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.6.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.6.module.bias  |    512     |\n",
      "| decoder.c_decoder.graph_decoder.norm_layers.7.module.weight |    512     |\n",
      "|  decoder.c_decoder.graph_decoder.norm_layers.7.module.bias  |    512     |\n",
      "|            decoder.c_decoder.chord_decoder.weight           |   786432   |\n",
      "|             decoder.c_decoder.chord_decoder.bias            |    1536    |\n",
      "|           decoder.c_decoder.drums_pitch_emb.weight          |   33536    |\n",
      "|            decoder.c_decoder.drums_pitch_emb.bias           |    131     |\n",
      "|         decoder.c_decoder.non_drums_pitch_emb.weight        |   33536    |\n",
      "|          decoder.c_decoder.non_drums_pitch_emb.bias         |    131     |\n",
      "|               decoder.c_decoder.dur_emb.weight              |   25344    |\n",
      "|                decoder.c_decoder.dur_emb.bias               |     99     |\n",
      "+-------------------------------------------------------------+------------+\n",
      "Total Trainable Parameters: 35913309\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
<<<<<<< HEAD
     "text": []
=======
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
<<<<<<< HEAD
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([7104, 4, 230])\n"
=======
      "torch.Size([512, 4, 230])\n"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
<<<<<<< HEAD
     "text": []
=======
     "text": [
      " 33%|███▎      | 1/3 [00:02<00:04,  2.34s/it]"
     ]
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Training on batch 1/1 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:18.09\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 4.5,\n",
      "  'kld': 62.75,\n",
      "  'pitch': 5.09,\n",
      "  'reconstruction': 10.0,\n",
      "  'structure': 0.41,\n",
      "  'tot': 10.0}\n",
      "Accuracies:\n",
      "{ 'dur': 0.15,\n",
=======
      "Training on batch 1/3 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:02.38\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 6.04,\n",
      "  'kld': 53.9,\n",
      "  'pitch': 5.89,\n",
      "  'reconstruction': 12.24,\n",
      "  'structure': 0.31,\n",
      "  'tot': 12.24}\n",
      "Accuracies:\n",
      "{ 'dur': 0.0,\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "  'note': 0.0,\n",
      "  'pitch': 0.0,\n",
      "  'pitch_drums': 0.0,\n",
      "  'pitch_non_drums': 0.0,\n",
<<<<<<< HEAD
      "  's_acc': 0.75,\n",
      "  's_f1': 0.86,\n",
      "  's_precision': 0.75,\n",
=======
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
<<<<<<< HEAD
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([7104, 4, 230])\n"
=======
      "torch.Size([512, 4, 230])\n"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
<<<<<<< HEAD
     "text": []
=======
     "text": [
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.11s/it]"
     ]
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Training on batch 1/1 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:33.28\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 4.43,\n",
      "  'kld': 63.47,\n",
      "  'pitch': 5.03,\n",
      "  'reconstruction': 9.87,\n",
      "  'structure': 0.41,\n",
      "  'tot': 9.87}\n",
      "Accuracies:\n",
      "{ 'dur': 0.16,\n",
=======
      "Training on batch 2/3 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:04.34\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 5.99,\n",
      "  'kld': 59.03,\n",
      "  'pitch': 5.87,\n",
      "  'reconstruction': 12.17,\n",
      "  'structure': 0.31,\n",
      "  'tot': 12.17}\n",
      "Accuracies:\n",
      "{ 'dur': 0.0,\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "  'note': 0.0,\n",
      "  'pitch': 0.0,\n",
      "  'pitch_drums': 0.0,\n",
      "  'pitch_non_drums': 0.0,\n",
<<<<<<< HEAD
      "  's_acc': 0.75,\n",
      "  's_f1': 0.86,\n",
      "  's_precision': 0.75,\n",
=======
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
<<<<<<< HEAD
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([7104, 4, 230])\n"
=======
      "torch.Size([512, 4, 230])\n"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
<<<<<<< HEAD
     "text": []
=======
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.01s/it]"
     ]
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Training on batch 1/1 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:47.40\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 3.13,\n",
      "  'kld': 61.83,\n",
      "  'pitch': 4.0,\n",
      "  'reconstruction': 7.53,\n",
      "  'structure': 0.41,\n",
      "  'tot': 7.53}\n",
      "Accuracies:\n",
      "{ 'dur': 0.35,\n",
      "  'note': 0.03,\n",
      "  'pitch': 0.08,\n",
      "  'pitch_drums': 0.01,\n",
      "  'pitch_non_drums': 0.12,\n",
      "  's_acc': 0.75,\n",
      "  's_f1': 0.86,\n",
      "  's_precision': 0.75,\n",
=======
      "Training on batch 3/3 of epoch 1/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:06.23\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 4.63,\n",
      "  'kld': 51.14,\n",
      "  'pitch': 4.79,\n",
      "  'reconstruction': 9.73,\n",
      "  'structure': 0.31,\n",
      "  'tot': 9.73}\n",
      "Accuracies:\n",
      "{ 'dur': 0.07,\n",
      "  'note': 0.0,\n",
      "  'pitch': 0.0,\n",
      "  'pitch_drums': 0.0,\n",
      "  'pitch_non_drums': 0.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
<<<<<<< HEAD
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([7104, 4, 230])\n"
=======
      "torch.Size([512, 4, 230])\n"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
<<<<<<< HEAD
     "text": []
=======
     "text": [
      "4it [00:08,  1.94s/it]                       "
     ]
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Training on batch 1/1 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:04.24\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 1.99,\n",
      "  'kld': 62.18,\n",
      "  'pitch': 3.01,\n",
      "  'reconstruction': 5.41,\n",
      "  'structure': 0.41,\n",
      "  'tot': 5.41}\n",
      "Accuracies:\n",
      "{ 'dur': 0.6,\n",
      "  'note': 0.28,\n",
      "  'pitch': 0.38,\n",
      "  'pitch_drums': 0.11,\n",
      "  'pitch_non_drums': 0.52,\n",
      "  's_acc': 0.75,\n",
      "  's_f1': 0.86,\n",
      "  's_precision': 0.75,\n",
=======
      "Training on batch 1/3 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:08.06\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 3.29,\n",
      "  'kld': 48.34,\n",
      "  'pitch': 3.76,\n",
      "  'reconstruction': 7.36,\n",
      "  'structure': 0.31,\n",
      "  'tot': 7.36}\n",
      "Accuracies:\n",
      "{ 'dur': 0.29,\n",
      "  'note': 0.06,\n",
      "  'pitch': 0.21,\n",
      "  'pitch_drums': 0.0,\n",
      "  'pitch_non_drums': 0.28,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
<<<<<<< HEAD
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([7104, 4, 230])\n"
=======
      "torch.Size([512, 4, 230])\n"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
<<<<<<< HEAD
     "text": []
=======
     "text": [
      "5it [00:09,  1.95s/it]"
     ]
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Training on batch 1/1 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:01:21.54\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 1.08,\n",
      "  'kld': 61.85,\n",
      "  'pitch': 2.13,\n",
      "  'reconstruction': 3.61,\n",
      "  'structure': 0.41,\n",
      "  'tot': 3.61}\n",
      "Accuracies:\n",
      "{ 'dur': 0.96,\n",
      "  'note': 0.7,\n",
      "  'pitch': 0.72,\n",
      "  'pitch_drums': 0.39,\n",
      "  'pitch_non_drums': 0.89,\n",
      "  's_acc': 0.75,\n",
      "  's_f1': 0.86,\n",
      "  's_precision': 0.75,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "Training completed in (h:m:s): 00:01:21.54\n",
=======
      "Training on batch 2/3 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:10.02\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 2.09,\n",
      "  'kld': 48.69,\n",
      "  'pitch': 2.82,\n",
      "  'reconstruction': 5.23,\n",
      "  'structure': 0.31,\n",
      "  'tot': 5.23}\n",
      "Accuracies:\n",
      "{ 'dur': 0.5,\n",
      "  'note': 0.27,\n",
      "  'pitch': 0.58,\n",
      "  'pitch_drums': 0.0,\n",
      "  'pitch_non_drums': 0.77,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:12,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 3/3 of epoch 2/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:12.14\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 1.1,\n",
      "  'kld': 45.69,\n",
      "  'pitch': 2.02,\n",
      "  'reconstruction': 3.43,\n",
      "  'structure': 0.31,\n",
      "  'tot': 3.43}\n",
      "Accuracies:\n",
      "{ 'dur': 0.99,\n",
      "  'note': 0.68,\n",
      "  'pitch': 0.68,\n",
      "  'pitch_drums': 0.08,\n",
      "  'pitch_non_drums': 0.88,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:14,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/3 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:14.45\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.48,\n",
      "  'kld': 46.55,\n",
      "  'pitch': 1.49,\n",
      "  'reconstruction': 2.28,\n",
      "  'structure': 0.31,\n",
      "  'tot': 2.28}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.72,\n",
      "  'pitch': 0.72,\n",
      "  'pitch_drums': 0.23,\n",
      "  'pitch_non_drums': 0.89,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:16,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 2/3 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:16.64\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.18,\n",
      "  'kld': 41.3,\n",
      "  'pitch': 1.11,\n",
      "  'reconstruction': 1.6,\n",
      "  'structure': 0.31,\n",
      "  'tot': 1.6}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.77,\n",
      "  'pitch': 0.77,\n",
      "  'pitch_drums': 0.41,\n",
      "  'pitch_non_drums': 0.89,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:18,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 3/3 of epoch 3/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:18.78\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.07,\n",
      "  'kld': 42.64,\n",
      "  'pitch': 0.8,\n",
      "  'reconstruction': 1.18,\n",
      "  'structure': 0.31,\n",
      "  'tot': 1.18}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.85,\n",
      "  'pitch': 0.85,\n",
      "  'pitch_drums': 0.55,\n",
      "  'pitch_non_drums': 0.95,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n",
      "Training on batch 1/3 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:20.86\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.02,\n",
      "  'kld': 42.98,\n",
      "  'pitch': 0.62,\n",
      "  'reconstruction': 0.96,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.96}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.84,\n",
      "  'pitch': 0.84,\n",
      "  'pitch_drums': 0.54,\n",
      "  'pitch_non_drums': 0.94,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "\n",
      "Evaluating on validation set...\n",
      "\n",
      "Starting evaluation with 0 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val losses:\n",
      "{}\n",
      "Val accuracies:\n",
      "{}\n",
      "Key 'tot' not found in val_losses. Setting tot_loss to 0.\n",
      "\n",
      "Validation loss improved.\n",
      "Saving new best model to disk...\n",
      "\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "Saving model to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "5it [01:21, 16.39s/it]"
=======
      "\n",
      "10it [00:21,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been successfully saved.\n",
      "Saving model to disk...\n",
      "The model has been successfully saved.\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:24,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 2/3 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:24.28\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.01,\n",
      "  'kld': 44.01,\n",
      "  'pitch': 0.44,\n",
      "  'reconstruction': 0.76,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.76}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.88,\n",
      "  'pitch': 0.88,\n",
      "  'pitch_drums': 0.59,\n",
      "  'pitch_non_drums': 0.97,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:26,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 3/3 of epoch 4/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:26.28\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 48.18,\n",
      "  'pitch': 0.26,\n",
      "  'reconstruction': 0.58,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.58}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 1.0,\n",
      "  'pitch': 1.0,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 1.0,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:28,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1/3 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:28.40\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 45.26,\n",
      "  'pitch': 0.18,\n",
      "  'reconstruction': 0.49,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.49}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.99,\n",
      "  'pitch': 0.99,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 0.98,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:30,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 2/3 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:30.57\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 44.11,\n",
      "  'pitch': 0.1,\n",
      "  'reconstruction': 0.42,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.42}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.99,\n",
      "  'pitch': 0.99,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 0.99,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([4, 64, 4, 2])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 64, 4, 2])\n",
      "torch.Size([2, 2, 32, 4, 131])\n",
      "torch.Size([2, 2, 32, 4, 99])\n",
      "torch.Size([2, 2, 32, 4, 230])\n",
      "torch.Size([4, 2, 32, 4, 230])\n",
      "torch.Size([512, 4, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:32,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 3/3 of epoch 5/5 complete.\n",
      "Elapsed time from start (h:m:s): 00:00:32.84\n",
      "Losses:\n",
      "{ 'beta*kld': 0.0,\n",
      "  'dur': 0.0,\n",
      "  'kld': 45.43,\n",
      "  'pitch': 0.08,\n",
      "  'reconstruction': 0.39,\n",
      "  'structure': 0.31,\n",
      "  'tot': 0.39}\n",
      "Accuracies:\n",
      "{ 'dur': 1.0,\n",
      "  'note': 0.98,\n",
      "  'pitch': 0.98,\n",
      "  'pitch_drums': 1.0,\n",
      "  'pitch_non_drums': 0.97,\n",
      "  's_acc': 1.0,\n",
      "  's_f1': 1.0,\n",
      "  's_precision': 1.0,\n",
      "  's_recall': 1.0}\n",
      "————————————————————————————————————————\n",
      "Training completed in (h:m:s): 00:00:32.84\n",
      "Saving model to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:33,  2.22s/it]"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been successfully saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "# Ensure you have imported PolyphemusDataset, VAE, set_seed, print_params, print_divider, PolyphemusTrainer, ExpDecayLRScheduler, StepBetaScheduler correctly\n",
    "\n",
    "# Configuration and setup\n",
<<<<<<< HEAD
    "dataset_dir = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\preprocessed\"\n",
    "output_dir = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\output\"\n",
    "config_file = r\"D:\\Desktop\\DTU Masters\\Master's Thesis\\Week 8 Model Building Continuous\\training.json\"\n",
=======
    "dataset_dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\preprocessed'\n",
    "output_dir = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\output'\n",
    "config_file = r'C:\\Users\\s222445\\Spatiotemporal GNN Thesis\\training.json'\n",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
    "model_name = 'testing_continuous lat lon emotions'  # or None to use a UUID\n",
    "save_every = 10\n",
    "print_every = 1\n",
    "eval_flag = True  # Set to False if you don't want to perform evaluation\n",
    "eval_every = 10  \n",
    "use_gpu = False\n",
    "gpu_id = 0\n",
    "num_workers = 0\n",
    "tr_split = 0.7\n",
    "vl_split = 0.1\n",
    "max_epochs = 5\n",
    "seed = 42  # or None\n",
    "\n",
    "# Set seed for reproducibility\n",
    "if seed is not None:\n",
    "    set_seed(seed)\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "#if use_gpu:\n",
    "#    torch.cuda.set_device(gpu_id)\n",
    "\n",
    "# Load training configuration from JSON file\n",
    "print(f\"Loading the configuration file {config_file}...\")\n",
    "with open(config_file, 'r') as f:\n",
    "    training_config = json.load(f)\n",
    "\n",
    "n_bars = training_config['model']['n_bars']\n",
    "batch_size = training_config['batch_size']\n",
    "\n",
    "# Prepare datasets and dataloaders\n",
    "print(\"Preparing datasets and dataloaders...\")\n",
    "dataset = PolyphemusDataset(dataset_dir, n_bars)\n",
    "\n",
    "tr_len = int(tr_split * len(dataset))\n",
    "vl_len = int(vl_split * len(dataset)) if eval_flag else 0\n",
    "ts_len = len(dataset) - tr_len - vl_len\n",
    "lengths = (tr_len, vl_len, ts_len) if eval_flag else (tr_len, len(dataset) - tr_len)\n",
    "\n",
    "split = random_split(dataset, lengths)\n",
    "tr_set, vl_set = split[0], (split[1] if eval_flag else None)\n",
    "\n",
    "trainloader = DataLoader(tr_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validloader = DataLoader(vl_set, batch_size=batch_size, shuffle=False, num_workers=num_workers) if eval_flag else None\n",
    "\n",
    "# Model setup\n",
    "model_dir = os.path.join(output_dir, model_name or str(uuid.uuid1()))\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=False)\n",
    "\n",
    "print(f\"Creating the model and moving it to {device} device...\")\n",
    "vae = VAE(**training_config['model'], device=device).to(device)\n",
    "print_params(vae)\n",
    "\n",
    "# Optimizer and schedulers setup\n",
    "optimizer = optim.Adam(vae.parameters(), **training_config['optimizer'])\n",
    "lr_scheduler = ExpDecayLRScheduler(optimizer=optimizer, **training_config['lr_scheduler'])\n",
    "beta_scheduler = StepBetaScheduler(**training_config['beta_scheduler'])\n",
    "\n",
    "# Save configuration\n",
    "config_path = os.path.join(model_dir, 'configuration.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(training_config, f)\n",
    "\n",
    "# Training\n",
    "print(\"Starting training...\")\n",
    "trainer = PolyphemusTrainer(\n",
    "    model_dir=model_dir,\n",
    "    model=vae,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    beta_scheduler=beta_scheduler,\n",
    "    save_every=save_every,\n",
    "    print_every=print_every,\n",
    "    eval_every=eval_every,\n",
    "    device=device\n",
    ")\n",
    "trainer.train(trainloader, validloader=validloader, epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 95,
=======
   "execution_count": 42,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "\n",
    "def plot_structure(s_tensor, save_dir=None, name='structure'):\n",
    "\n",
    "    lines_linewidth = 1\n",
    "    axes_linewidth = 1\n",
    "    font_size = 14\n",
    "    fformat = 'svg'\n",
    "    dpi = 200\n",
    "\n",
    "    n_bars = s_tensor.shape[0]\n",
    "    figsize = (3 * n_bars, 3)\n",
    "\n",
    "    n_timesteps = s_tensor.size(2)\n",
    "    resolution = n_timesteps // 4\n",
    "    s_tensor = s_tensor.permute(1, 0, 2)\n",
    "    s_tensor = s_tensor.reshape(s_tensor.shape[0], -1)\n",
    "\n",
    "    with mpl.rc_context({'lines.linewidth': lines_linewidth,\n",
    "                         'axes.linewidth': axes_linewidth,\n",
    "                         'font.size': font_size}):\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.pcolormesh(s_tensor, edgecolors='k', linewidth=1)\n",
    "        ax = plt.gca()\n",
    "\n",
    "        plt.xticks(range(0, s_tensor.shape[1], resolution),\n",
    "                   range(1, 4*n_bars + 1))\n",
    "        plt.yticks(range(0, s_tensor.shape[0]), TRACKS)\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        if save_dir:\n",
    "            plt.savefig(os.path.join(save_dir, name + \".\" + fformat),\n",
    "                        format=fformat, dpi=dpi)\n",
    "    \n",
    "    \n",
    "def plot_stats(stat_names, stats_tr, stats_val=None, eval_every=None, \n",
    "               labels=None, rx=None, ry=None):\n",
    "\n",
    "    for i, stat in enumerate(stat_names):\n",
    "\n",
    "        label = stat if not labels else labels[i]\n",
    "\n",
    "        plt.plot(range(1, len(stats_tr[stat])+1), stats_tr[stat],\n",
    "                label=label+' (TR)')\n",
    "\n",
    "        if stats_val:\n",
    "            plt.plot(range(eval_every, len(stats_tr[stat])+1, eval_every),\n",
    "                    stats_val[stat], '.', label=label+' (VL)')\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.ylim(ry) if ry else plt.ylim(0)\n",
    "    plt.xlim(rx) if rx else plt.xlim(0)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "# Dictionary that maps loss statistic name to plot label \n",
    "loss_labels = {\n",
    "    'tot': 'Total Loss',\n",
    "    'structure': 'Structure',\n",
    "    'pitch': 'Pitches',\n",
    "    'dur': 'Duration',\n",
    "    'reconstruction': 'Reconstruction Term',\n",
    "    'kld': 'KLD',\n",
    "    'beta*kld': 'beta * KLD'\n",
    "}\n",
    "\n",
    "\n",
    "def plot_losses(model_dir, losses, plot_val=False):\n",
    "    \n",
    "    checkpoint_path = os.path.join(model_dir, 'checkpoint')\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    labels = [loss_labels[loss] for loss in losses]\n",
    "    \n",
    "    tr_losses = checkpoint['tr_losses']\n",
    "    val_losses = checkpoint['val_losses'] if plot_val == True else None\n",
    "    eval_every = checkpoint['eval_every'] if plot_val == True else None\n",
    "\n",
    "    plot_stats(losses, tr_losses, stats_val=val_losses,\n",
    "               eval_every=eval_every, labels=labels, rx=(0))\n",
    "    \n",
    "\n",
    "# Dictionary that maps accuracy statistic name to plot label \n",
    "accuracy_labels = {\n",
    "    's_acc': 'Struct. Accuracy',\n",
    "    's_precision': 'Struct. Precision',\n",
    "    's_recall': 'Struct. Recall',\n",
    "    's_f1': 'Struct. F1',\n",
    "    'pitch': 'Pitch Accuracy',\n",
    "    'pitch_drums': 'Pitch Accuracy (Drums)',\n",
    "    'pitch_non_drums': 'Pitch Accuracy (Non Drums)',\n",
    "    'dur': 'Duration Accuracy',\n",
    "    'note': 'Note Accuracy'\n",
    "}\n",
    "\n",
    "\n",
    "def plot_accuracies(model_dir, accuracies, plot_val=False):\n",
    "    \n",
    "    checkpoint_path = os.path.join(model_dir, 'checkpoint')\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    labels = [accuracy_labels[accuracy] for accuracy in accuracies]\n",
    "    \n",
    "    tr_accuracies = checkpoint['tr_accuracies']\n",
    "    val_accuracies = checkpoint['val_accuracies'] if plot_val == True else None\n",
    "    eval_every = checkpoint['eval_every'] if plot_val == True else None\n",
    "\n",
    "    plot_stats(accuracies, tr_accuracies, stats_val=val_accuracies,\n",
    "               eval_every=eval_every, labels=labels, ry=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [02:50<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
=======
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming your model's directory is 'model_dir'\n",
    "plot_losses(model_dir='output/testing_continuous lat lon emotions', losses=['tot', 'structure', 'pitch'], plot_val=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 97,
=======
   "execution_count": 45,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
=======
      "image/png": "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",
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming your model's directory is 'model_dir'\n",
    "plot_accuracies(model_dir='output/testing_continuous lat lon emotions', accuracies=['s_acc', 'pitch', 'dur'], plot_val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Reconstruction"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 98,
=======
   "execution_count": null,
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_original_data(data, title='Original Data', samples=5):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(samples):\n",
    "        plt.subplot(samples, 1, i+1) \n",
    "        plt.plot(data[i], marker='o', linestyle='-')\n",
    "        plt.title(f\"{title} for Sample {i+1}\")\n",
    "        plt.ylabel('Value')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
<<<<<<< HEAD
    "#plot_original_data(emotions, title='Original Emotions')\n"
=======
    "plot_original_data(emotions, title='Original Emotions')\n"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.6"
=======
   "version": "3.11.9"
>>>>>>> 7dca5082d7e7cb0049fdb9a8a48f20f1823f623c
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
