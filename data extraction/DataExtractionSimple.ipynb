{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for Open Data Extraction - Emotional Cities Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm  # Use tqdm.notebook for Jupyter integration\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapillary \n",
    "\n",
    "Remember to get mappilary api token, and replace teh xx in teh mapillary script with yours :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading images \n",
    "\n",
    "# input your own paths here\n",
    "# Adjust number of images to download, image size and radius\n",
    "\n",
    "!python3 mapillary.py --dest_dir \"/your/dest_dir/path\" --input_file \"/path/to/input/file/with/Coordinates.csv\" --image_size 2048 --n_images 250 --radius 24\n",
    "\n",
    "# This will give you directories for each coordinate, that have all images downloaded with different imageIds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class descriptions\n",
    "class_descriptions = {\n",
    "    13: \"Road Features\", 24: \"Road Features\", 41: \"Road Features\",  # Road, Lane Marking, Manhole\n",
    "    2: \"Pedestrian Areas\", 15: \"Pedestrian Areas\",  # Sidewalk, Curb\n",
    "    17: \"Building\",  # Building\n",
    "    6: \"Wall\",  # Wall\n",
    "    3: \"Fence\",  # Fence\n",
    "    45: \"Pole\", 47: \"Pole\",  # Pole, Utility Pole\n",
    "    48: \"Traffic Light\",  # Traffic Light\n",
    "    50: \"Traffic Sign\",  # Traffic Sign (Front)\n",
    "    30: \"Vegetation\",  # Vegetation\n",
    "    29: \"Terrain\",  # Terrain\n",
    "    27: \"Sky\",  # Sky\n",
    "    19: \"Person\",  # Person\n",
    "    20: \"Riders\", 21: \"Riders\", 22: \"Riders\",  # Bicyclist, Motorcyclist, Other Rider\n",
    "    55: \"Car\",  # Car\n",
    "    61: \"Truck\",  # Truck\n",
    "    54: \"Bus\",  # Bus\n",
    "    58: \"On Rails\",  # On Rails\n",
    "    57: \"Motorcycle\",  # Motorcycle\n",
    "    52: \"Bicycle\",  # Bicycle\n",
    "    1: \"Car\",  # Caravan\n",
    "    53: \"Truck\"  # Trailer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation to get percentage of features for each coordinate (averaged over all images) \n",
    "\n",
    "!python3 mapillarySegmentation.py --input_dir \"/path/to/directory/with/Images\" --dest_dir \"/your/dest_dir/path\"\n",
    "\n",
    "# This will give you a csv file with all the features and their percentages for each coordinate\n",
    "\n",
    "# The approach could be changed if there are other opininions on how thsi could be done, hence cumulative or normalised mean could be used\n",
    "# also classes can be adjusted to get more or less features, in teh segmentation.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Determening amount of images needed to have stable std, based on one coordinate that is known to be complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 226/226 [05:07<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 226 images. Current Mean Std Deviation: 8.72959947935563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the processor and model globally\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-mapillary-vistas-semantic\")\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-mapillary-vistas-semantic\")\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Process a single image and return semantic segmentation results as percentages.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predicted_map = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "\n",
    "    unique_classes, counts = torch.unique(predicted_map, return_counts=True)\n",
    "    total_pixels = counts.sum().item()\n",
    "    features = {}\n",
    "\n",
    "    class_descriptions = {\n",
    "        13: \"Road Features\", 24: \"Road Features\", 41: \"Road Features\",\n",
    "        2: \"Pedestrian Areas\", 15: \"Pedestrian Areas\",\n",
    "        17: \"Building\",\n",
    "        6: \"Wall\", 3: \"Fence\", 45: \"Pole\", 47: \"Pole\",\n",
    "        48: \"Traffic Light\", 50: \"Traffic Sign\",\n",
    "        30: \"Vegetation\", 29: \"Terrain\", 27: \"Sky\",\n",
    "        19: \"Person\", 20: \"Riders\", 21: \"Riders\", 22: \"Riders\",\n",
    "        55: \"Car\", 61: \"Truck\", 54: \"Bus\", 58: \"On Rails\", 57: \"Motorcycle\", 52: \"Bicycle\"\n",
    "    }\n",
    "\n",
    "    for cls, count in zip(unique_classes.numpy(), counts.numpy()):\n",
    "        label = class_descriptions.get(cls, \"Unknown\")\n",
    "        if label != \"Unknown\":\n",
    "            if label not in features:\n",
    "                features[label] = 0\n",
    "            features[label] += count.item()\n",
    "\n",
    "    features = {k: (v / total_pixels) * 100 for k, v in features.items()}\n",
    "    return features\n",
    "\n",
    "def aggregate_and_check_stability(input_dir):\n",
    "    \"\"\"Aggregate features over images and check stability of mean feature percentages.\"\"\"\n",
    "    feature_list = []\n",
    "    images = [img for img in os.listdir(input_dir) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    for i, img_name in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "        img_path = os.path.join(input_dir, img_name)\n",
    "        features = process_image(img_path)\n",
    "        feature_list.append(features)\n",
    "        \n",
    "        if len(feature_list) > 1:\n",
    "            df = pd.DataFrame(feature_list)\n",
    "            mean_features = df.mean()\n",
    "            std_dev = mean_features.std()\n",
    "            if std_dev < 0.05:  # Stability threshold\n",
    "                print(f\"Stability achieved with {i+1} images.\")\n",
    "                break\n",
    "\n",
    "    print(f\"Processed {i+1} images. Current Mean Std Deviation: {std_dev}\")\n",
    "\n",
    "# Define the directory containing images\n",
    "input_dir = '/home/s184310/3.Project/data/testing_data/nørreportTest/55.68333_12.57167'\n",
    "aggregate_and_check_stability(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Street Maps\n",
    "\n",
    "GET CARLSO TO GIVE YOU ACCES, it's already ready :) \n",
    "\n",
    "For this you need acess to the server where there is a map of teh city your are working with, thi is in order to work around teh limited number of times you can ping osm.\n",
    "Data will thereby be extracted a local copy of OSM running on a private server. This setup allows for much faster data extraction processes which would take days/weeks otherwise for very short list of points (I believe Overpass begins to throttle requests after x amounts of requests are done). Once everything is set up the code can be run, linking to the private server endpoint. For the private server of OSM/Overpass I refer you to this repo: https://github.com/wiktorn/Overpass-API  . There is also this page that might help https://wiki.openstreetmap.org/wiki/Overpass_API/Installation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urban Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieveing Urban metrics for csv file of coordinates\n",
    "\n",
    "# Again input your file paths and adjust the number of nodes and radius (osm works with nodes that you can find withing a certain radius)\n",
    "# Network can be adjusted to be walk, bike, drive or all \n",
    "!python3 OsmUrbanMetrics.py --dest_dir=\"/path\" --input_file=\"/path/coordinates.csv\" --radius=49 --num_nodes=55 --network=\"all\"\n",
    "\n",
    "# This will give you a csv file with all the urban metrics for each coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POIs\n",
    "\n",
    "For now this just retieves poir and then cleanes tehm based on the tags you want (see tags.py). Later on (after information from portuga) there will me metrics calculated from teh POI's retreived liek vobrancy etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 OsmPoiRetrieval.py --dest_dir=\"/path\" --input_file=\"/path/coordinates.csv\" --radius=72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 OsmPoiTidy.py --dest_dir=\"/path\" --input_file=\"/pathpoiRetrieved.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
