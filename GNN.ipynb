{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from itertools import product\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.collate import collate\n",
    "import itertools\n",
    "from enum import Enum\n",
    "\n",
    "# Constants definitions\n",
    "MAX_SIMU_TOKENS = 5 \n",
    "\n",
    "class PitchToken:\n",
    "    SOS = 0  # Start of sequence, example value\n",
    "\n",
    "class DurationToken:\n",
    "    SOS = 0  # Start of sequence, example value\n",
    "\n",
    "N_DISCRETE_VALUES = 128  \n",
    "N_SAMPLES = 100  \n",
    "N_TIMESTEPS = 100  \n",
    "\n",
    "# EdgeTypes for simplicity\n",
    "class EdgeTypes(Enum):\n",
    "    TRACK = 0\n",
    "    ONSET = 1\n",
    "    NEXT = 2\n",
    "    N_EDGE_TYPES = 3  # Total number of edge types\n",
    "\n",
    "def generate_sample_data(num_samples, n_timesteps):\n",
    "    np.random.seed(42)  \n",
    "    emotions = np.random.randint(0, N_DISCRETE_VALUES, (num_samples, n_timesteps))\n",
    "    locations = np.random.randint(0, N_DISCRETE_VALUES, (num_samples, n_timesteps))\n",
    "    activities = np.random.randint(0, N_DISCRETE_VALUES, (num_samples, n_timesteps))\n",
    "    modes = np.random.randint(0, N_DISCRETE_VALUES, (num_samples, n_timesteps))\n",
    "    return emotions, locations, activities, modes\n",
    "\n",
    "def preprocess_data(data, n_bars, resolution):\n",
    "    \"\"\"\n",
    "    Preprocess the sample data to create content and structure tensors.\n",
    "    \"\"\"\n",
    "    num_samples, n_timesteps = data[0].shape\n",
    "    length = n_timesteps\n",
    "\n",
    "    # Initialize content and structure tensors\n",
    "    c_tensor = np.zeros((num_samples, length, MAX_SIMU_TOKENS, 2), np.int16)\n",
    "    s_tensor = np.zeros((num_samples, length), dtype=bool)\n",
    "\n",
    "    for i, sample in enumerate(zip(*data)):\n",
    "        for t in range(length):\n",
    "            c_tensor[i, t, 0, 0] = PitchToken.SOS  # Start of sequence\n",
    "            c_tensor[i, t, 1, 0] = sample[0][t]  # Emotions as pitch\n",
    "            c_tensor[i, t, 2, 0] = sample[1][t]  # Locations as pitch\n",
    "            c_tensor[i, t, 3, 0] = sample[2][t]  # Activities as pitch\n",
    "            c_tensor[i, t, 4, 0] = sample[3][t]  # Modes as pitch\n",
    "            c_tensor[i, t, :, 1] = DurationToken.SOS  # Using SOS token for duration for simplicity\n",
    "            s_tensor[i, t] = True  # Example, setting structure tensor\n",
    "\n",
    "    # Apply sliding window to generate sequences\n",
    "    sequences = []\n",
    "    for i in range(0, length - n_bars * resolution + 1, resolution):\n",
    "        seq_c_tensor = c_tensor[:, i:i + n_bars * resolution, :, :]\n",
    "        seq_s_tensor = s_tensor[:, i:i + n_bars * resolution]\n",
    "        sequences.append((seq_c_tensor, seq_s_tensor))\n",
    "        print(f\"seq_c_tensor shape: {seq_c_tensor.shape}, seq_s_tensor shape: {seq_s_tensor.shape}\")\n",
    "    return sequences\n",
    "\n",
    "def save_preprocessed_data(filepath, sequences):\n",
    "    \"\"\"\n",
    "    Save the preprocessed data sequences to a file.\n",
    "    Each sequence is saved as a separate item in the npz file.\n",
    "    \"\"\"\n",
    "    # Create a dict where key is the sequence index and value is the sequence data\n",
    "    seq_dict = {}\n",
    "    for i, (seq_c_tensor, seq_s_tensor) in enumerate(sequences):\n",
    "        seq_dict[f'seq_c_{i}'] = seq_c_tensor\n",
    "        seq_dict[f'seq_s_{i}'] = seq_s_tensor\n",
    "\n",
    "    # Save each sequence tensor as a separate item in the npz file\n",
    "    np.savez(filepath, **seq_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(n_bars=2, resolution=8)\n",
    "\n",
    "# Generate sample data\n",
    "sample_data = generate_sample_data(N_SAMPLES, N_TIMESTEPS)\n",
    "\n",
    "# Preprocess the data\n",
    "sequences = preprocess_data(sample_data, args.n_bars, args.resolution)\n",
    "\n",
    "# Save the preprocessed data\n",
    "save_preprocessed_data(\"preprocessed_data.npz\", sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "    track_edges = []\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    for track in range(s_tensor.size(0)):\n",
    "        tss = list(ones_idxs[1][ones_idxs[0] == track])\n",
    "        edge_type = EdgeTypes.TRACK.value + track\n",
    "        edges = [\n",
    "            (node_labels[track, t1].item(), node_labels[track, t2].item(), edge_type, t2 - t1)\n",
    "            for t1, t2 in zip(tss[:-1], tss[1:])\n",
    "        ]\n",
    "        inverse_edges = [(u, v, t, d) for (v, u, t, d) in edges]\n",
    "        track_edges.extend(edges + inverse_edges)\n",
    "\n",
    "    return torch.tensor(track_edges, dtype=torch.long) if track_edges else torch.empty((0, 4), dtype=torch.long)\n",
    "\n",
    "def get_onset_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "    onset_edges = []\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    for ts in range(s_tensor.size(1)):\n",
    "        tracks = list(ones_idxs[0][ones_idxs[1] == ts])\n",
    "        combinations = list(itertools.combinations(tracks, 2))\n",
    "        edges = [\n",
    "            (node_labels[track1, ts].item(), node_labels[track2, ts].item(), EdgeTypes.ONSET.value, 0)\n",
    "            for track1, track2 in combinations\n",
    "        ]\n",
    "        inverse_edges = [(u, v, t, d) for (v, u, t, d) in edges]\n",
    "        onset_edges.extend(edges + inverse_edges)\n",
    "\n",
    "    return torch.tensor(onset_edges, dtype=torch.long) if onset_edges else torch.empty((0, 4), dtype=torch.long)\n",
    "\n",
    "def get_next_edges(s_tensor, ones_idxs=None, node_labels=None):\n",
    "    next_edges = []\n",
    "\n",
    "    if ones_idxs is None:\n",
    "        ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    if node_labels is None:\n",
    "        node_labels = get_node_labels(s_tensor, ones_idxs)\n",
    "\n",
    "    tss = torch.nonzero(torch.any(s_tensor.bool(), dim=0)).squeeze()\n",
    "    if tss.dim() == 0:\n",
    "        return torch.empty((0, 4), dtype=torch.long)\n",
    "\n",
    "    for i in range(tss.size(0)-1):\n",
    "        t1, t2 = tss[i], tss[i+1]\n",
    "        t1_tracks = ones_idxs[0][ones_idxs[1] == t1]\n",
    "        t2_tracks = ones_idxs[0][ones_idxs[1] == t2]\n",
    "        tracks_product = list(itertools.product(t1_tracks, t2_tracks))\n",
    "        tracks_product = [(track1, track2) for (track1, track2) in tracks_product if track1 != track2]\n",
    "        edges = [\n",
    "            (node_labels[track1, t1].item(), node_labels[track2, t2].item(), EdgeTypes.NEXT.value, t2 - t1)\n",
    "            for track1, track2 in tracks_product\n",
    "        ]\n",
    "\n",
    "        next_edges.extend(edges)\n",
    "\n",
    "    return torch.tensor(next_edges, dtype=torch.long) if next_edges else torch.empty((0, 4), dtype=torch.long)\n",
    "\n",
    "def get_track_features(s_tensor):\n",
    "    # Indices where the binary structure tensor is active\n",
    "    ones_idxs = torch.nonzero(s_tensor, as_tuple=True)\n",
    "\n",
    "    n_nodes = len(ones_idxs[0])\n",
    "    tracks = ones_idxs[0]  # Track indices for each active node\n",
    "\n",
    "    # Assuming N_TRACKS is the total number of tracks (3 in this case)\n",
    "    features = torch.zeros((n_nodes, N_TRACKS), dtype=torch.float32)\n",
    "\n",
    "    # Assign one-hot encoded track information as features\n",
    "    for i, track_idx in enumerate(tracks):\n",
    "        features[i, track_idx] = 1.0\n",
    "\n",
    "    return features\n",
    "\n",
    "def graph_from_tensor(s_tensor):\n",
    "    bars = []\n",
    "\n",
    "    # Iterate over bars and construct a graph for each bar\n",
    "    for i in range(s_tensor.size(1)):  # Adjusted to iterate over timesteps\n",
    "        bar = s_tensor[:, i, :]  # Adjusted to select the correct slice\n",
    "\n",
    "        if not torch.any(bar):\n",
    "            bar[0, 0] = 1  # Add a fake activation if the bar is empty\n",
    "\n",
    "        track_edges = get_track_edges(bar)\n",
    "        onset_edges = get_onset_edges(bar)\n",
    "        next_edges = get_next_edges(bar)\n",
    "        edges = [track_edges, onset_edges, next_edges]\n",
    "\n",
    "        edge_list = torch.cat([x for x in edges if x.numel() > 0]) if any(x.numel() > 0 for x in edges) else torch.LongTensor([[0], [0]])\n",
    "        edge_index = edge_list[:, :2].t().contiguous()\n",
    "        attrs = edge_list[:, 2:] if edge_list.numel() > 0 else torch.Tensor([[0, 0]])\n",
    "\n",
    "        edge_attrs = torch.zeros(attrs.size(0), s_tensor.shape[-1] + 1)\n",
    "        edge_attrs[:, 0] = attrs[:, 0]\n",
    "        edge_attrs[torch.arange(edge_attrs.size(0)), attrs.long()[:, 1] + 1] = 1\n",
    "\n",
    "        node_features = get_track_features(bar)\n",
    "        num_nodes = torch.sum(bar, dtype=torch.long)\n",
    "\n",
    "        bars.append(Data(edge_index=edge_index, edge_attrs=edge_attrs, num_nodes=num_nodes, node_features=node_features).to(s_tensor.device))\n",
    "\n",
    "    graph, _, _ = collate(Data, data_list=bars, increment=True, add_batch=True)\n",
    "    graph.bars = graph.batch  # Rename to avoid conflict with DataLoader's batch\n",
    "\n",
    "    return graph\n",
    "\n",
    "def get_node_labels(s_tensor, ones_idxs):\n",
    "    # Build a tensor which has node labels in place of each activation in the\n",
    "    # stucture tensor\n",
    "    labels = torch.zeros_like(s_tensor, dtype=torch.long, \n",
    "                              device=s_tensor.device)\n",
    "    n_nodes = len(ones_idxs[0])\n",
    "    labels[ones_idxs] = torch.arange(n_nodes, device=s_tensor.device)\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n",
      "seq_c_tensor shape: (100, 16, 5, 2), seq_s_tensor shape: (100, 16)\n"
     ]
    }
   ],
   "source": [
    "class PolyphemusDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_c_tensor, seq_s_tensor = self.sequences[idx]\n",
    "        c_tensor = torch.tensor(seq_c_tensor, dtype=torch.float)\n",
    "        s_tensor = torch.tensor(seq_s_tensor, dtype=torch.float)\n",
    "\n",
    "        # Convert to one-hot encoding if necessary or directly use as features\n",
    "        # Here, assuming c_tensor is already in the desired format\n",
    "        # and s_tensor indicates the structure (active/inactive timesteps)\n",
    "\n",
    "        # Build graph structure from structure tensor\n",
    "        # Note: The function `graph_from_tensor` should be defined elsewhere in the project\n",
    "        # and is responsible for converting the structure tensor into a graph object\n",
    "        # compatible with the GNN model.\n",
    "        s_tensor = s_tensor.unsqueeze(0)\n",
    "        graph = graph_from_tensor(s_tensor)\n",
    "\n",
    "        graph.c_tensor = c_tensor\n",
    "        graph.s_tensor = s_tensor\n",
    "\n",
    "        return graph\n",
    "\n",
    "# Example usage\n",
    "sample_data = generate_sample_data(N_SAMPLES, N_TIMESTEPS)\n",
    "sequences = preprocess_data(sample_data, n_bars=2, resolution=8)\n",
    "dataset = PolyphemusDataset(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 3000], edge_attrs=[3000, 17], num_nodes=1600, node_features=[1600, 4], batch=[1600], ptr=[101], bars=[1600], c_tensor=[100, 16, 5, 2], s_tensor=[1, 100, 16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph 0:\n",
      "c_tensor shape: torch.Size([100, 16, 5, 2])\n",
      "s_tensor shape: torch.Size([1, 100, 16])\n",
      "----------\n",
      "Graph 1:\n",
      "c_tensor shape: torch.Size([100, 16, 5, 2])\n",
      "s_tensor shape: torch.Size([1, 100, 16])\n",
      "----------\n",
      "Graph 2:\n",
      "c_tensor shape: torch.Size([100, 16, 5, 2])\n",
      "s_tensor shape: torch.Size([1, 100, 16])\n",
      "----------\n",
      "Graph 3:\n",
      "c_tensor shape: torch.Size([100, 16, 5, 2])\n",
      "s_tensor shape: torch.Size([1, 100, 16])\n",
      "----------\n",
      "Graph 4:\n",
      "c_tensor shape: torch.Size([100, 16, 5, 2])\n",
      "s_tensor shape: torch.Size([1, 100, 16])\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Print the contents of the first few items in the dataset\n",
    "for i in range(min(len(dataset), 5)):  # Just as an example, print first 5 items\n",
    "    graph = dataset[i]\n",
    "    print(f\"Graph {i}:\")\n",
    "    print(f\"c_tensor shape: {graph.c_tensor.shape}\")\n",
    "    print(f\"s_tensor shape: {graph.s_tensor.shape}\")\n",
    "    # Add any other properties you wish to inspect\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
